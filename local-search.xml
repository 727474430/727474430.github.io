<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>K8S-External-Service</title>
    <link href="/2020/06/07/K8S-External-Service/"/>
    <url>/2020/06/07/K8S-External-Service/</url>
    
    <content type="html"><![CDATA[<center><p style="font-size:30px;color:black"> K8S External Service </p></center><a id="more"></a><h3 id="Kubernetes- 外部服务"><a href="#Kubernetes- 外部服务" class="headerlink" title="Kubernetes 外部服务"></a>Kubernetes 外部服务 </h3><p>  &ensp;&ensp; 在 Kubernetes 使用过程中，我们经常会使用一些部署在 Kubernetes 集群外的服务，例如数据库、缓存、配置中心等。在开发过程中对于这些服务我们一般都会部署多个环境，例如开发、测试、生产等，那么每个环境都会有不同的 IP Address 或 Domain，而我们又不想在每个环境里都变更代码，所以一般都不会硬编码这些地址。</p><p>  &ensp;&ensp; 在 Kubernetes 中我们可以基于 DNS 服务发现来访问这些外部服务，就如同访问本地服务一样。</p><center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/multi-env-service.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        多环境外部服务    </div></center><h3 id="Kubernetes- 静态服务"><a href="#Kubernetes- 静态服务" class="headerlink" title="Kubernetes 静态服务"></a>Kubernetes 静态服务 </h3><p>  &ensp;&ensp; 在 Kubernetes 中可以使用静态服务的方式，对外部服务建立连接。</p><p>  &ensp;&ensp; 我们可以创建一个没有关联任何 Pod 的 Service 对象，然后在创建一个可以接受流量的 Endpoints 对象。在 Endpoints 中需要手动置顶远程服务 IP Address 并且使用与 Service 相同的名字。Kubernetes 会使用配置的所有 IP Address 来建立外部服务连接，这样我们就可以使用一条简单的连接串来访问外部服务了。也就避免了在应用中硬编码外部服务的问题。如果以后 IP Address 发生变更，我们只需要在 Endpoints 中更新即可，应用程序无需任何变更，这对应用是透明的。</p><center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/static-service.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        静态服务    </div></center><h3 id="Kubernetes-IP- 静态服务"><a href="#Kubernetes-IP- 静态服务" class="headerlink" title="Kubernetes IP 静态服务"></a>Kubernetes IP 静态服务 </h3><p>  &ensp;&ensp; 如果我们可以使用 IP Address 方式访问外部服务，我们就可以通过 <strong>type: ClusterIp</strong> 的 IP 静态服务的方式对外部服务建立连接。Kubernetes 会通过 IP 方式进行重定向，性能开销非常小。</p><p>  &ensp;&ensp; 如下我们为外部的 MongoDb 服务建立了静态服务，我们的应用可以通过连接串的方式进行连接。</p><p>  &ensp;&ensp;<strong>mongodb://external-mongo</strong></p><pre><code class="yaml">apiVersion: v1kind: Servicemetadata:  name: external-mongospec:  type: ClusterIp  ports:  - port: 27017    targetPort: 27017</code></pre><pre><code class="yaml">apiVersion: v1kind: Endpointsmetadata:  name: external-mongosubsets:  - address:      - ip: 10.0.0.1    ports:      - port: 27017</code></pre><center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/ip-static-service.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        IP 静态服务    </div></center><h3 id="Kubernetes-URL- 静态服务（一）"><a href="#Kubernetes-URL- 静态服务（一）" class="headerlink" title="Kubernetes URL 静态服务（一）"></a>Kubernetes URL 静态服务（一）</h3><p>  &ensp;&ensp; 如果我们无法使用 IP Address 方式访问外部服务，而是需要通过 URL 方式进行外部服务的访问，我们就需要通过 <strong>type: ExternalName</strong> 的 Domain 静态服务的方式对外部服务建立连接。Kubernetes 会通过内核级别的 CNAME 进行重定向，性能开销非常小。</p><p>  &ensp;&ensp; 如下我们为外部的 MongoDb 服务建立了静态服务，我们的应用可以通过连接串的方式进行连接。</p><p>  &ensp;&ensp;<strong>mongodb://<dbuser>:<dbpassword>@external-mongo:<port>/dev</port></dbpassword></dbuser></strong></p><pre><code class="yaml">apiVersion: v1kind: Servicemetadata:  name: external-mongospec:  type: ExternalName  externalName: mongo.service.com</code></pre><center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/domain-static-service1.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        Domain 静态服务带端口    </div></center><h3 id="Kubernetes-URL- 静态服务（二）"><a href="#Kubernetes-URL- 静态服务（二）" class="headerlink" title="Kubernetes URL 静态服务（二）"></a>Kubernetes URL 静态服务（二）</h3><p>  &ensp;&ensp; 通过 Domain 的方式我们连接了外部服务，我们发现外部服务的端口号是硬编码的，如果外部服务端口段是静态的那么这种方式没有任何问题，但是如果外部端口是动态的，那么我们就需要在端口进行变更时，手动修改硬编码的端口，这无异是一种累赘。</p><p>  &ensp;&ensp; 对于上述问题，我们可以通过 nslookup domain 或 ping domain 获取到 domain 对应的 IP Address，有了 IP 我们就可以使用 Endpoints 方式对外部服务建立静态连接了。</p><p>  &ensp;&ensp; 如下我们为外部的 MongoDb 服务建立了静态服务，我们的应用可以通过连接串的方式进行连接。</p><p>  &ensp;&ensp;<strong>mongodb://<dbuser>:<dbpassword>@external-mongo/dev</dbpassword></dbuser></strong></p><pre><code class="bash">$ nslookup mongo.service.com  Server:        192.168.1.1Address:    192.168.1.1#53Non-authoritative answer:www.baidu.com    canonical name = mongo.service.com Name:    mongo.service.com Address: 10.0.0.1</code></pre><pre><code class="yaml">apiVersion: v1kind: Servicemetadata:  name: external-mongospec:  ports:  - port: 27017    targetPort: 27017</code></pre><pre><code class="yaml">apiVersion: v1kind: Endpointsmetadata:  name: external-mongosubsets:  - address:      - ip: 10.0.0.1    ports:      - port: 27017</code></pre><center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/domain-static-service2.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        Domain 静态服务无端口    </div></center><h3 id="注意事项"><a href="# 注意事项" class="headerlink" title="注意事项"></a> 注意事项 </h3><ul><li><p> 使用 domain 解析 ip 的方式时，需要确保 ip 地址是不会变的，否则当 ip 发生变更时，在生产环境可能会出现无法连接外部服务的情况。</p></li><li><p> 使用 type: ClusterIp 建立静态服务时，需要确保外部服务的 IP Address 是集群内部 IP 通往的的地址才可以。</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Kubernetes</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>K8S-Termination-Grace</title>
    <link href="/2020/06/07/K8S-Termination-Grace/"/>
    <url>/2020/06/07/K8S-Termination-Grace/</url>
    
    <content type="html"><![CDATA[<center><p style="font-size:30px;color:black"> K8S Termination Grace </p></center><a id="more"></a><h3 id="Kubernetes- 系统健康"><a href="#Kubernetes- 系统健康" class="headerlink" title="Kubernetes 系统健康"></a>Kubernetes 系统健康 </h3><p>  &ensp;&ensp; 在分布式系统中能及时处理系统失败是很重要的一项能力。Kubernetes 可以利用 Controller 观察系统的运行状态，并重启已经停止运转的服务。另一方面 Kubernetes 可以强制终止服务，并确保系统整体不受损害。</p><p>  &ensp;&ensp; 在传统容器或虚拟机中，如果节点出错，需要我们人为的重启系统并启动相关应用，服务会长时间的处于不可用状态，这对用户来讲是不可接受的。</p><p>  &ensp;&ensp; 在 Kubernets 中会使用一种循环系统，确保从容器到节点的资源都保持健康，确保不再需要人为进行系统监控。如果一个资源在健康检查过程中出现问题，Kubernetes 会自动制作一个替代品。</p><center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/cycle-check.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        循环检测，确保系统健康    </div></center><h3 id="Kubernetes- 优雅关闭"><a href="#Kubernetes- 优雅关闭" class="headerlink" title="Kubernetes 优雅关闭"></a>Kubernetes 优雅关闭 </h3><p>  &ensp;&ensp;Kubernetes 会在一些情况下主动终止一个健康的容器，用以确保调度任务正常执行，例如滚动更新 Deployment、资源耗尽终止 Pod 释放资源、节点故障迁移 Pod 等，Kubernetes 会慢慢终止久的容器，同时准备新的替代品。所以这时我们需要确保可以将我们的应用优雅关闭，优雅关闭前需要终止所有长链接、数据库连接、WebSocket 流、保存会话状态等工作。</p><h3 id="Kubernetes-sigterm"><a href="#Kubernetes-sigterm" class="headerlink" title="Kubernetes sigterm"></a>Kubernetes sigterm</h3><p>  &ensp;&ensp; 当应用收到 Sigterm 信号时，应用响应 sigterm 信号并开始进行优雅关闭，一旦 Kubernetes 决定终止容器，会出发一系列相关事件。</p><center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/sigterm-state.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        sigterm 状态    </div></center><h3 id="Kubernetes-Prestop"><a href="#Kubernetes-Prestop" class="headerlink" title="Kubernetes Prestop"></a>Kubernetes Prestop</h3><p>  &ensp;&ensp;Prestop 钩子是一个特殊的 Command 或者 HTTP 请求，会被发送到 Pod 的容器中。如果应用不能在收到 Sigterm 信号时优雅关闭，可以使用 Prestop 钩子来触发应用的优雅关闭。当出发 Prestop 时，Kubernetes 会等待一段被称为优雅关闭的时间数值。</p><pre><code class="yaml">apiVersion: v1kind: Podmetadata:  name: Termination-demospec:  containers:  - name: Termination-demo    image: nginx:1.9    ports:      - name: http        containerPort: 80    lifecycle:      preStop:        exec:          command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo preStop handler &gt;&gt; /usr/share/message; sleep 30&quot;]</code></pre><center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/prestop-state.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        prestop 状态    </div></center><h3 id="Kubernetes-TerminationGracePeriodSeconds"><a href="#Kubernetes-TerminationGracePeriodSeconds" class="headerlink" title="Kubernetes TerminationGracePeriodSeconds"></a>Kubernetes TerminationGracePeriodSeconds</h3><p>  &ensp;&ensp;TerminationGracePeriodSeconds 代表优雅关闭等待时间，Kubernetes 在终止 Pod 时会等待该参数值设置的时间后，强制终止 Pod，注意超过这个时间后 Kubernetes 不会等待 Sigterm 或 Prestop 处理完成。</p><pre><code class="yaml">apiVersion: v1kind: Podmetadata:  name: Termination-demospec:  containers:  - name: Termination-demo    image: nginx:1.9    ports:      - name: http        containerPort: 80    TerminationGracePeriodSeconds: 60</code></pre><center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/terminating-grace-period-state.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        termination 状态    </div></center><h3 id="Kubernetes-Sigkill"><a href="#Kubernetes-Sigkill" class="headerlink" title="Kubernetes Sigkill"></a>Kubernetes Sigkill</h3><p>  &ensp;&ensp;Kubernetes 会在等待 TerminationGracePeriodSeconds 时间后，对有容器运行 Pod 发送 Sigkill 信号，然后强制移除 Pod 并清除所有对象。</p><center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/sigkill-state.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        sigkill 状态    </div></center><h3 id="注意事项"><a href="# 注意事项" class="headerlink" title="注意事项"></a> 注意事项 </h3><ul><li><p> 应用应该测试当 Sigterm 信号被送达时，应用会做出何种反应。</p></li><li><p>Prestop 是一个优雅关闭的工具。</p></li><li><p>Sigterm 与 Prestop 并行发生。</p></li><li><p>TerminationGracePeriodSeconds 值的设置一定要经过严格的测试。</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Kubernetes</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>K8S-Resources</title>
    <link href="/2020/06/07/K8S-Resources/"/>
    <url>/2020/06/07/K8S-Resources/</url>
    
    <content type="html"><![CDATA[<center><p style="font-size:30px;color:black"> K8S Resources </p></center><a id="more"></a><h3 id="Kubernetes- 资源管理"><a href="#Kubernetes- 资源管理" class="headerlink" title="Kubernetes 资源管理"></a>Kubernetes 资源管理 </h3><p>  &ensp;&ensp; 在 Kubernetes 调度 Pod 时，节点有足够的资源用来运行容器非常重要。如果想将一个大的应用调度到一个资源受限的节点，节点可能会耗尽 Memory 或 CPU，导致无法正常工作。</p><p>  &ensp;&ensp; 在 Kubernetes 中提供了 requests 和 limits 来解决调度时选择合适资源的问题。requests 和 limits 是用于控制资源的机制，例如 CPU 和 Memory。</p><p>  &ensp;&ensp; 在 Kubernetes 中 scheduler 使用 CPU 和 Memory 的值来确定在哪里运行 Pod。Pod 中的每个容器都可以设置自己的 requests 和 limits，这些都是附加值。CPU 资源使用 millicores 定义，Memory 使用 million 定义。</p><center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/requests.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        requests 资源    </div></center><center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/limits.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        limits 资源    </div></center><h3 id="Kubernetes-Requests"><a href="#Kubernetes-Requests" class="headerlink" title="Kubernetes Requests"></a>Kubernetes Requests</h3><p>  &ensp;&ensp;requests 代表一定能获取到的资源，如果一个容器设置了 requests 属性，Kubernetes 会将其调度到能够提供这些资源的节点上。</p><p>  &ensp;&ensp;requests 有两种类型的资源：</p><ul><li><p>CPU：需要使用 CPU 的核数，单位是 millicores。如：1/4 核设置为 250m，1 核设置为 1000m。</p></li><li><p>Memory：需要使用 Memory 的容量，单位时 million。如：100 兆设置为 100Mi，200 兆设置为 200Mi。</p><pre><code class="yaml">apiVersion: v1kind: Podmetadata:  name: resource-demo  labels:    app: resource-demospec:  containers:  - name: resource-demo    image: nginx:1.9    ports:      - name: http        containerPort: 80    resources:      requests:        memory: &quot;32Mi&quot;        cpu: &quot;200m&quot;</code></pre></li></ul><h3 id="Kubernetes-Limits"><a href="#Kubernetes-Limits" class="headerlink" title="Kubernetes Limits"></a>Kubernetes Limits</h3><p>  &ensp;&ensp;limits 代表容器能获取的资源上限，如果一个容器设置了 limits 属性，Kubernetes 只允许容器上升到 limits，然后被限制住。</p><p>  &ensp;&ensp;limits 有两种类型的资源：</p><ul><li><p>CPU：需要使用 CPU 的核数，单位是 millicores。如：1/4 核设置为 250m，1 核设置为 1000m。</p></li><li><p>Memory：需要使用 Memory 的容量，单位时 million。如：100 兆设置为 100Mi，200 兆设置为 200Mi。</p><pre><code class="yaml">apiVersion: v1kind: Podmetadata:  name: resource-demo  labels:    app: resource-demospec:  containers:  - name: resource-demo    image: nginx:1.9    ports:      - name: http        containerPort: 80    resources:      limites:        memory: &quot;64Mi&quot;        cpu: &quot;300m&quot;</code></pre></li></ul><h3 id="Kubernetes-ResourceQuotas"><a href="#Kubernetes-ResourceQuotas" class="headerlink" title="Kubernetes ResourceQuotas"></a>Kubernetes ResourceQuotas</h3><p>  &ensp;&ensp; 为了防止运维人员未限制资源使用或者使用过大的资源，Kubernetes 提供了 ResourceQuotas 资源配额来限制 Namespace 命名空间中所有容器所能使用的资源之合。</p><ul><li><p>requests.cpu：命名空间中所有容器所能达到的合计 CPU requests 的最大值。例如：50 个 10m requests 的容器。</p></li><li><p>requests.memory：命名空间中所有容器能达到的合计 Memory request 的最大值。例如：5 个 20MB requests 的容器。</p></li><li><p>limits.cpu：命名空间中所有容器所能达到的合计 CPU limits 的最大值。</p></li><li><p>limits.memory：命名空间中所有容器能达到的合计 Memory limits 的最大值。</p></li><li><p>pods：命名空间中 Pod 最大实例数。</p></li><li><p>secrets：命名空间中 Secret 最大实例数。</p></li><li><p>services：命名空间中 Service 最大实例数。</p></li><li><p>configmaps：命名空间中 ConfigMap 最大实例数。</p></li><li><p>persistentvolumeclaims：命名空间中 PVC 最大实例数。</p></li><li><p>replicationcontrollers：命名空间中 RC 最大实例数。</p><pre><code class="yaml">apiVersion: v1kind: ResourceQuotametadata:  name: resource-quota-demospec:  hard:    requests.cpu: 0.5    requests.memory: 100Mi    limits.cpu: 1    limits.memory: 500Mi    pods: 10    secrets: 10    services: 10    configmaps: 10    persistentvolumeclaims: 10    replicationcontrollers: 10</code></pre></li></ul><h3 id="Kubernetes-LimitRange"><a href="#Kubernetes-LimitRange" class="headerlink" title="Kubernetes LimitRange"></a>Kubernetes LimitRange</h3><p>  &ensp;&ensp; 通过 LimitRange 可以有效的防止我们在命名空间内创建超小型或超大型的容器。它与针对每个命名空间的 ResourceQuotas 不同，LimitRange 会加强到每个容器上。LimitRange 是对 Pod 和 Container 级别的资源进行限制。</p><ul><li><p>default：Pod 中容器默认 limits，任何没有明确设置 limits 的容器，都将使用这个默认值。</p></li><li><p>defaultRequest：Pod 中容器默认 requests，任何没有明确设置 requests 的容器，都将使用这个默认值。</p></li><li><p>max：Pod 中容器可以设置的最大 limits 值。default 不能大于 max 值，同样容器中设置的值也不能大于该值。如果设置了 max 而为设置 default，那么 max 将成为默认值。</p></li><li><p>min：Pod 中容器可以设置的最小 requests 值。defaultRequest 不能小于 min 值，同样容器中设置的值也不能小于该值。如果设置了 min 而为设置 defaultRequest，那么 min 将成为默人值。</p></li><li><p>maxLimitRequestRatio：limit / request 限制值与请求值的比值上限。例如 Pod 中 CPU 的 Limit 值为 3，而 Requests 值为 0.5，此时比值为 6，创建 Pod 会失效。</p><pre><code class="yaml">apiVersion: v1kind: LimitRangemetadata:  name: limit-range-demosepc:  limits:  - max:      cpu: &quot;4&quot;      memory: 2Gi    min:      cpu: 200m      memory: 6Mi    maxLimitRequestRatio: # max value for limit / request 限制值与请求值的比例      cpu: 3      memory: 2    type: Pod  - default:      cpu: 600m      memory: 100Mi    defaultRequest:      cpu: 100m      memory: 50Mi    max:      cpu: 1000m      memory: 200Mi    min: # min request      cpu: 10m      memory: 10Mi    maxLimitRequestRatio: # max value for limit / request 限制值与请求值的比例      cpu: 2      memory: 2    type: Container</code></pre></li></ul><h3 id="Kubernets- 资源超出"><a href="#Kubernets- 资源超出" class="headerlink" title="Kubernets 资源超出"></a>Kubernets 资源超出 </h3><p>  &ensp;&ensp; 当 CPU 超过负载时，Kubernetes 会限制每个 Pod 可用 CPU 的资源，但会确保每个 Pod 都有可用的 CPU 资源。</p><center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/cpu-allocation.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        限制 CPU 资源    </div></center><p>  &ensp;&ensp; 当 Memory 超过负载时，首先 Kubernetes 会将资源超出 requests 的 Pods 终止运行，如果某个 Pod 没有配置 requests 那么这个 Pod 就满足资源超出 requests 的条件，所以这个 Pod 是终止运行的最佳候选。</p><center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/kill-requests.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        将超出 requests 终止运行    </div></center><p>  &ensp;&ensp; 其次 Kubernetes 会将资源超出 requests 但仍低于 limits 的 Pod 终止运行，如果 Kubernetes 找出了多个符合条件的 Pod 会对这些 Pods 进行优先级（Priority）排序，然后终止运行。</p><center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/kill-priority.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        将优先级 priority 最低的终止运行    </div></center><p>  &ensp;&ensp; 最后如果所有 Pods 优先级一致，那么 Kubernets 会终止运行超出 requests 最多的 Pod。</p><center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/kill-big-requests.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        将超出 requests 最多的终止运行    </div></center><h3 id="注意事项"><a href="# 注意事项" class="headerlink" title="注意事项"></a> 注意事项 </h3><ul><li><p> 如果设置 CPU 核数大于最大节点的核数，那么这个 Pod 将永远无法得到调度。如果应用不是以计算为主，那么 requests 最好设置为 1 或 以下，然后通过更多副本来扩展。这样可以给系统更大的灵活性。</p></li><li><p>CPU 作为一种可压缩资源，当 CPU 使用达到上限时，Kubernetes 将会限制资源使用，这意味着 CPU 将受到认为的限制，给应用带来潜在的性能问题，然而 CPU 无法终止或收回。</p></li><li><p>Memory 作为一种不可压缩的资源，我们无法控制内存的使用，如果容器的内存使用超过了 limits 它将被终止。</p></li><li><p> 如果集群中所有节点都无法满足 Pod 需要的资源，那么 Pod 将被挂起。</p></li></ul><center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/big-requests.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        requests 过大无法调度    </div></center>]]></content>
    
    
    <categories>
      
      <category>Kubernetes</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>K8S-Health</title>
    <link href="/2020/06/06/K8S-Health/"/>
    <url>/2020/06/06/K8S-Health/</url>
    
    <content type="html"><![CDATA[<center><p style="font-size:30px;color:black"> K8S Health </p></center><a id="more"></a><h3 id="分布式系统问题"><a href="# 分布式系统问题" class="headerlink" title="分布式系统问题"></a> 分布式系统问题 </h3><p>&ensp;&ensp; 分布式系统比较难于管理的主要原因在于，在系统运行过程中，如果有某一点出现问题，我们需要让系统自动绕过该问题，并且自动修复该问题，来给用户带来 0 宕机时间的高可用系统。</p><h3 id="Kubernetes- 健康检查"><a href="#Kubernetes- 健康检查" class="headerlink" title="Kubernetes 健康检查"></a>Kubernetes 健康检查 </h3><p>&ensp;&ensp; 运行状况检查是一种可以让系统知道当前系统中每一个实例状态是否正常的简单方法，如果某个某个实例的某个服务不可用，那么其他服务就不应访问它，也就是不应该有任何流量发送到该服务，正确的方式应该是将流量发往另一个正常的实例或稍后重试。同时系统还应该将不可用的服务恢复到健康的状态。</p><p>&ensp;&ensp; 在 Kubernetes 中当 Pod 中所有的容器（应用进程）启动后，Kuberntes 将会开始向该 Pod 发送流量。并且在容器故障时重新启动容器。这个默认的行为一个足够好了，但是 Kubernetes 提供了可以自定义运行健康检查的方式，让我们更有针对性的应对不同容器做出更合理的检查方式。</p><h3 id="Kubernetes- 健康检查方式"><a href="#Kubernetes- 健康检查方式" class="headerlink" title="Kubernetes 健康检查方式"></a>Kubernetes 健康检查方式 </h3><p>&ensp;&ensp;Kubernetes 提供了两种健康检查的方式：</p><ul><li><p>Readiness 探针的用途旨在让 Kubernetes 知道我们的应用何时准备就绪，可对外提供服务。Kubernetes 在允许服务将流量发送到 Pod 之前，会确保 readiness 通过检查。如果启动时 readiness 探针失败，Kubernetes 会停止向这个 Pod 发送流量 </p></li><li><p>Liveness 探针的用途旨在让 Kubernetes 知道我们的应用是否存活，如果检测到应用非存活状态，Kubernetes 会删除这个 Pod，并启动一个新的 Pod 替换它。</p></li></ul><h3 id="Kubernetes- 健康检查类型"><a href="#Kubernetes- 健康检查类型" class="headerlink" title="Kubernetes 健康检查类型"></a>Kubernetes 健康检查类型 </h3><p>&ensp;&ensp;Kubernetes 提供了三种健康检查的类型：</p><ul><li><p>HTTP：发送 HTTP 请求，Kubernetes 会 ping 一个指定 path，当返回状态码在 200-300 范围内会标记为健康，否则标记为不健康。即使应用不是 HTTP 服务，也可以写一个轻量级 HTTP 接口，用于响应 Liveness 检测。</p></li><li><p>CMD：在容器中运行指定命令，如果命令返回码为 0 会标记为健康，否则标记为不健康。当不能使用 HTTP 检测服务是否健康时，可以使用 CMD 运行指定命令的方式进行健康检查。</p></li><li><p>TCP：在容器中对指定端口建立 TCP 链接，如果可以建立会标记为健康，否则标记为不健康。当服务为 grpc 或 ftp 等服务时，可以使用 TCP 对指定端口建立 TCP 链接进行健康检查。</p></li></ul><h3 id="Kubernetes- 健康检查属性"><a href="#Kubernetes- 健康检查属性" class="headerlink" title="Kubernetes 健康检查属性"></a>Kubernetes 健康检查属性 </h3><p>&ensp;&ensp;Kubernetes 提供了五种健康检查的属性：</p><ul><li><p>initialDelaySeconds：第一次检查，在容器启动多少秒后执行检查，单位秒。</p></li><li><p>periodSeconds：周期性检查，在容器启动后执行检查的周期是多少秒，单位秒。</p></li><li><p>timeoutSeconds：检查超时时间，检查运行超过多少秒后认为失败，单位秒。</p></li><li><p>successThreshold：检查成功阈值，检查通过次数达到阈值时认为成功，单位秒。</p></li><li><p>failureThreshold：检查失败阈值，检查失败此时达到阈值时认为失败，单位秒。</p></li></ul><h3 id="Liveness- 存活性检查"><a href="#Liveness- 存活性检查" class="headerlink" title="Liveness 存活性检查"></a>Liveness 存活性检查 </h3><p>&ensp;&ensp;Kubernetes 会定期执行 Liveness 探针检测，在通过检测时不会对 Pod 做任何处理。在未通过检测时 Kubernetes 会删除该 Pod，并启动新的 Pod 替换它。</p><ul><li>HTTP 方式 </li></ul><p> 启动 nginx 容器 5 秒后执行存活性检查，ping /index.html 路径，检查周期 5 秒，检查超时时间 5 秒，失败 3 次后认为失败，成功 1 次后认为成功。</p><pre><code class="yaml">apiVersion: v1kind: Podmetadata:name: liveness-httplabels:app: liveness-httpspec:containers:        - name: liveness        image: nginx:1.9        ports:                - name: http                containerPort: 80                livenessProbe:                httpGet:                path: /index.html                port: 80                initialDelaySeconds: 5                periodSeconds: 5                timeoutSeconds: 3                successThreshold: 1                failureThreshold: 3                ```* CMD 方式启动 busybox 容器 5 秒后执行存活性检查，cat /tmp/healthy 文件，检查周期 5 秒，检查超时时间 5 秒，失败 3 次后认为失败，成功 1 次后认为成功。```yamlapiVersion: v1kind: Podmetadata:name: liveness-cmdlabels:app: liveness-cmdspec:containers:        - name: busybox        image: busybox        command: [&quot;sh&quot;, &quot;-c&quot;, &quot;touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600&quot;]        livenessProbe:        exec:        command:                        - cat                        - /tmp/healthy                        initialDelaySeconds: 5                        periodSeconds: 5                        timeoutSeconds: 3                        successThreshold: 1                        failureThreshold: 3                        ```* TCP 方式启动 nginx 容器 5 秒后执行存活性检查，对 80 端口建立 tcp 链接，检查周期 5 秒，检查超时时间 5 秒，失败 3 次后认为失败，成功 1 次后认为成功。```yamlapiVersion: v1kind: Podmetadata:name: liveness-tcplabels:app: liveness-tcpspec:containers:        - name: liveness        image: nginx:1.9        ports:                - name: http                containerPort: 80                livenessProbe:                tcpSocket:                port: 80                initialDelaySeconds: 5                periodSeconds: 5                timeoutSeconds: 3                successThreshold: 1                failureThreshold: 3                ```                &lt;center&gt;                &lt;img style=&quot;border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);&quot;                 src=&quot;http://qiniu.raindrop-wl.cn/liveness-pass.png&quot;&gt;                &lt;div style=&quot;color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;&quot;&gt;                liveness-pass                &lt;/div&gt;                &lt;/center&gt;                &lt;center&gt;                &lt;img style=&quot;border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);&quot;                 src=&quot;http://qiniu.raindrop-wl.cn/liveness-notpass.png&quot;&gt;                &lt;div style=&quot;color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;&quot;&gt;                liveness-notpass                &lt;/div&gt;                &lt;/center&gt;### Readiness 可用性检查&amp;ensp;&amp;ensp;Kuberntes 会定期执行 Readiness 探针检测，在未通过检测时不会将流量发往该 Pod。在通过检测后才会将流量发往该 Pod。* HTTP 方式启动 nginx 容器 5 秒后执行可用性检查，ping /index.html 路径，检查周期 5 秒，检查超时时间 5 秒，失败 3 次后认为失败，成功 1 次后认为成功。```yamlapiVersion: v1kind: Podmetadata:name: readiness-httplabels:app: readiness-httpspec:containers:        - name: readiness        image: nginx:1.9        ports:                - name: http                containerPort: 80                readinessProbe:                httpGet:                path: /index.html                port: 80                initialDelaySeconds: 5                periodSeconds: 5                timeoutSeconds: 3                successThreshold: 1                failureThreshold: 3                ```* CMD 方式启动 busybox 容器 5 秒后执行可用性检查，cat /tmp/healthy 文件，检查周期 5 秒，检查超时时间 5 秒，失败 3 次后认为失败，成功 1 次后认为成功。```yamlapiVersion: v1kind: Podmetadata:name: readiness-cmdlabels:app: readiness-cmdspec:containers:        - name: nginx        image: nginx:1.9        command: [&quot;sh&quot;, &quot;-c&quot;, &quot;touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600&quot;]        readinessProbe:        exec:        command:                        - cat                        - /tmp/healthy                        initialDelaySeconds: 5                        periodSeconds: 5                        timeoutSeconds: 3                        successThreshold: 1                        failureThreshold: 3                        ```* TCP 方式启动 nginx 容器 5 秒后执行可用性检查，对 80 端口建立 tcp 链接，检查周期 5 秒，检查超时时间 5 秒，失败 3 次后认为失败，成功 1 次后认为成功。```yamlapiVersion: v1kind: Podmetadata:name: readiness-tcplabels:app: readiness-tcpspec:containers:        - name: readiness        image: nginx:1.9        ports:                - name: http                containerPort: 80                readinessProbe:                tcpSocket:                port: 80                initialDelaySeconds: 5                periodSeconds: 5                timeoutSeconds: 3                successThreshold: 1                failureThreshold: 3                ```                &lt;center&gt;                &lt;img style=&quot;border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);&quot;                 src=&quot;http://qiniu.raindrop-wl.cn/readiness-notpass.png&quot;&gt;                &lt;div style=&quot;color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;&quot;&gt;                readiness-notpass                &lt;/div&gt;                &lt;/center&gt;                &lt;center&gt;                &lt;img style=&quot;border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);&quot;                 src=&quot;http://qiniu.raindrop-wl.cn/readiness-pass.png&quot;&gt;                &lt;div style=&quot;color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;&quot;&gt;                readiness-pass                &lt;/div&gt;                &lt;/center&gt;### 注意事项* 当使用 Liveness 时，需要注意 initialDelaySecons 参数设置的时间一定要大于应用启动时间，否则应用只能不断的循环重启，永远无法就绪。* 建议使用 P99 的启动时间作为 initialDelaySecons 参数的值。随着应用启动时间变快或变慢，确保更新该参数。</code></pre>]]></content>
    
    
    <categories>
      
      <category>Kubernetes</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>K8S-Namespace</title>
    <link href="/2020/06/04/K8S-Namespace/"/>
    <url>/2020/06/04/K8S-Namespace/</url>
    
    <content type="html"><![CDATA[<center><p style="font-size:30px;color:black"> K8S Namespace </p></center><a id="more"></a><h3 id="Namespace- 介绍"><a href="#Namespace- 介绍" class="headerlink" title="Namespace 介绍"></a>Namespace 介绍 </h3><p>  &ensp;&ensp;K8S 中的 Namespace（命名空间）的作用是资源隔离。我们可以想象为在 K8S 集群内的虚拟机，用来讲不空命名空间的资源进行彼此隔离。当企业内部存在多个项目组时，可以通过 Namespace 来对项目组范围资源进行隔离，也可通过 Namespace 对应用相关环境如开发、测试、生产等进行隔离。</p><p>  &ensp;&ensp; 虽然 Namespace 可以隔离资源，但是不同的 Namespace 之间的服务是可以互相访问的。这样设计的目的是，让一个 Namespace 命名空间下的团队的服务可以调用另一个 Namespace 命名空间下的服务。</p><p>  &ensp;&ensp; 使用 Namespace 还可以提升 K8S 的可控性、安全性和灵活性。</p><h3 id="Namespace- 类型"><a href="#Namespace- 类型" class="headerlink" title="Namespace 类型"></a>Namespace 类型 </h3><p>  &ensp;&ensp;K8S 中的 Namespce 默认提供三个命名空间，分别为：</p><ul><li><p>default</p><p> 当我们创建资源时，未显示的使用命名空间时默认的命名空间 </p></li><li><p>kube-system</p><p>k8s 集群默认资源使用的命名空间，不建议改动该命名空间相关资源 </p></li><li><p>kube-public</p><p> 很少用的命名空间 </p></li><li><p>custom</p><p> 泛指我们自定的命名空间 </p></li></ul><h3 id="Namespace- 创建"><a href="#Namespace- 创建" class="headerlink" title="Namespace 创建"></a>Namespace 创建 </h3><p>  &ensp;&ensp;Namespace 创建的方式有两种，分别如下：</p><ol><li><p> 命令行 </p><pre><code class="bash">$ kubectl create namespace test</code></pre></li><li><p> 声明式 </p><pre><code class="yaml"># test.yamlapiVersion: v1kind: Namespacemetadata:  name: test  labels:    name: test</code></pre><pre><code class="bash">$ kubectl apply -f test.yaml</code></pre></li></ol><h3 id="Namespace- 查询"><a href="#Namespace- 查询" class="headerlink" title="Namespace 查询"></a>Namespace 查询 </h3><p>  &ensp;&ensp;Namespace 查询的方式有两种，分别如下：</p><ol><li><p> 查询全部 </p><pre><code class="bash">$ kubectl get namespace</code></pre></li><li><p> 查询个别 </p><pre><code class="bash">$ kubectl get namespace test</code></pre></li><li><p> 查询制定资源 </p><pre><code class="bash">$ kubectl get pod --namespace=test$ kubectl get svc --namespace=test$ kubectl get deploy --namespace=test</code></pre></li></ol><h3 id="Namespace- 使用"><a href="#Namespace- 使用" class="headerlink" title="Namespace 使用"></a>Namespace 使用 </h3><p>  &ensp;&ensp; 我们可以在创建资源时指定资源所属 Namespace，这里有两种方式，分别如下：</p><ol><li><p> 命令行 </p><pre><code class="bash">$ kubectl apply -f pod.yaml --namespace=test</code></pre></li><li><p> 声明式 </p><pre><code class="yaml">apiVersion: v1kind: Podmetadata:  name: app  namespace: test  labels:    name: appspac:  containers:  - name: nginx    image: nginx</code></pre><p><strong> 注意 </strong>：建议使用声明式，因为无论资源如何改动，使用的命名空间时不会变化的。</p></li></ol><h3 id="Namespace- 激活"><a href="#Namespace- 激活" class="headerlink" title="Namespace 激活"></a>Namespace 激活 </h3><p>  &ensp;&ensp;K8S 默认激活 default 命名空间，当我们创建资源时，未指定命名空间默认都会在 default 空间下进行资源创建。当然我们可以使用 –namespace 或 -n 进行指定命名空间的相关查询、更新等操作，但是这样还是比较麻烦的，每次执行命令都需要指定对应的命名空间。幸运的是，又一个叫做 kubens 的工具，可以简化这个工作。</p><p>  &ensp;&ensp;kubens 使用非常简单，只需要在终端执行 kebens 然后就会在下面列出当前系统中全部的 namespace，如果需要切换直接选择对应的 namespace 安回车即可激活选中的 namespace 为默认激活命名空间。之后的全部操作，默认都会在该 namespace 下进行。  </p><ul><li><p> 运行 kubens 查看命名空间 </p><pre><code class="bash"># 运行 kubens 查看命名空间$ kubensdefault ✅kube-publickube-systemtest</code></pre></li><li><p> 运行 kubens test 切换命名空间 </p><pre><code class="bash"># 运行 kubens test 切换命名空间$ kubens test$ kubensdefaultkube-publickube-systemtest ✅</code></pre></li></ul><h3 id="Namespace- 多服务"><a href="#Namespace- 多服务" class="headerlink" title="Namespace 多服务"></a>Namespace 多服务 </h3><p>  &ensp;&ensp; 在 K8S 中我们想要访问一个服务，只需要使用每桌的 DNS 服务发现，将应用指向服务名即可，但是当一个集群内有多个同名不通作用的服务器时，这是不行的。通过 Namespace 隔离方式 K8S 允许在不同的 Namespace 中存在相同的服务，通过使用扩展形式的 DNS 地址可以轻松解决此问题。</p><p>  &ensp;&ensp;K8S DNS 解析：</p><ul><li><p>DNS 完整版：&lt;ServiceName&gt;.&lt;NamespaceName&gt;.svc.cluster.local</p></li><li><p>DNS 精简版：&lt;ServiceName&gt; 可以解析到当前命名空间下的服务。自动解析成完成版 DNS</p></li><li><p>DNS 命名空间版：&lt;ServiceName&gt;.&lt;NamespaceName&gt; 可以解析到指定命名空间下的服务。自动解析成完成版 DNS</p><p> 例如：访问 test 命名空间下的数据库服务 &lt; 图 1&gt;，访问 prod 命名空间下的数据库 &lt; 图 2&gt;</p>  <center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/namespace-dns1.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        图一      </div>  </center>  <center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/namespace-dns2.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        图二      </div>  </center></li></ul><h3 id="Namespace- 选择"><a href="#Namespace- 选择" class="headerlink" title="Namespace 选择"></a>Namespace 选择 </h3><p>  &ensp;&ensp; 无需使用 Namespace 进行隔离 </p><ul><li><p> 小团队 5-10 人 </p><p> 可以使用 Namespace 进行隔离 </p></li><li><p> 多团队 </p>  <center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/namespace-team.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        多团队      </div>  </center></li><li><p> 多服务 </p>  <center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/namespace-service.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        多团队      </div>  </center></li><li><p> 多环境 </p>  <center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/namespace-env.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        多团队      </div>  </center></li><li><p> 多集群 </p>  <center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/namespace-cluster.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        多团队      </div>  </center></li></ul>]]></content>
    
    
    <categories>
      
      <category>Kubernetes</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>JenkinsSharedLibrary</title>
    <link href="/2020/06/03/JenkinsSharedLibrary/"/>
    <url>/2020/06/03/JenkinsSharedLibrary/</url>
    
    <content type="html"><![CDATA[<center><p style="font-size:30px;color:black"> Jenkins Shared Library </p></center><a id="more"></a><h3 id="Jenkins-Pipeline- 共享库介绍"><a href="#Jenkins-Pipeline- 共享库介绍" class="headerlink" title="Jenkins Pipeline 共享库介绍"></a>Jenkins Pipeline 共享库介绍 </h3><p>  目前 Groupama Jenkins Pipeline 共享库提供了 5 个入口方法，方法如下：</p><ul><li><p>build：代码构建 </p></li><li><p>checkout：代码拉取 </p></li><li><p>codescan：代码扫描 </p></li><li><p>notify：结果通知 </p></li><li><p>logger：执行日志 </p></li></ul><h3 id="build- 代码构建"><a href="#build- 代码构建" class="headerlink" title="build 代码构建"></a>build 代码构建 </h3><p>  该方法主要用来对重复性的构建命令进行服用，目前支持 maven、gradle 两种方式进行构建。</p><ul><li><p> 使用方法 </p><p> 方法签名：Build(String buildType, String buildParams)</p><p>buildType：构建工具类型，支持 maven、gradle 两种方式 </p><p>buildParams：构建参数，如：mvn clean install、gradle build</p></li><li><p>maven</p><pre><code class="groovy">#!groovy@Library(&#39;shared-lib&#39;) _def build = new org.devops.build()pipeline {  stages {stage(&#39;Build&#39;) {      script {build.Build(&#39;maven&#39;, &#39;clean install&#39;)      }    }  }}</code></pre></li><li><p>gradle</p><pre><code class="groovy">#!groovy@Library(&#39;shared-lib&#39;) _def build = new org.devops.build()pipeline {stages { stage(&#39;Build&#39;) {      script {build.Build(&#39;gradle&#39;, &#39;build&#39;)      }    }  }}</code></pre></li></ul><h3 id="checkout- 代码取"><a href="#checkout- 代码取" class="headerlink" title="checkout 代码取"></a>checkout 代码取 </h3><p>  该方法主要用来对应用源码进行拉取，目前支持从 git、svn 两种版本管理工具中拉取代码。</p><ul><li><p> 使用方法 </p><p>Checkout(String scmType, String url, String branchName, String credentialsId)</p><p>scmType：版本管理工具类型，支持 git、svn 两种 </p><p>url：源码地址 </p><p>branchName：分支名称 </p><p>credentialsId：凭证 ID</p></li><li><p>git</p><pre><code class="groovy">#!groovy@Library(&#39;shared-lib&#39;) _def checkout = new org.devops.checkout()pipeline {  stages {stage(&#39;Checkout&#39;) {      script {checkout.Checkout(&#39;git&#39;, &#39;https://github.com/727474430/web-logging-spring-boot-starter&#39;, &#39;master&#39;, &#39;tobo_wl&#39;)      }    }  }}</code></pre></li><li><p>svn</p><pre><code class="groovy">#!groovy@Library(&#39;shared-lib&#39;) _def checkout = new org.devops.checkout()pipeline {  stages {stage(&#39;Checkout&#39;) {      script {checkout.Checkout(&#39;svn&#39;, &#39;https://10.28.1.160/svn/sourcecode/platform/code/groupama-microservice-v2&#39;, &#39;&#39;, &#39;tobo_wl&#39;)      }    }  }}</code></pre></li></ul><h3 id="codescan- 代码扫描"><a href="#codescan- 代码扫描" class="headerlink" title="codescan 代码扫描"></a>codescan 代码扫描 </h3><p>  该方法主要用来对后端代码执行静态文件扫描，对应用中不符合规则的代码进行检索并提示，若代码不符合规范将中断执行流水线任务。</p><ul><li><p> 使用方法 </p><p>SonarScan(String projectKey, String projectVersion, String javaVersion, String modules, String branchName)</p><p>projectKey：项目标识（名称）</p><p>projectVersion：项目版本 </p><p>javaVersion：JDK 版本 </p><p>modules：子模块名称，如果有多个使用 ‘,’ 分割 </p><p>branchName：分支名称，默认 master</p></li><li><p>codescan</p><pre><code class="groovy">#!groovy@Library(&#39;shared-lib&#39;) _def codescan = new org.devops.codescan()pipeline {  stages {stage(&#39;SonarScan&#39;) {      script {codescan.SonarScan(&#39;ticket&#39;, &#39;v1.0&#39;, &#39;1.8&#39;, &#39;ticket-backend,ticket-common&#39;, &#39;dev&#39;)      }    }  }}</code></pre></li></ul><h3 id="logger- 执行日志"><a href="#logger- 执行日志" class="headerlink" title="logger 执行日志"></a>logger 执行日志 </h3><p>  该方法用来在流水线成打印不同级别的日志，通过不同颜色区分，目前支持 info、warning、error 三种级别 </p><ul><li><p> 使用方法 </p><p>Info(String message)、Warning(String message)、Error(String message)</p><p>message：消息内容 </p></li><li><p>info</p><pre><code class="groovy">#!groovy@Library(&#39;shared-lib&#39;) _def logger = new org.devops.logger()pipeline {  stages {stage(&#39;Example&#39;) {      script {logger.Info(&quot; 这是一段 Info 日志 &quot;)      }    }  }}</code></pre></li><li><p>warning</p><pre><code class="groovy">#!groovy@Library(&#39;shared-lib&#39;) _def logger = new org.devops.logger()pipeline {  stages {stage(&#39;Example&#39;) {      script {logger.Warning(&quot; 这是一段 Warning 日志 &quot;)      }    }  }}</code></pre></li><li><p>error</p><pre><code class="groovy">#!groovy@Library(&#39;shared-lib&#39;) _def logger = new org.devops.logger()pipeline {  stages {stage(&#39;Example&#39;) {      script {logger.Error(&quot; 这是一段 Error 日志 &quot;)      }    }  }}</code></pre></li></ul><center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/logger-info.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        Info 日志    </div></center><center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/logger-warning.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        Warning 日志    </div></center><center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/logger-error.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        Error 日志    </div></center><h3 id="notify- 结果通知"><a href="#notify- 结果通知" class="headerlink" title="notify 结果通知"></a>notify 结果通知 </h3><p>  该方法用来发送消息通知，一般在构建结果阶段使用。目前支持钉钉、邮件两种方式。</p><ul><li><p> 使用方法 </p><p>DingTalkNotify(String webhook, String jobName, String status, String version)</p><p>webhook：钉钉机器人 webhook</p><p>jobName：任务名称 </p><p>status：执行状态 </p><p>version：应用版本 </p></li></ul><p>  MailNotify(String to, String status)</p><p>  to：收件人邮箱 </p><p>  status：执行状态 </p><ul><li><p> 钉钉 </p><pre><code class="groovy">#!groovy@Library(&#39;shared-lib&#39;) _def notify = new org.devops.notify()pipeline {  stages {stage(&#39;Notification&#39;) {      script {// ...}    }  }  post {    success {      script {notify.DingTalkNotify(&quot;2kjdkj2jfk32ll&quot;,&quot;${JOB_NAME}&quot;, &quot; 构建成功 ✅&quot;, &quot;master&quot;)      }    }    failure {      script {notify.DingTalkNotify(&quot;2kjdkj2jfk32ll&quot;,&quot;${JOB_NAME}&quot;, &quot; 构建失败 ❌&quot;, &quot;master&quot;)      }    }  }}</code></pre></li><li><p> 邮件 </p><pre><code class="groovy">#!groovy@Library(&#39;shared-lib&#39;) _def notify = new org.devops.notify()pipeline {  stages {stage(&#39;Notification&#39;) {      script {// ...}    }  }  post {    success {      script {tool.MailNotify(&quot;727474430@qq.com&quot;, &quot; 构建成功 ✅&quot;)      }    }    failure {      script {tool.MailNotify(&quot;727474430@qq.com&quot;, &quot; 构建失败 ❌&quot;)      }    }  }}</code></pre></li></ul><center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/ding-success.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        构建成功    </div></center><center>  <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/ding-error.png">  <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">        构建失败    </div></center>]]></content>
    
    
    <categories>
      
      <category>DevOps</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>JenkinsPipeline</title>
    <link href="/2020/05/23/JenkinsPipeline/"/>
    <url>/2020/05/23/JenkinsPipeline/</url>
    
    <content type="html"><![CDATA[<center><p style="font-size:30px;color:black"> Jenkins Pipeline </p></center><a id="more"></a><h3 id="介绍"><a href="# 介绍" class="headerlink" title="介绍"></a> 介绍 </h3><p>  &ensp;&ensp;Jenkins Pipeline（或简称为“ Pipeline”，以大写字母“ P”表示）是一套插件，是 Jenkins 2.0 的核心特性，可支持将持续交付过程中的多个步骤集成到 Jenkins 中。</p><p>  &ensp;&ensp; 从根本上说，Jenkins 是一个支持多种自动化模式的自动化引擎。Pipeline 为 Jenkins 添加了一组强大的自动化工具，支持从简单的 CI 到全面的 CD 管道的用例。通过对一系列相关任务进行建模，用户可以利用管道的许多特性。实现了构建步骤代码化、结构化、构建过程视图化的能力。</p><p><strong>Code</strong>: 代码性，Pipeline 是用代码实现的，通常会集成到源代码管理中（版本管理），从而使团队能够编辑，查看和迭代其交付流水线。</p><p><strong>Durable</strong>: 持久性，Pipeline 可以在 Jenkins master 的计划重启和计划外重启中存活。</p><p><strong>Pausable</strong>：暂停性，Pipeline 可以选择停止并等待人工输入或批准，然后再继续管道运行。</p><p><strong>Versatile</strong>: 多样性，Pipelines 支持复杂的真实 CD 需求, 包括分支、级联、循环、并行执行等。</p><p><strong>Extensible</strong>: 扩展性，Pipeline 插件支持对 DSL 自定义扩展，以及与其他插件集成实现复杂功能的能力。</p><blockquote><p> 官方介绍：<a href="https://www.jenkins.io/doc/book/pipeline/" target="_blank" rel="noopener">https://www.jenkins.io/doc/book/pipeline/</a></p></blockquote><h3 id="概念"><a href="# 概念" class="headerlink" title="概念"></a> 概念 </h3><p>  &ensp;&ensp; 以下概念是 Jenkins Pipeline 的关键，它们与 Pipeline 语法紧密相关。</p><p><strong>Pipeline</strong>：一个 Pipeline 对应一个用户定义的 CD 模型。Pipeline 的代码描述了整个构建过程，通常包括构建、测试、验证、交付等阶段。</p><p><strong>Node</strong>：一个 Node 对应一个 Jenkins 集群环境中的一个节点，它能够执行 Pipeline 定义的描述。</p><p><strong>Stage</strong>：一个 Stage 块对应描述了在 Pipeline 中不同的任务子集（阶段），例如构建、测试、部署 Stages。</p><p><strong>Step</strong>：一个 Step 对应一个步骤，它告诉 Jenkins 在某个特定时间点应该作什么。例如执行 shell 命令，执行 mvn 命令等。</p><blockquote><p> 官方介绍：<a href="https://www.jenkins.io/doc/book/pipeline/#pipeline" target="_blank" rel="noopener">https://www.jenkins.io/doc/book/pipeline/#pipeline</a></p></blockquote><h3 id="语法"><a href="# 语法" class="headerlink" title="语法"></a> 语法 </h3><p>  &ensp;&ensp;Jenkins Declarative Pipeline 代码块一般定义在名为 Jenkinsfile 的文件中。</p><pre><code class="groovy">pipeline {  agent any // 1  stages {stage(&#39;Build&#39;) { // 2          steps {              // 3              sh &#39;echo build&#39;          }      }      stage(&#39;Test&#39;) { // 4          steps {              // 5              sh &#39;echo test&#39;          }      }      stage(&#39;Deploy&#39;) { // 6          steps {              // 7              sh &#39;echo deploy&#39;          }      }  }}</code></pre><ol><li><p> 在任何可用的 agent 节点上执行 Piepline 定义的描述。</p></li><li><p> 定义”构建”阶段。</p></li><li><p> 执行与”构建”相关的一些步骤。</p></li><li><p> 定义”测试”阶段。</p></li><li><p> 执行与”测试”相关的一些步骤。</p></li><li><p> 定义”发布”阶段 </p></li><li><p> 执行与”发布”相关的一些步骤。</p><p>&ensp;&ensp;Pipeline post：Jenkins Pipeline 支持使用 Post 在执行执行结束后的各种结果状态中进行定义操作。</p></li></ol><pre><code class="groovy">pipeline {  agent any  stages {stage(&#39;Test&#39;) {          steps {...}      }  }  post {always { // 1}      success {// 2}      failure {// 3}      unstable {// 4}      changed {// 5}      aborted {// 6}  }}</code></pre><ol><li> 构建结束后，结果无论是什么状态，总会执行该代码块中的内容。</li><li> 构建结束后，结果是成功状态时执行该代码块中的内容。</li><li> 构建结束后，结果是失败状态时，执行该代码块中的内容。</li><li> 构建结束后，结果是不稳定状态时，执行该代码块的内容。</li><li> 构建结束后，结果运行状态与之前的状态不同时，执行该代码块的内容。</li><li> 构建结束后，结果是终止状态时，执行该代码块中的内容。</li></ol><h3 id="指令"><a href="# 指令" class="headerlink" title="指令"></a> 指令 </h3><p><strong>environment</strong>：环境变量，一系列键值对，定义在 steps 外将对所有 step 可见，定义在 step 内仅对该 step 可见。该指令支持一种特殊的方法 credentials()，可以通过其在 Jenkins 环境中的标识符来访问预定义的凭据。</p><pre><code class="groovy">pipeline {  agent any  environment {JAVA_HOME = &quot;/usr/local/java&quot; // 全局变量}  stages {stage(&quot; 构建 &quot;) {          environment {NAME = &quot;Raindrop&quot; // 只在 Stage 中生效}          steps {              sh &#39;echo &quot;Hello $NAME&quot;&#39;              sh &#39;echo &quot;Java_HOME $JAVA_HOME&quot;&#39;          }      }      stage(&quot; 扫描 &quot;) {          environment {NAME = &quot;Tom&quot; // 只在 Stage 中生效}          steps {              sh &#39;echo &quot;Hello $NAME&quot;&#39;              sh &#39;echo &quot;Java_HOME $JAVA_HOME&quot;&#39;          }      }  }}</code></pre><p><strong>options</strong>：选项，Pipeline 内置了很多选项，用于在构建阶段中进行功能强化。例如 timestamps、buildDiscarder 等。</p><pre><code class="groovy">pipeline {  agent any  // 定义管道特殊选项  options {skipDefaultCheckout() // 忽略 checkout 步骤      timeout(time: 1, unit: &#39;HOURS&#39;) // 设置管道执行超时时间      retry(3) // 设置管道失败重试次数      timestamps() // 控制台输出时，显示时间戳}  stages {stage(&quot;Example&quot;) {          steps {echo &quot;Hello pipeline！&quot;}      }  }}</code></pre><p><strong>parameters</strong>：参数，在触发 Pipeline 时可用的参数列表。参数列表中的值可以通过 params 对象获取。</p><pre><code class="groovy">pipeline {  agent any  parameters {      // 字符串参数      string(name: &#39;PERSON&#39;, defaultValue: &#39;Mr Jenkins&#39;, description: &#39;This is string param&#39;)      // 布尔值参数      booleanParam(name: &#39;DEBUG&#39;, defaultValue: true, description: &#39;This is boolean param&#39;)      // 选择参数      choice(name: &#39;ENV_TYPE&#39;, choices: [&#39;test&#39;, &#39;dev&#39;, &#39;prod&#39;], description: &#39;This is choice param&#39;)      // 文件参数      file(name: &#39;FILE_NAME&#39;, description: &#39;This is file param&#39;)      // 密码参数      password(name: &#39;PASSWORD&#39;, defaultValue: &#39;123456&#39;, description: &#39;This is password param&#39;)  }  stages {stage(&quot; 字符串参数 &quot;) {          steps {              script {echo &quot;String param ${params.PERSON}&quot;              }          }      }      stage(&quot; 布尔值参数 &quot;) {          steps {              script {echo &quot;Boolean param ${params.DEBUG}&quot;              }          }      }      stage(&quot; 选择参数 &quot;) {          steps {              script {echo &quot;Choice param ${params.ENV_TYPE}&quot;              }          }      }      stage(&quot; 文件参数 &quot;) {          steps {              script {echo &quot;File param ${params.FILE_NAME}&quot;              }          }      }      stage(&quot; 密码参数 &quot;) {          steps {              script {echo &quot;Password param ${params.PASSWORD}&quot;              }          }      }  }}</code></pre><p><strong>triggers</strong>：触发器，定义了 Pipeline 自动化的触发方式。目前支持 cron、pollSCM 两种触发器，都是定时方式的实现。</p><pre><code class="groovy">pipeline {  agent any  // 触发器：  // 如果使用的是 Gitlab、Github 等，有 webhook 功能的版本管理库，则可以不用使用。  // 如果使用的是 Svn 就可以使用 Cron/PollSCM 两种方式触发。  triggers {cron(&#39;H 4/* 0 0 1-5&#39;) // linux 语法      pollSCM(&#39;H 4/* 0 0 1-5&#39;) // Jenkins 语法  }  stages {stage(&quot;Example&quot;) {          steps {echo &quot;Hello pipeline！&quot;}      }  }}</code></pre><p><strong>tools</strong>：工具，通过 tools 可以自动安装工具，并配置到环境变量 PATH 中。如果 agent none 则忽略。</p><pre><code class="groovy">pipeline {    agent any    tools {        // 工具名称必须在 Jenkins 管理 Jenkins → 全局工具配置中预配置。        maven &#39;apache-maven-3&#39;        java &#39;jdk8&#39;    }    stages {stage(&#39;Example&#39;) {            steps {                sh &#39;mvn -version&#39;                sh &#39;java -version&#39;            }        }    }}</code></pre><p><strong>when</strong>：分支判断，根据给定的条件判断是否执行该阶段任务。when 指令至少包含一个条件。如果 when 指令包含多个条件，则所有条件都为 true 时才会执行该阶段。</p><pre><code class="groovy">pipeline {    agent any    environment {ROLE_NAME = &#39;ADMIN&#39;}    stages {stage(&#39; 初始化 &#39;) {            steps {                script {                    BRANCH_NAME = &#39;trunk&#39;                    SUBMITTER = &quot;admin&quot;                }            }        }        stage(&#39; 分支判断 &#39;) {            when {branch &#39;trunk&#39;}            steps {echo &quot;trunk 分支部署 &quot;}        }        stage(&#39; 变量判断 &#39;) {            when {                environment name: &#39;ROLE_NAME&#39;,                        value: &#39;ADMIN&#39;            }            steps {echo &quot; 角色为 ADMIN&quot;}        }        stage(&#39; 表达式判断 &#39;) {            when {                expression {return true}            }            steps {echo &quot; 表达式为 true&quot;}        }        stage(&#39; 为真判断 &#39;) {            when {                equals expected: &#39;admin&#39;,                        actual: SUBMITTER            }            steps {echo &quot; 条件为真 &quot;}        }        stage(&#39; 为假判断 &#39;) {            when {                not {branch &#39;dev&#39;}            }            steps {echo &quot; 条件为假 &quot;}        }        stage(&#39; 全部为真判断 &#39;) {            when {                allOf {equals expected: &#39;admin&#39;, actual: SUBMITTER; environment name: &#39;ROLE_NAME&#39;, value: &#39;ADMIN&#39;}            }            steps {echo &quot; 全部条件为真 &quot;}        }        stage(&#39; 任意为真判断 &#39;) {            when {                anyOf {equals expected: &#39;admin&#39;, actual: SUBMITTER; environment name: &#39;ROLE&#39;, value: &#39;ADMINA&#39;}            }            steps {echo &quot; 任意条件为真 &quot;}        }    }}</code></pre><p><strong>parallel</strong>：并行，对耗时较长，相互不存在依赖关系的 stage 可以使用此方式提升执行效率。</p><pre><code class="groovy">pipeline {    agent any    stages {stage(&#39;Non-Parallel&#39;) {            steps {echo &#39;Non-Parallel&#39;}        }        stage(&#39;Parallel Stage&#39;) { // 一个 stage 只能有一个 steps 或者 parallel            failFast true // 并行的 job 中如果其中的一个失败，则终止其他并行的 stage            parallel { // parallel 不能包含 agent 或者 tools                stage(&#39;parallel stage 1&#39;) { // 嵌套的 stages 里不能使用 parallel                    steps {echo &quot;parallel stage 1&quot;}                }                stage(&#39;parallel stage 2&#39;) { // 嵌套的 stages 里不能使用 parallel                    steps {echo &quot;parallel stage 2&quot;}                }            }        }    }}</code></pre><p><strong>if-else</strong>：分支，当满足条件是执行 if 代码块，否则执行 else 代码块。</p><pre><code class="groovy">pipeline {    agent any    environment {NAME = &quot;Tom&quot;}    stages {stage(&#39;Case&#39;) {            steps {                script {if (&quot;$NAME&quot; == &quot;Tom&quot;) {echo &quot;true&quot;} else {echo &quot;false&quot;}                }            }        }        stage(&#39;Not-Case&#39;) {            steps {                script {if (&quot;$NAME&quot; == &quot;LiLi&quot;) {echo &quot;true&quot;} else {echo &quot;false&quot;}                }            }        }    }}</code></pre><p><strong>input</strong>：用户输入，阻塞当前构建阶段，显示提示等待用户选择。只有接收到有效选择才会继续当前构建阶段。</p><pre><code class="groovy">/** * message * 这个 option 是必须的，这个 message 会在用户提交构建的页面显示，提示用户提交相关的 input 条件。 * id * 这个 id 是一个可选的 option，可以作为这个 input 的标记符，默认的标记符是这个 stage 的名称。 * ok * 这个 ok 也是一个可选的 option, 主要是在 ok 按钮上显示一些文本，在 input 表单里。 * submitter * 这个 submitter 也是一个可选的 option，里面可以写多个用户名称或者组名称，用逗号隔开。意思就是，只有这写名称的对应用户登陆 jenkins，才能提交这个 input 动作，如果不写，默认是任何人都可以提交 input。 * parameters * 这个也是一个可选的 option, 和我们前面学的 parameters 没有区别，就是定义一些参数的地方。 */// Inputpipeline {    agent any    stages {stage(&#39;Deploy Application&#39;) {            input {                message &quot; 是否发布应用？&quot;                ok &quot; 发布 &quot;                submitter &quot;admin&quot;            }            steps {echo &quot;Hello pipeline nice to meet you.&quot;}        }    }}</code></pre><p><strong>try-catch</strong>：异常捕获，对可能出现异常的代码块进行捕获，在出现异常时进行显示处理。</p><pre><code class="groovy">pipeline {    agent any    stages {stage(&#39;trycache&#39;) {            steps {                script {                    try {sh &#39;exit 1&#39;} catch (exc) {echo &quot;something failed $exc&quot;}                }            }        }    }}</code></pre><h3 id="Scripted-Pipeline"><a href="#Scripted-Pipeline" class="headerlink" title="Scripted Pipeline"></a>Scripted Pipeline</h3><p>  &ensp;&ensp;Scripted pipeline 是 Jenkins 提供的基于 Groovy 脚本进行 pipeline 描述的一种格式。Groovy 脚本不一定适合所有使用者，因此 Jenkins 创建了 Declarative pipeline（声明式），为编写 Jenkins 管道提供了一种更简单、更有主见的语法。但是不可否认，由于脚本化的 pipeline 是基于 groovy 的一种 DSL 语言，所以 Scripted pipeline 相较于 Declarative pipeline 为 Jenkins 用户提供了更巨大的灵活性和可扩展性。</p><p>  &ensp;&ensp;pipeline 脚本同其它脚本语言一样，从上至下顺序执行，它的流程控制取决于 Groovy 表达式，如 if/else 条件语句，举例如下：</p><pre><code class="groovy">node {    checkout scm // 代码检出    stage(&#39;Build&#39;) { // 构建阶段        docker.image(&#39;maven:3.3.3&#39;).inside {sh &#39;mvn --version&#39;}    }    stage(&#39;Deploy&#39;) { // 发布阶段        if (env.BRANCH_NAME == &#39;master&#39;) {echo &#39;Deploy master version.&#39;} else {echo &#39;Deploy other version.&#39;}    }}</code></pre><h3 id="高级特性"><a href="# 高级特性" class="headerlink" title="高级特性"></a> 高级特性 </h3><p><strong>notification</strong>：通知，利用 Jenkins 提供的插件机制，在 Pipeline 构建阶段进行制定通知。</p><pre><code class="groovy">pipeline {    agent any    stages {stage(&#39;Example&#39;) {...}    }    post {        always {            script {                // BUILD_USER 需要 user build vars plugin 插件支持                wrap([$class: &#39;BuildUser&#39;]) { // 邮件通知                    mail to: &quot;xxxxx@163.com&quot;, // 收件人地址                    subject: &quot;PineLine &#39;${JOB_NAME}&#39; (${BUILD_NUMBER}) result&quot;, // 主题                    body: &quot;${env.BUILD_USER}&#39;s Pineline &#39;${JOB_NAME}&#39; (${BUILD_NUMBER}) run success\n 请及时前往 ${env.BUILD_URL} 进行查看 &quot; // 内容                }            }        }    }}</code></pre><pre><code class="groovy">pipeline {    agent any    stages {stage(&#39;Example&#39;) {...}    }    post {        always {            script {                // 需要 DingTalk 插件支持                dingtalk(                        robot: &#39;robotid&#39;, // 机器人 ID                        type: &#39;LINK&#39;, // 消息类型                        title: &#39; 监控报警 &#39;, // 消息标题                        text: [&quot;msg&quot;], // 消息内容                        messageUrl: &quot;build_url&quot;, // 消息连接地址                        picUrl: &quot;image_url&quot; // 图片连接地址                )            }        }    }}</code></pre><p><strong> 注意 </strong>：以上邮件通知、钉钉通知都需要先在全局工具配置中进行对应配置，才可正常使用。</p><h3 id="项目示例"><a href="# 项目示例" class="headerlink" title="项目示例"></a> 项目示例 </h3><p>  &ensp;&ensp; 工单系统：</p><pre><code class="groovy">// 工单系统 Jenkinsfilepipeline {    agent any    parameters {string(name: &#39;svnUrl&#39;, defaultValue: &#39;https://10.28.1.160/svn/sourcecode/ticketSystem/code/branch/develop-1.0.0/ticket-system&#39;, description: &#39;SVN 代码路径 &#39;)        string(name: &#39;sonarParam&#39;, defaultValue: &#39;-Dsonar.projectKey=${JOB_NAME} -Dsonar.projectName=${JOB_NAME} -Dsonar.projectVersion=${v} -Dsonar.language=java -Dsonar.java.source=1.8 -Dsonar.sourceEncoding=UTF-8 -Dsonar.sources=src/main/java -Dsonar.java.binaries=target/classes -Dsonar.modules=ticket-system-backend,ticket-system-common&#39;, description: &#39;SonarQube 项目参数 &#39;)    }    environment {SONAR_HOME = tool &#39;SonarScanner4.2&#39; // 这里这个 tool 是直接根据名称，获取自动安装的插件的路径}    stages {stage(&quot; 拉取代码 &quot;) {            steps {                script {echo &quot;Checkout ticket system from svn, branch name: ${env.BRANCH_NAME}; job name: ${env.JOB_NAME}&quot;                    def scmVars = checkout([$class                : &#39;SubversionSCM&#39;,                                            additionalCredentials : [],                                            excludedCommitMessages: &#39;&#39;,                                            excludedRegions       : &#39;&#39;,                                            excludedRevprop       : &#39;&#39;,                                            excludedUsers         : &#39;&#39;,                                            filterChangelog       : false,                                            ignoreDirPropChanges  : false,                                            includedRegions       : &#39;&#39;,                                            locations             : [[cancelProcessOnExternalsFail: true,                                                                      credentialsId               : &#39;85475088-cf46-4bc1-a77e-70ae5fb65f8e&#39;,                                                                      depthOption                 : &#39;infinity&#39;,                                                                      ignoreExternalsOption       : true,                                                                      local                       : &#39;.&#39;,                                                                      remote                      : &#39;${svnUrl}&#39;]],                                            quietOperation        : true,                                            workspaceUpdater      : [$class: &#39;UpdateUpdater&#39;]])                    svnVersion = scmVars.SVN_REVISION                    echo &quot;Current svn version: ${svnVersion}&quot;                }            }        }        stage(&quot; 代码编译 &quot;) {            steps {                script {echo &quot;Compile ticket system code. branch name: ${env.BRANCH_NAME}; job name: ${env.JOB_NAME}&quot;                    sh &quot;mvn clean install&quot;                }            }        }        stage(&quot; 单元测试 &quot;) {            steps {                script {echo &quot;Unit test for ticket system. branch name: ${env.BRANCH_NAME}; job name: ${env.JOB_NAME}&quot;                    sh &quot;mvn test&quot;                }            }        }        stage(&quot; 扫描代码 &quot;) {            steps {echo &quot;Starting codeAnalyze with SonarQube... branch name: ${env.BRANCH_NAME}; job name: ${env.JOB_NAME}&quot;                withSonarQubeEnv(&quot;GroupamaSonar&quot;) {sh &quot;${SONAR_HOME}/bin/sonar-scanner ${sonarParam}&quot;                }                script {                    // 此处由于 SonarQube 响应较慢，需要叫上超时处理                    timeout(5) {                        // 利用 sonarqube webhook 通知 pipeline 代码扫描结果，未通过则 fail                        def qg = waitForQualityGate()                        if (qg.status != &#39;OK&#39;) {error &quot; 未通过 SonarQube 的代码检查，请及时修改! failure: ${qg.status}&quot;                        }                    }                }            }        }        stage(&quot; 构建代码 &quot;) {            steps {                script {echo &quot;Build ticket system code. branch name: ${env.BRANCH_NAME}; job name: ${env.JOB_NAME}&quot;                    sh &quot;mvn clean package -DskipTests&quot;                }            }        }        stage(&quot;Deploy Application&quot;) {            input {                message &quot; 是否发布应用？&quot;                ok &quot; 发布 &quot;                submitter &quot;admin&quot;            }            steps {                script {sh &quot;sshpass root@xxxxxx sh -c /app/deploy.sh&quot;}            }        }    }    post {        success {            script {def msg = &quot;【${JOB_NAME}】 项目打包成功，请及时处理！&quot;                def imageUrl = &quot;https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=1729441498,1472936606&amp;fm=26&amp;gp=1.jpg&quot;                // 需要 DingTalk 插件支持                dingtalk(                        robot: &#39;ff6ce1f1-589a-4243-8d81-a4391ae21102&#39;,                        type: &#39;LINK&#39;,                        title: &#39; 监控报警 &#39;,                        text: [&quot;${msg}&quot;],                        messageUrl: &quot;${BUILD_URL}&quot;,                        picUrl: &quot;${imageUrl}&quot;                )                println &quot; 构建成功！&quot;                currentBuild.description = &quot; 工单系统生产环境构建成功！&quot;            }        }        failure {            script {def msg = &quot;【${JOB_NAME}】项目打包失败，请及时处理！&quot;                def imageUrl = &quot;https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=1729441498,1472936606&amp;fm=26&amp;gp=0.jpg&quot;                // 需要 DingTalk 插件支持                dingtalk(                        robot: &#39;ff6ce1f1-589a-4243-8d81-a4391ae21102&#39;,                        type: &#39;LINK&#39;,                        title: &#39; 监控报警 &#39;,                        text: [&quot;${msg}&quot;],                        messageUrl: &quot;${BUILD_URL}&quot;,                        picUrl: &quot;${imageUrl}&quot;                )                println &quot; 构建失败！&quot;                currentBuild.description = &quot; 工单系统生产环境构建失败！&quot;            }        }        aborted {           script {def msg = &quot;【${JOB_NAME}】 项目打包终端，请及时处理！&quot;                def imageUrl = &quot;https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=1729441498,1472936606&amp;fm=26&amp;gp=2.jpg&quot;                // 需要 DingTalk 插件支持                dingtalk(                        robot: &#39;ff6ce1f1-589a-4243-8d81-a4391ae21102&#39;,                        type: &#39;LINK&#39;,                        title: &#39; 监控报警 &#39;,                        text: [&quot;${msg}&quot;],                        messageUrl: &quot;${BUILD_URL}&quot;,                        picUrl: &quot;${imageUrl}&quot;                )                println &quot; 构建中断，请联系相关服务人询问中断原因！&quot;                currentBuild.description = &quot; 工单系统生产环境构建中断！&quot;            }        }    }}</code></pre><h3 id="插件推荐"><a href="# 插件推荐" class="headerlink" title="插件推荐"></a> 插件推荐 </h3><p>  &ensp;&ensp; 在使用 Jenkins Pipeline 过程中，有很多插件支持我们的发布流程，常用的有如下插件，大家可以事情选择：</p><ol><li>Pipeline：Pipeline 流水线支持。</li><li>Blue Ocean：Pipeline 流水线美化插件。</li><li>SonarScanner：SonarQube 集成插件。</li><li>user build vars：Pipeline 中获取构建人时需要用到。</li><li>Sonar Quality Gates：SonarQube 扫描结果获取插件。</li><li>Pipeline：InputStep：Input 等待用户输出需要用到该插件。</li><li>Extended Choice Parameter：使用 Choice Parameter 参数选项时需要使用。</li></ol><h3 id="愿景"><a href="# 愿景" class="headerlink" title="愿景"></a> 愿景 </h3><p>  &ensp;&ensp; 我们使用 Jenkins Pipeline 流水线实现 CI/CD 的最终愿景是自动化重复性操作，并提升应该交付效率。流程如下图：<br>    <center><br>    <img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="http://qiniu.raindrop-wl.cn/JenkinsPiepline-log.jpg"><br>    <div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;"><br>          多团队 <br>        </div><br>    </center></p>]]></content>
    
    
    <categories>
      
      <category>DevOps</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>MemoryLeaker</title>
    <link href="/2020/04/14/MemoryLeaker/"/>
    <url>/2020/04/14/MemoryLeaker/</url>
    
    <content type="html"><![CDATA[<p><strong>MemoryLeaker</strong></p><a id="more"></a><h3 id="背景"><a href="# 背景" class="headerlink" title="背景"></a>背景 </h3><p> 内存溢出，对我们 Java 开发者来讲是一个熟悉又陌生对话题。熟悉是因为我们常常会在各大文章中看到该类问题对字眼，而陌生是因为我们在实际对工作中，<br>可能基本上没有遇到过内存溢出的问题，或者说遇到了也没有花时间去排查该问题。这次我们就来模拟一下应用程序代码问题，导致的内存溢出问题，并对该 <br> 问题进行排查，最终找到问题代码。</p><h3 id="应用"><a href="# 应用" class="headerlink" title="应用"></a>应用 </h3><p> 这里我们使用 SpringBoot 创建一个简单的应用，并故意写出一个会导致内存泄漏的代码，然后使用工具逐步定位问题，最终解决内存泄漏对相关问题。</p><h3 id="内存异常"><a href="# 内存异常" class="headerlink" title="内存异常"></a>内存异常 </h3><h3 id="排查问题"><a href="# 排查问题" class="headerlink" title="排查问题"></a> 排查问题 </h3><h4 id="步骤一"><a href="# 步骤一" class="headerlink" title="步骤一"></a> 步骤一 </h4><h4 id="步骤二"><a href="# 步骤二" class="headerlink" title="步骤二"></a> 步骤二 </h4><h4 id="步骤三"><a href="# 步骤三" class="headerlink" title="步骤三"></a> 步骤三 </h4><h4 id="步骤四"><a href="# 步骤四" class="headerlink" title="步骤四"></a> 步骤四 </h4><h4 id="步骤五"><a href="# 步骤五" class="headerlink" title="步骤五"></a> 步骤五 </h4><h4 id="步骤六"><a href="# 步骤六" class="headerlink" title="步骤六"></a> 步骤六 </h4><h3 id="总结"><a href="# 总结" class="headerlink" title="总结"></a> 总结 </h3><p> 当然生产中对问题不会这么容易排查，但是这次模拟内存溢出主要对目的是熟悉相关排查工具及熟悉处理流程，这些内容 <br> 对于内存溢出问题来讲是通用的。</p>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Nginx Ftp</title>
    <link href="/2020/04/12/Nginx%20Ftp/"/>
    <url>/2020/04/12/Nginx%20Ftp/</url>
    
    <content type="html"><![CDATA[<center> <font face="黑体" size="6">Nginx Ftp 搭建 </font> </center><a id="more"></a><h3 id="Centos-Nginx-Vsftpd- 搭建文件服务器"><a href="#Centos-Nginx-Vsftpd- 搭建文件服务器" class="headerlink" title="Centos Nginx Vsftpd 搭建文件服务器"></a>Centos Nginx Vsftpd 搭建文件服务器 </h3><ul><li> 本篇文章记录一下在工作中，使用 Nginx Vsftpd 搭建文件服务器的过程，以及文件索引美化的内容。<br> 环境如下：<br>Centos 7.2<br>Nginx 1.14<br>Ngx-Fancyindex 0.4.3</li></ul><h3 id="Setp-1"><a href="#Setp-1" class="headerlink" title="Setp 1"></a>Setp 1</h3><ul><li><p> 首先我们先来安装 Vsftpd 服务.</p><pre><code class="bash"># 使用 yum 安装$ yum -y install vsftpd# 创建 ftp 用户及密码$ useradd ftpadmin$ passwd ftpadmin# 防火墙开启 21 端口（ftp 默认 21 端口）$ vim /etc/sysconfig/iptables  # 新增规则 如图一  -A INPUT -m state --state NEW -m tcp -p tcp --dport 21 -j ACCEPT# 重启防火墙$ service iptables restart# 修改 Selinux，允许 ftp 外网访问# 查看状态 如图二，其他红色标识的两个选项需要改为 on$ getsebool -a | grep ftp# 修改 ftp 选项为 on$ setsebool -P allow_ftpd_full_access on$ setsebool -P ftp_home_dir on# 关闭 ftp 匿名访问 如图三$ vim /etc/vsftpd/vsftpd.conf  # 原为 anonymous_enable=NO  anonymous_enable=YES# 修改 ftp 所属用户为上面创建的用户 如图四$ vim /etc/vsftpd/vsftpd.conf  chown_username=ftpadmin# 设置 ftp 开机启动$ chkconfig vsftpd on# 重启 ftp 服务$ service vsftpd restart</code></pre></li><li><p> 图一:<br><img src="http://qiniu.raindrop-wl.cn/ftb-iptables.png" srcset="/img/loading.gif" alt="ftp-iptables"></p></li><li><p> 图二:<br><img src="http://qiniu.raindrop-wl.cn/ftp-selinux.png" srcset="/img/loading.gif" alt="ftp-selinux"></p></li><li><p> 图三:<br><img src="http://qiniu.raindrop-wl.cn/fts-anonymous.png" srcset="/img/loading.gif" alt="ftp-anonymous"></p></li><li><p> 图四:<br><img src="http://qiniu.raindrop-wl.cn/ftp-chown.png" srcset="/img/loading.gif" alt="ftp-chown"></p></li></ul><h3 id="Setp-2"><a href="#Setp-2" class="headerlink" title="Setp 2"></a>Setp 2</h3><ul><li><p>Nginx 安装 </p><pre><code class="bash"># 安装 c 依赖$ yum -y install gcc gcc-c++ autoconf automake make pcre-devel openssl openssl-devel# 解压 Nginx 并编译安装$ tar -zxvf nginx-1.4.0.tar.gz &amp;&amp; cd nginx-1.4.0$ ./configure \    --prefix=/usr/local/nginx \    --pid-path=/var/run/nginx/nginx.pid \    --lock-path=/var/lock/nginx.lock \    --error-log-path=/var/log/nginx/error.log \    --http-log-path=/var/log/nginx/access.log \    --with-http_gzip_static_module \    --http-client-body-temp-path=/var/temp/nginx/client \    --http-proxy-temp-path=/var/temp/nginx/proxy \    --http-fastcgi-temp-path=/var/temp/nginx/fastcgi \    --http-uwsgi-temp-path=/var/temp/nginx/uwsgi \    --http-scgi-temp-path=/var/temp/nginx/scgi \    --add-module=ngx-fancyindex-0.4.3  # 该模块用来美化 ftp 目录，在 github 上下载到 nginx-1.4.0 目录下即可 https://github.com/aperezdc/ngx-fancyindex$ make &amp;&amp; make install# 配置 nginx，将目录地址指向 ftp 目录位置，我们的目录为： /home/ftpuser$ vim /usr/local/nginx/conf/nginx.conf  location / {root /home/ftpuser;}# 重新加载 nginx，访问 http://localhost/ 即可看见文件目录了$ ./nginx -s reload</code></pre></li></ul><h3 id="Setp-3"><a href="#Setp-3" class="headerlink" title="Setp 3"></a>Setp 3</h3><ul><li><p> 下面我们将 Nginx 页面进行美化一下（现在的样子实在是有点不过关）</p><pre><code class="bash"># 下载 Nginx-Fancyindex-Theme，目前有两种主题比较好，地址如下，我们选择第一种# https://github.com/Naereen/Nginx-Fancyindex-Theme# https://github.com/TheInsomniac/Nginx-Fancyindex-Theme# 进入 nginx web 目录，并克隆项目$ cd nginx &amp;&amp; git clone https://github.com/Naereen/Nginx-Fancyindex-Theme# 修改 nginx 配置文件，导入样式文件 如图一$ vi conf/nginx.conf  include /home/weblogic/software/nginx-1.14/Nginx-Fancyindex-Theme/fancyindex.conf;# note：需要注意的是，我们需要把 Nginx-Fancyindex-Theme 目录全部拷贝一份到 ftp 根目录下，不然会报 404，如图二$ cp -R Nginx-Fancyindex-Theme /home/ftpuser# 重新加载 nginx 即可$ ./nginx -s reload</code></pre></li><li><p> 图一:<br><img src="http://qiniu.raindrop-wl.cn/ftp-theme.png" srcset="/img/loading.gif" alt="ftp-theme"></p></li><li><p> 图二:<br><img src="http://qiniu.raindrop-wl.cn/ftp-theme-path.png" srcset="/img/loading.gif" alt="ftp-theme-path"></p></li></ul><h3 id="Setp-4"><a href="#Setp-4" class="headerlink" title="Setp 4"></a>Setp 4</h3><ul><li><p> 我们来检查一下最终的效果，访问 <a href="http://localhost/" target="_blank" rel="noopener">http://localhost/</a> ，我们看到的内容会如下图一下，美观、大方、简洁、漂亮！</p><p><img src="http://qiniu.raindrop-wl.cn/ftp-over1.png" srcset="/img/loading.gif" alt="ftp-ftp-over1"></p><p><img src="http://qiniu.raindrop-wl.cn/ftp-over2.png" srcset="/img/loading.gif" alt="ftp-ftp-over2"></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Nginx</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>CAS</title>
    <link href="/2020/04/12/CAS/"/>
    <url>/2020/04/12/CAS/</url>
    
    <content type="html"><![CDATA[<p><strong>Compare And Swap</strong></p><a id="more"></a><h5 id="背景"><a href="# 背景" class="headerlink" title="背景"></a>背景</h5><p>Java 在 1.4 版本后，提供了 JUC 下面的很多并发工具类，我们常使用的如下：</p><ol><li>AtomicInteger</li><li>AtomicLong</li><li>AtmoicReference</li></ol><p>那么在使用这些原子工具类来确保并发安全的背后，究竟是什么操作，代替了原有的 Sync 重量锁操作呢？<strong>CAS Java Util Current</strong> 背后的男人。</p><h5 id="CAS- 概念"><a href="#CAS- 概念" class="headerlink" title="CAS 概念"></a>CAS 概念</h5><blockquote><p>Cas 是 Compare And Swap 的简称，他的出现主要是解决了并发操作时，使用 Sync 锁而产生的效率问题，同时他的实现也是乐观锁的一种方式。</p></blockquote><h5 id="L1- 缓存概念"><a href="#L1- 缓存概念" class="headerlink" title="L1 缓存概念"></a>L1 缓存概念</h5><blockquote><p>L1 缓存是为了提高线程每次直接从主内存读写变量的速度而开发的逻辑缓存单元，各线程 L1 中的数据是独享的。有些处理器还提供了 L2 工作缓存</p></blockquote><h5 id="并发问题"><a href="# 并发问题" class="headerlink" title="并发问题"></a>并发问题 </h5><p> 在没有 CAS 出现之前，我们在并发操作一个共享变量的时候，步骤如下：</p><blockquote><p>假设目前有两个线程（T1、T2），同时对内存中的共享变量 x 其值为 0 变量做 +1 操作</p></blockquote><ol><li>线程 T1 从主内存读取变量 x 值，同时将 x 加入到 L1 缓存</li><li>线程 T2 从主内存读取变量 x 值，同时将 x 加入到 L1 缓存</li><li>线程 T1 对 x 做 +1 操作，此时 x 值为 1，并将其写入到 L1 缓存中</li><li>线程 T2 对 x 做 +1 操作，此时 x 值为 1，并将其写入到 L1 缓存中</li><li>线程 T1 将 L1 缓存中的 x 写入到主内存（此时主内存的 x 值为 1）</li><li>线程 T2 将 L1 缓存中的 x 写入到主内存（此时主内存的 x 值为 1）</li></ol><blockquote><p>经过如上步骤我们发现，最终主内存中的 x 并不符合我们预期对值 2，而这就是并发安全问题。<br>解决上述问题，以往我们会对操作 x 的方法添加 Sync 关键字，使该方法加锁来解决此类问题。<br>但是锁的消耗是巨大的，为了这么小的一个改变，而对方法加锁，是不值得的。为此 CAS 诞生。</p></blockquote><h5 id="CAS- 解决方式"><a href="#CAS- 解决方式" class="headerlink" title="CAS 解决方式"></a>CAS 解决方式 </h5><p> 我们来看一下 CAS 如何解决上述问题:</p><blockquote><p>假设目前有两个线程（T1、T2），同时对内存中的共享变量 x 其值为 0 变量做 +1 操作</p></blockquote><ol><li>线程 T1 从主内存读取变量 x 值，同时将 x 加入到 L1 缓存</li><li>线程 T2 从主内存读取变量 x 值，同时将 x 加入到 L1 缓存</li><li>线程 T1 对 x 做 +1 操作，此时 x 值为 1，并将其写入到 L1 缓存中</li><li>线程 T2 对 x 做 +1 操作，此时 x 值为 1，并将其写入到 L1 缓存中</li><li>线程 T1 将 L1 缓存中的 x 写入到主内存，在写入之前会再次从主内存中拿到 x 的值，并与开始获取到的 x 值做对比，<br>发现相等，然后写入 x 值到主内存（此时主内存的 x 值为 1）</li><li>线程 T2 将 L1 缓存中的 x 写入到主内存，在写入之前会再次从主内存中拿到 x 的值，并与开始获取到的 x 值做对比,<br>发现不等，此时 T2 线程不会将 x 值写入到主内存，而是返回到第一步操作，读取主内存中 x 的值，并对其做 +1 操作，<br>然后再次判断主内存中当前 x 与开始获取到的 x 做对比（此时 x 为 1），直到相等后，然后写入 x 值到主内存（此时主内存的 x 值为 2）</li></ol><blockquote><p>以上便是 CAS 操作到步骤，在与之前线程直接将 x 值协会主内存中不同，CAS 此时会做一个对比，将开始获取到到 x 与当前 <br> 主内存的 x 做对比，如果一致则写入主内存，如果不一致则回到获取 x 值的步骤重新执行，直至 x 对比一致后写入主内存</p></blockquote><h5 id="CAS- 流程图如下"><a href="#CAS- 流程图如下" class="headerlink" title="CAS 流程图如下"></a>CAS 流程图如下 </h5><h5 id="ABA- 问题（对象引用）"><a href="#ABA- 问题（对象引用）" class="headerlink" title="ABA 问题（对象引用）"></a>ABA 问题（对象引用）</h5><h5 id="乐观锁"><a href="# 乐观锁" class="headerlink" title="乐观锁"></a> 乐观锁</h5>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Dockerfile 使用</title>
    <link href="/2020/04/12/Dockerfile/"/>
    <url>/2020/04/12/Dockerfile/</url>
    
    <content type="html"><![CDATA[<p><strong>Dockerfile</strong> 使用 </p><a id="more"></a><h5 id="Dockerfile- 常用命令"><a href="#Dockerfile- 常用命令" class="headerlink" title="Dockerfile 常用命令"></a>Dockerfile 常用命令 </h5><table><thead><tr><th align="center"> 命令 </th><th align="center"> 备注 </th><th align="center"> 是否必填 </th></tr></thead><tbody><tr><td align="center">FROM</td><td align="center"> 基础镜像 </td><td align="center"> 必填 </td></tr><tr><td align="center">ADD</td><td align="center"> 拷贝文件到容器中（文件可以为 URL 链接）</td><td align="center"> 不必填 </td></tr><tr><td align="center">COPY</td><td align="center"> 拷贝文件到容器中（文件只能是本地文件）</td><td align="center"> 不必填 </td></tr><tr><td align="center">WORKDIR</td><td align="center"> 切换工作目录到指定目录 </td><td align="center"> 不必填 </td></tr><tr><td align="center">RUN</td><td align="center"> 镜像构建时运行脚本命令 </td><td align="center"> 不必填 </td></tr><tr><td align="center">CMD</td><td align="center"> 镜像构建后，启动容器时运行脚本命令 </td><td align="center"> 不必填 </td></tr><tr><td align="center">ENTRYPOINT</td><td align="center"> 镜像构建后，启动容器时运行脚本命令 </td><td align="center"> 不必填 </td></tr><tr><td align="center">ONBUILE</td><td align="center"> 在当前 Dockerfile 中不执行，在子镜像中会的 FROM 命令后执行 </td><td align="center"> 不必填 </td></tr><tr><td align="center">ENV</td><td align="center"> 设置环境变量，容器启动后依然存在 </td><td align="center"> 不必填 </td></tr><tr><td align="center">ARG</td><td align="center"> 设置变量参数，只在容器构建时存在 </td><td align="center"> 不必填 </td></tr><tr><td align="center">SHELL</td><td align="center"> 执行 SHELL 脚本 </td><td align="center"> 不必填 </td></tr><tr><td align="center">MAINTAINER</td><td align="center"> 维护人信息 </td><td align="center"> 不必填 </td></tr><tr><td align="center">LABEL</td><td align="center">key-value 形式标签，没有实质作用 </td><td align="center"> 不必填 </td></tr><tr><td align="center">EXPOSE</td><td align="center"> 暴露容器内端口 </td><td align="center"> 不必填 </td></tr><tr><td align="center">USER</td><td align="center">RUN、CMD、ENTRYPOINT 执行 Shell 命令时指定用户，默认 root</td><td align="center"> 不必填 </td></tr><tr><td align="center">VOLUME</td><td align="center"> 挂在主机目录到容器 </td><td align="center"> 不必填 </td></tr><tr><td align="center">HEALTHCHECK</td><td align="center"> 告诉 Docker 如何测试容器以检查它是否仍在工作，健康检查 </td><td align="center"> 不必填 </td></tr></tbody></table><h5 id="命令示例"><a href="# 命令示例" class="headerlink" title="命令示例"></a> 命令示例 </h5><ul><li><p><strong>FROM</strong></p><pre><code class="dockerfile"># Dockerfile 基于 centos 为基础镜像构建FROM centos</code></pre></li></ul><ul><li><p><strong>MAINTAINER</strong></p><pre><code class="dockerfile"># 维护者信息MAINTAINER Raindrop &lt;727474430@qq.com&gt;</code></pre></li></ul><ul><li><p><strong>LABEL</strong></p><pre><code class="dockerfile"># 标签，一般可用来替代 MAINTAINERLABEL maintainer=Raindrop email=727474430@qq.com</code></pre></li></ul><ul><li><p><strong>ARG</strong></p><pre><code class="dockerfile"># 环境变量，构建镜像时有效ARG SERVICE_NAME TomcatRUN echo $SERVICE_NAME# 可在构建时传入变量docker build -t --build-arg SERVICE_NAME=Weblogic .</code></pre></li></ul><ul><li><p><strong>ENV</strong></p><pre><code class="dockerfile"># 环境变量，容器启动后依然有效ENV JAVA_HOME /usr/local/jdk1.8RUN echo $JAVA_HOME</code></pre></li></ul><ul><li><p><strong>ADD</strong></p><pre><code class="dockerfile"># 拷贝文件到容器中，可拷贝网络资源ADD index.html /var/www/htmlADD https://www.baidu.com/index.html /var/www/html</code></pre></li></ul><ul><li><p><strong>COPY</strong></p><pre><code class="dockerfile"># 拷贝文件到容器中，只能拷贝本地资源，不拷贝网络资源时，建议使用COPY index.html /var/www/htmlCOPY app.jar /app</code></pre></li></ul><ul><li><p><strong>WORKDIR</strong></p><pre><code class="dockerfile"># 切入工作目录，类似 cdWORKDIR /appWORKDIR /tomcat</code></pre></li></ul><ul><li><p><strong>RUN</strong></p><pre><code class="dockerfile"># 构建镜像时执行的 shellRUN [&quot;yum&quot;, &quot;install&quot;, &quot;httpd&quot;]RUN yum install httpd</code></pre></li></ul><ul><li><p><strong>CMD</strong></p><pre><code class="dockerfile"># 启动容器时执行的 shellCMD [&quot;-C&quot;, &quot;/run.sh&quot;]CMD [&quot;/usr/sbin/sshd&quot;, &quot;-D&quot;]CMD /usr/sbin/sshd -D</code></pre></li></ul><ul><li><p><strong>ENTRYPOINT</strong></p><pre><code class="dockerfile"># 启动容器时执行的 shell，同 CMD 类似，只是由 ENTRYPOINT 启动的程序不会被 docker run 命令行指定的参数所覆盖，而且，这些命令行参数会被当作参数传递给 ENTRYPOINT 指定指定的程序ENTRYPOINT [&quot;/bin/bash&quot;, &quot;-C&quot;, &quot;/start.sh&quot;]ENTRYPOINT /bin/bash -C &#39;/start.sh&#39;</code></pre></li></ul><ul><li><p><strong>EXPOSE</strong></p><pre><code class="dockerfile"># 暴露端口EXPOSE 80 443</code></pre></li></ul><ul><li><p><strong>USER</strong></p><pre><code class="dockerfile"># RUN、CMD、ENTRYPOINT 执行 shell 命令指定用户，默认 rootUSER &lt;user&gt;[:&lt;usergroup&gt;]USER &lt;UID&gt;[:&lt;UID&gt;]USER weblogic:weblogic</code></pre></li></ul><ul><li><p><strong>VOLUME</strong></p><pre><code class="dockerfile"># 挂载容器目录之本地VOLUME [&quot;/var/lib/mysql&quot;]VOLUME /usr/lib/mysql /var/lib/mysql</code></pre></li></ul><ul><li><p><strong>ONBUILE</strong></p><pre><code class="dockerfile"># 子容器 FROM 后执行，通常用于构建基础镜像时预先添加内容，在子镜像中依赖，以减轻镜像容量FROM alpineONBUILD ENV APP_NAME=TomcatCMD echo $APP_NAMEdocker build -t test .---# 若不指定 CMD 和 ENTRYPOINT 默认执行父镜像指令，若父镜像也没有 CMD 和 ENTRYPOINT 则报错FROM test</code></pre></li></ul><ul><li><p><strong>HEALTHCHECK</strong></p><pre><code class="dockerfile"># 健康检查HEALTHCHECK --interval=5m --timeout=3s --retries=3 \    CMD curl -f http:/localhost/ || exit 1# 含义-- interval=DURATION (default: 30s)：每隔多长时间探测一次，默认 30 秒-- timeout= DURATION (default: 30s)：服务响应超时时长，默认 30 秒-- start-period= DURATION (default: 0s)：服务启动多久后开始探测，默认 0 秒-- retries=N (default: 3)：认为检测失败几次为宕机，默认 3 次# 一些返回值的说明：0：容器成功是健康的，随时可以使用1：不健康的容器无法正常工作2：保留不使用此退出代码 </code></pre></li></ul><h5 id="Dockerfile 示例"><a href="#Dockerfile 示例" class="headerlink" title="Dockerfile 示例"></a>Dockerfile 示例 </h5><ul><li><p> 构建 centos 镜像 </p><pre><code class="dockerfile"># 基础镜像FROM centos# 维护人信息MAINTAINER Raindrop &lt;727474430@qq.com&gt;# 构建时运行命令RUN yum -y update &amp;&amp; yum -y install httpd# 暴露 80 端口EXPOSE 80# 复制 index.html 到指定地址COPY index.html /var/www/html/index.html# 切换工作目录WORKDIR /var/www/html/index.html# 设置环境变量ENV SHELL_NAME=&quot;run.sh&quot;# 复制该脚本至镜像中，并修改其权限ADD $SHELL_NAME /run.shRUN chmod 775 /run.sh# 容器启动时执行脚本文件CMD [&quot;/run.sh&quot;]</code></pre></li></ul><div aligh="center">    <img src="http://qiniu.raindrop-wl.cn/Dockerfile.png" srcset="/img/loading.gif" width="100%"></div>]]></content>
    
    
    <categories>
      
      <category>docker</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Curl 常用命令</title>
    <link href="/2020/04/12/Curl/"/>
    <url>/2020/04/12/Curl/</url>
    
    <content type="html"><![CDATA[<p><strong>Curl</strong> 日常命令 </p><a id="more"></a><h5 id="参数列表"><a href="# 参数列表" class="headerlink" title="参数列表"></a> 参数列表 </h5><table><thead><tr><th> 参数 </th><th> 含义 </th><th> 用法 </th></tr></thead><tbody><tr><td>-s</td><td> 去掉进度条 </td><td>curl 127.0.0.1:80 -s</td></tr><tr><td>-o</td><td> 指定结果写入文件 </td><td>curl 127.0.0.1:80 -o curl.txt</td></tr><tr><td>-d</td><td> 指定参数 body</td><td>curl 127.0.0.1:80 -d ‘foo=bar’</td></tr><tr><td>-H</td><td> 指定请求头 </td><td>curl 127.0.0.1:80 -H ‘Content-Type:application/json’</td></tr><tr><td>-X</td><td> 指定请求方法 </td><td>curl 127.0.0.1:80 -X POST -H -H ‘Content-Type:application/json’ -d ‘{“foo”:”bar”}’</td></tr><tr><td></td><td></td><td></td></tr></tbody></table><h5 id="s"><a href="#s" class="headerlink" title="-s"></a>-s</h5><pre><code class="bash">$ curl https://www.baidu.com -o baidu.txt$ curl https://www.baidu.com -o baidu.txt -s</code></pre><div aligh="center">    <img src="http://qiniu.raindrop-wl.cn/curl-s.png" srcset="/img/loading.gif" width="100%"></div><h5 id="o"><a href="#o" class="headerlink" title="-o"></a>-o</h5><pre><code class="bash">$ curl https://www.baidu.com -o baidu.txt$ ll baidu.txt$ cat baidu.txt</code></pre><div aligh="center">    <img src="http://qiniu.raindrop-wl.cn/curl-o(1).png" srcset="/img/loading.gif" width="100%"></div><div aligh="center">    <img src="http://qiniu.raindrop-wl.cn/curl-o(2).png" srcset="/img/loading.gif" width="100%"></div><h5 id="d"><a href="#d" class="headerlink" title="-d"></a>-d</h5><pre><code class="bash">$ curl http://localhost:8888 -d &quot;age=18&quot;</code></pre><div aligh="center">    <img src="http://qiniu.raindrop-wl.cn/curl-d.png" srcset="/img/loading.gif" width="100%"></div><h5 id="H"><a href="#H" class="headerlink" title="-H"></a>-H</h5><pre><code class="bash">$ curl http://localhost:8888 -H &quot;Content-Type:application/json&quot;$ curl http://localhost:8888 -H &quot;foo:bar&quot;</code></pre><div aligh="center">    <img src="http://qiniu.raindrop-wl.cn/curl-h(1).png" srcset="/img/loading.gif" width="100%"></div><div aligh="center">    <img src="http://qiniu.raindrop-wl.cn/curl-h(2).png" srcset="/img/loading.gif" width="100%"></div><h5 id="X"><a href="#X" class="headerlink" title="-X"></a>-X</h5><pre><code class="bash">curl http://localhost:8888\?name\=wl -H &quot;Content-Type:application/json&quot; -X POST  -d &quot;{\&quot;age\&quot;:24}&quot;</code></pre><div aligh="center">    <img src="http://qiniu.raindrop-wl.cn/curl-x.png" srcset="/img/loading.gif" width="100%"></div>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Idea Plugin</title>
    <link href="/2020/04/09/Idea%20Plugin/"/>
    <url>/2020/04/09/Idea%20Plugin/</url>
    
    <content type="html"><![CDATA[<p><strong>Intellij Idea</strong> 插件推荐</p><a id="more"></a><h3 id="关于那些常用的 -Intellij-Idea- 插件推荐"><a href="# 关于那些常用的 -Intellij-Idea- 插件推荐" class="headerlink" title="关于那些常用的 Intellij Idea 插件推荐"></a>关于那些常用的 Intellij Idea 插件推荐</h3><ul><li>在我们日常开发过程中, 都难免或多或少有自己喜欢得一些插件, 有的可以提升我们的开发效率, 有的则可以美化我们的工作窗口, 今天笔者将推荐一些自己在开发过程中使用的插件, 当然是基于现在最流行的 Java 开发 Idea 而言.</li></ul><h3 id="进入正题"><a href="# 进入正题" class="headerlink" title="进入正题"></a>进入正题</h3><ul><li><p><strong>Translation</strong></p><p>首先推荐这个插件, 因为笔者英文不太好 (其实是很不好), 那么我就喜欢一款即时翻译得插件, 来帮助我在日常开发中随时翻译一些不懂得内容, 安装方式很简单, 在 Intellij 中依次选择 Preferences -&gt; Plugins -&gt; Search in repositories -&gt; 搜索 Translation 安装即可(其他插件一样), 插件使用得方式很简单, 只需要执行默认快捷键 “<strong>Alt + 1</strong>“ 就 OK 啦, 简直 easy 妈妈再也不用担心我们英文了！<br> 下面我们看一下使用效果:</p><p><img src="http://qiniu.raindrop-wl.cn/translation.png" srcset="/img/loading.gif" alt="img"></p></li><li><p><strong>Maven Helper</strong></p><p>日常工作中大部分项目都通过 Maven 来进行管理(当然现在也有很多基于 Gredle 开发的项目), 那就不得不提这个插件了. 这个插件可以将当前 Maven 项目的依赖树、依赖冲突、依赖列表帮我们完整的展示出来, 并且有很客观的呈现. 同时该插件提供了可以搜索得功能(简直完美)！下面我们看一下使用效果.</p><p><img src="http://qiniu.raindrop-wl.cn/maven.png" srcset="/img/loading.gif" alt="img"></p></li><li><p><strong>Grep Console</strong></p><p>该插件帮助我们将不同级别的日志用不同颜色标记起来.</p><p><img src="http://qiniu.raindrop-wl.cn/grep-console.png" srcset="/img/loading.gif" alt="img"></p></li><li><p><strong>ideaVim</strong></p><p>重度 Vim 使用人员离不开的插件, 在 Intellij 中下载次数也是摇摇领先, 喜欢 Vim 模式得同学们不要错过了！快捷键都是可以自定义的, 下面看一下自定义快捷键.</p><p><img src="http://qiniu.raindrop-wl.cn/ideavim.png" srcset="/img/loading.gif" alt="img"></p></li><li><p><strong>FindBugs-IDEA</strong></p><p>这个插件相信很多同学已经在 Eclipse 中接触过了, 当然 Idea 中同样提供了该插件帮助我们开发人员第一时间找到有漏洞得代码, 该插件提供了单独得插件窗口.</p><p><img src="http://qiniu.raindrop-wl.cn/findbugs.png" srcset="/img/loading.gif" alt="img"></p></li><li><p><strong>JRebel</strong></p><p>这个插件是一款热部署插件, 如果你得项目没有合适的热部署功能的话推荐你使用该插件, 配置简单使用简单, 当我们开启项目时只需要选择 JRebel 开启就行了.</p><p><img src="http://qiniu.raindrop-wl.cn/jrebel.png" srcset="/img/loading.gif" alt="img"></p></li><li><p><strong>BashSupport</strong></p><p>一款可以识别 shell 得插件, 让我们可以在 Idea 中轻松构建.sh 代码并且执行.</p><p><img src="http://qiniu.raindrop-wl.cn/bash.png" srcset="/img/loading.gif" alt="img"></p></li><li><p><strong>Markdown Navigator</strong></p><p>markdown 语法器插件, 通过该插件我们可以轻松的在 idea 中构建.md 文件, 并且使用 markdown 语法进行文件编写.</p><p><img src="http://qiniu.raindrop-wl.cn/markdown.png" srcset="/img/loading.gif" alt="img"></p></li><li><p><strong>Alibaba Cloud Toolkit</strong></p><p>阿里巴巴提供的 Idea 插件，可以链接阿里云 ECS、远程服务器、文件上传、部署 ECS 等等.</p><p><img src="http://qiniu.raindrop-wl.cn/alibaba-cloud.png" srcset="/img/loading.gif" alt="img"><br><img src="http://qiniu.raindrop-wl.cn/alibaba-cloud-01.png" srcset="/img/loading.gif" alt="img"></p></li><li><p><strong>ASM Bytecode Outline</strong></p><p>字节码展示插件</p><p><img src="http://qiniu.raindrop-wl.cn/ASM-bytecode.png" srcset="/img/loading.gif" alt="img"></p></li><li><p>好啦! 到这里笔者常用得 idea 插件已经贡献出来给大家了, 希望大家可以从中找到自己喜爱的插件并用于开发中. 感谢大家观看!</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Redis 分布式锁</title>
    <link href="/2020/03/26/Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
    <url>/2020/03/26/Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</url>
    
    <content type="html"><![CDATA[<center> <font face="黑体" size="6">Redis 分布式锁</font> </center><a id="more"></a><h3 id="背景"><a href="# 背景" class="headerlink" title="背景"></a>背景 </h3><p> 随着互联网应用从单体应用部署，到分布式部署，除了有好的方面外，随之而带来的问题也不断涌现。其中，最为重要的数据一致性问题，在分布式情况下并发对共享数据源进行写操作带来的数据 <br> 安全问题，都需要优先考虑在程序设计之中。<br>本次将从单体应用出发，到分布式集群部署，一步一步模拟在高并发程序下，不断涌现出的数据一致性问题，并对问题逐步解决的记录。</p><h5 id="环境"><a href="# 环境" class="headerlink" title="环境"></a>环境 </h5><p> 首先使用 SpringBoot 搭建一个基础的 Web 服务</p><p><code>pom.xml</code></p><pre><code class="xml">&lt;dependencies&gt;    &lt;!-- Web --&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;!-- Redis --&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;</code></pre><p><code>application.yml</code></p><pre><code class="yaml"># 端口server:  port: 8080spring:  application:    name: redis-lock  # 缓存配置  redis:    host: localhost    port: 6379    database: 0    password:</code></pre><hr><h5 id="无锁单节点"><a href="# 无锁单节点" class="headerlink" title="无锁单节点"></a>无锁单节点 </h5><p><code> 首先我们来看在单节点情况下，不使用锁进行资源保护，对订单接口进行并发访问带来对问题</code></p><pre><code class="java">@Slf4j@RestController@RequestMapping(&quot;/orders&quot;)public class OrderController {    public static final String ORDER_STOCK_KEY = &quot;order:stock&quot;;    @Autowired    private RedisTemplate&lt;String, String&gt; redisTemplate;    /**     * 创建订单，使用 Redis 模拟数据源     *     *     * @return     */    @GetMapping(&quot;/createOrder&quot;)    public String unsafeDeductOrder() {log.info(&quot; 开始创建订单...........&quot;);        String stockNum = redisTemplate.opsForValue().get(ORDER_STOCK_KEY);        if (StringUtils.isEmpty(stockNum)) {log.warn(&quot; 订单创建失败，库存不足！&quot;);            return &quot; 订单创建失败，库存不足！&quot;;        }        int stock = Integer.parseInt(stockNum);        if (stock &lt;= 0) {log.warn(&quot; 订单创建失败，库存不足！&quot;);            return &quot; 订单创建失败，库存不足！&quot;;        }        log.info(&quot; 扣减前库存数: {}&quot;, stock);        redisTemplate.opsForValue().set(ORDER_STOCK_KEY, String.valueOf(stock - 1));        log.info(&quot; 扣减后库存数: {}&quot;, redisTemplate.opsForValue().get(ORDER_STOCK_KEY));        log.info(&quot; 结束创建订单...........&quot;);        return &quot; 当前库存数：&quot; + redisTemplate.opsForValue().get(ORDER_STOCK_KEY);    }}</code></pre><p><code>初始化订单库存</code></p><pre><code class="bash">redis&gt; set order:stock 50OKredis&gt; get order:stock50</code></pre><p><code>使用 Jmeter 模拟 200 并发，对创建订单接口进行访问，如果程序正常，应该在创建 50 个订单后，返回库存不足</code></p><div aligh="center">    <img src="http://qiniu.raindrop-wl.cn/jmeter-200c.png" srcset="/img/loading.gif" width="100%"></div><div aligh="center">    <img src="http://qiniu.raindrop-wl.cn/jmeter-create-order.png" srcset="/img/loading.gif" width="100%"></div><p><code>查看结果，所有请求都成功了。但是我们可以看到日志中存在严重的重复扣减库存，这在真实环境是可怕的问题。同时查看最后一个请 求返回都结果，显示当前库存为 46 远比我们都预期差的多</code></p><pre><code class="java">2020-03-28 20:38:00.718  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 20:38:00.718  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 20:38:00.718  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 20:38:01.013  c.r.r.lock.controller.OrderController    : 扣减前库存数: 502020-03-28 20:38:01.013  c.r.r.lock.controller.OrderController    : 扣减前库存数: 502020-03-28 20:38:01.013  c.r.r.lock.controller.OrderController    : 扣减前库存数: 50......2020-03-28 20:38:01.168  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 20:38:01.158  c.r.r.lock.controller.OrderController    : 扣减后库存数: 492020-03-28 20:38:01.169  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 20:38:01.158  c.r.r.lock.controller.OrderController    : 扣减前库存数: 492020-03-28 20:38:01.169  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 20:38:01.158  c.r.r.lock.controller.OrderController    : 扣减前库存数: 49</code></pre><div aligh="center">    <img src="http://qiniu.raindrop-wl.cn/jmeter-result-01.png" srcset="/img/loading.gif" width="100%"></div><div aligh="center">    <img src="http://qiniu.raindrop-wl.cn/jmeter-result-tree-01.png" srcset="/img/loading.gif" width="100%"></div><hr><h5 id="Sync- 锁单节点"><a href="#Sync- 锁单节点" class="headerlink" title="Sync 锁单节点"></a>Sync 锁单节点 </h5><p><code> 在单体应用的情况下，我们可以通过使用锁的方式来避免上述问题。这里简单使用 synchronized 锁</code></p><pre><code class="java">@Slf4j@RestController@RequestMapping(&quot;/orders&quot;)public class OrderController {    public static final String ORDER_STOCK_KEY = &quot;order:stock&quot;;    @Autowired    private RedisTemplate&lt;String, String&gt; redisTemplate;    /**     * 创建订单，添加 synchronized 锁     *     * @return     */    @GetMapping(&quot;/createOrder&quot;)    public synchronized String unsafeDeductOrder() {log.info(&quot; 开始创建订单...........&quot;);        String stockNum = redisTemplate.opsForValue().get(ORDER_STOCK_KEY);        if (StringUtils.isEmpty(stockNum)) {log.warn(&quot; 订单创建失败，库存不足！&quot;);            return &quot; 订单创建失败，库存不足！&quot;;        }        int stock = Integer.parseInt(stockNum);        if (stock &lt;= 0) {log.warn(&quot; 订单创建失败，库存不足！&quot;);            return &quot; 订单创建失败，库存不足！&quot;;        }        log.info(&quot; 扣减前库存数: {}&quot;, stock);        redisTemplate.opsForValue().set(ORDER_STOCK_KEY, String.valueOf(stock - 1));        log.info(&quot; 扣减后库存数: {}&quot;, redisTemplate.opsForValue().get(ORDER_STOCK_KEY));        log.info(&quot; 结束创建订单...........&quot;);        return &quot; 当前库存数：&quot; + redisTemplate.opsForValue().get(ORDER_STOCK_KEY);    }}</code></pre><p><code>初始化订单库存</code></p><pre><code class="bash">redis&gt; set order:stock 50OKredis&gt; get order:stock50</code></pre><p><code>使用 Jmeter 模拟 200 并发，对创建订单接口进行访问，如果程序正常，应该在创建 50 个订单后，返回库存不足</code></p><div aligh="center">    <img src="http://qiniu.raindrop-wl.cn/jmeter-200c.png" srcset="/img/loading.gif" width="100%"></div><div aligh="center">    <img src="http://qiniu.raindrop-wl.cn/jmeter-create-order.png" srcset="/img/loading.gif" width="100%"></div><p><code>查看结果，所有请求都成功了。查看响应结果也正常，无重复扣减库存，在扣减了 50 个库存后，正常返回无库存</code></p><pre><code class="java">2020-03-28 20:26:56.227  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 20:26:56.461  c.r.r.lock.controller.OrderController    : 扣减前库存数: 502020-03-28 20:26:56.466  c.r.r.lock.controller.OrderController    : 扣减后库存数: 492020-03-28 20:26:56.467  c.r.r.lock.controller.OrderController    : 结束创建订单...........2020-03-28 20:26:56.469  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 20:26:56.471  c.r.r.lock.controller.OrderController    : 扣减前库存数: 492020-03-28 20:26:56.476  c.r.r.lock.controller.OrderController    : 扣减后库存数: 482020-03-28 20:26:56.476  c.r.r.lock.controller.OrderController    : 结束创建订单...........2020-03-28 20:26:56.478  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 20:26:56.480  c.r.r.lock.controller.OrderController    : 扣减前库存数: 482020-03-28 20:26:56.483  c.r.r.lock.controller.OrderController    : 扣减后库存数: 472020-03-28 20:26:56.484  c.r.r.lock.controller.OrderController    : 结束创建订单.................2020-03-28 20:26:56.831  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 20:26:56.833  c.r.r.lock.controller.OrderController    : 扣减前库存数: 22020-03-28 20:26:56.835  c.r.r.lock.controller.OrderController    : 扣减后库存数: 12020-03-28 20:26:56.836  c.r.r.lock.controller.OrderController    : 结束创建订单...........2020-03-28 20:26:56.837  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 20:26:56.839  c.r.r.lock.controller.OrderController    : 扣减前库存数: 12020-03-28 20:26:56.842  c.r.r.lock.controller.OrderController    : 扣减后库存数: 02020-03-28 20:26:56.842  c.r.r.lock.controller.OrderController    : 结束创建订单...........2020-03-28 20:26:56.843  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 20:26:56.845  c.r.r.lock.controller.OrderController    : 订单创建失败，库存不足！</code></pre><div aligh="center">    <img src="http://qiniu.raindrop-wl.cn/jmeter-result-02.png" srcset="/img/loading.gif" width="100%"></div><hr><h5 id="Sync- 锁多节点"><a href="#Sync- 锁多节点" class="headerlink" title="Sync 锁多节点"></a>Sync 锁多节点 </h5><p><code> 如上，在单节点部署情况下使用 synchronized 锁可以解决问题，那么我们再来看看多节点集群部署情况下，是否能正常运行</code></p><ul><li>启动 8080 端口应用</li></ul><pre><code class="yaml"># 端口server:  port: 8080</code></pre><ul><li>启动 8081 端口应用</li></ul><pre><code class="yaml"># 端口server:  port: 8081</code></pre><p><code>使用 Nginx 做负载，将流量分别打入两个应用</code></p><pre><code class="conf">upstream backend {    server localhost:8080;    server localhost:8081;}server {    listen 80;    server_name localhost;    location / {proxy_pass http://backend;}}</code></pre><p><code>初始化订单库存</code></p><pre><code class="bash">redis&gt; set order:stock 50OKredis&gt; get order:stock50</code></pre><p><code>使用 Jmeter 模拟 200 并发，访问 Nginx 入口，对两个节点进行负载均衡。如果程序正常，应该在创建 50 个订单后，返回库存不足</code></p><div aligh="center">    <img src="http://qiniu.raindrop-wl.cn/jmeter-200c.png" srcset="/img/loading.gif" width="100%"></div><div aligh="center">    <img src="http://qiniu.raindrop-wl.cn/jmeter-create-order-nginx.png" srcset="/img/loading.gif" width="100%"></div><p><code>查看结果，所有请求都成功了。查看响应结发现存在重复扣减库存情况</code></p><ul><li>8080 节点日志</li></ul><pre><code class="java">2020-03-28 21:00:03.203  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 21:00:03.260  c.r.r.lock.controller.OrderController    : 扣减前库存数: 502020-03-28 21:00:03.270  c.r.r.lock.controller.OrderController    : 扣减后库存数: 492020-03-28 21:00:03.271  c.r.r.lock.controller.OrderController    : 结束创建订单.................2020-03-28 21:00:03.684  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 21:00:03.688  c.r.r.lock.controller.OrderController    : 扣减前库存数: 262020-03-28 21:00:03.693  c.r.r.lock.controller.OrderController    : 扣减后库存数: 252020-03-28 21:00:03.693  c.r.r.lock.controller.OrderController    : 结束创建订单..............2020-03-28 21:00:04.162  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 21:00:04.164  c.r.r.lock.controller.OrderController    : 订单创建失败，库存不足！</code></pre><ul><li>8081 节点日志</li></ul><pre><code class="java">2020-03-28 21:00:03.203  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 21:00:03.264  c.r.r.lock.controller.OrderController    : 扣减前库存数: 502020-03-28 21:00:03.274  c.r.r.lock.controller.OrderController    : 扣减后库存数: 492020-03-28 21:00:03.274  c.r.r.lock.controller.OrderController    : 结束创建订单.................2020-03-28 21:00:03.687  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 21:00:03.690  c.r.r.lock.controller.OrderController    : 扣减前库存数: 262020-03-28 21:00:03.695  c.r.r.lock.controller.OrderController    : 扣减后库存数: 252020-03-28 21:00:03.695  c.r.r.lock.controller.OrderController    : 结束创建订单..............2020-03-28 21:00:04.162  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 21:00:04.164  c.r.r.lock.controller.OrderController    : 订单创建失败，库存不足！</code></pre><div aligh="center">    <img src="http://qiniu.raindrop-wl.cn/jmeter-result-02.png" srcset="/img/loading.gif" width="100%"></div><hr><h5 id="Redis-setnx- 多节点"><a href="#Redis-setnx- 多节点" class="headerlink" title="Redis.setnx 多节点"></a>Redis.setnx 多节点 </h5><p><code> 我们可以看到，当在分布式情况下 synchronized 锁就无能为力了，因为集群中当每个节点都是在单独的 jvm 中运行的， 所以 synchronized 只能在当前 jvm 下保证并发安全。我们可以使用 redis 提供的 setnx 命令进行加锁，来保证集群情况下的并发安全</code></p><blockquote><p>redis.setnx: 命令在指定的 key 不存在时，为 key 设置指定的值。如果指定的 key 存在，则不做任何操作。</p></blockquote><pre><code class="java">@Slf4j@RestController@RequestMapping(&quot;/orders&quot;)public class OrderController {    public static final String ORDER_STOCK_KEY = &quot;order:stock&quot;;    public static final String LOCK_KEY = &quot;lock:key&quot;;    public static final String LOCK_VALUE = &quot;lock:value&quot;;    @Autowired    private RedisTemplate&lt;String, String&gt; redisTemplate;    /**     * 创建订单     *     * @return     */    @GetMapping(&quot;/createOrder&quot;)    public String unsafeDeductOrder() {        // 这里使用 SpringBoot 提供的 setIfAbsent api 模拟 setnx 的效果        // 如果返回 true 表示获取锁成功，正常创建订单。否则失败，不做任何操作        Boolean flag = redisTemplate.opsForValue().setIfAbsent(LOCK_KEY, LOCK_VALUE);        if (!flag) {return &quot;&quot;;}        log.info(&quot; 开始创建订单...........&quot;);        String stockNum = redisTemplate.opsForValue().get(ORDER_STOCK_KEY);        if (StringUtils.isEmpty(stockNum)) {log.warn(&quot; 订单创建失败，库存不足！&quot;);            return &quot; 订单创建失败，库存不足！&quot;;        }        int stock = Integer.parseInt(stockNum);        if (stock &lt;= 0) {log.warn(&quot; 订单创建失败，库存不足！&quot;);            // 注意，如果库存已经没有了，需要释放掉锁，不然会造成死锁            redisTemplate.delete(LOCK_KEY);            return &quot; 订单创建失败，库存不足！&quot;;        }        log.info(&quot; 扣减前库存数: {}&quot;, stock);        redisTemplate.opsForValue().set(ORDER_STOCK_KEY, String.valueOf(stock - 1));        log.info(&quot; 扣减后库存数: {}&quot;, redisTemplate.opsForValue().get(ORDER_STOCK_KEY));        // 注意，在处理完业务后，需要释放掉锁，不然会造成死锁        redisTemplate.delete(LOCK_KEY);        log.info(&quot; 结束创建订单...........&quot;);        return &quot; 当前库存数：&quot; + redisTemplate.opsForValue().get(ORDER_STOCK_KEY);    }}</code></pre><ul><li>启动 8080 端口应用</li></ul><pre><code class="yaml"># 端口server:  port: 8080</code></pre><ul><li>启动 8081 端口应用</li></ul><pre><code class="yaml"># 端口server:  port: 8081</code></pre><p><code>使用 Jmeter 模拟 5s 1000 并发，对创建订单接口进行访问</code></p><div aligh="center">    <img src="http://qiniu.raindrop-wl.cn/jmeter-1000c.png" srcset="/img/loading.gif" width="100%"></div><p><code>查看结果，所有请求都成功了。查看响应结发现没有重复扣减库存情况，说明 redis.setnx 可以保证分布式下的并发安全问题</code></p><ul><li>8080 节点日志</li></ul><pre><code class="java">2020-03-28 21:56:59.285  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 21:56:59.297  c.r.r.lock.controller.OrderController    : 扣减前库存数: 472020-03-28 21:56:59.311  c.r.r.lock.controller.OrderController    : 扣减后库存数: 462020-03-28 21:56:59.318  c.r.r.lock.controller.OrderController    : 结束创建订单...........2020-03-28 21:56:59.421  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 21:56:59.443  c.r.r.lock.controller.OrderController    : 扣减前库存数: 452020-03-28 21:56:59.500  c.r.r.lock.controller.OrderController    : 扣减后库存数: 442020-03-28 21:56:59.528  c.r.r.lock.controller.OrderController    : 结束创建订单.................2020-03-28 21:57:02.157  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 21:57:02.159  c.r.r.lock.controller.OrderController    : 扣减前库存数: 32020-03-28 21:57:02.166  c.r.r.lock.controller.OrderController    : 扣减后库存数: 22020-03-28 21:57:02.170  c.r.r.lock.controller.OrderController    : 结束创建订单...........2020-03-28 21:57:02.177  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 21:57:02.180  c.r.r.lock.controller.OrderController    : 扣减前库存数: 22020-03-28 21:57:02.186  c.r.r.lock.controller.OrderController    : 扣减后库存数: 12020-03-28 21:57:02.189  c.r.r.lock.controller.OrderController    : 结束创建订单...........2020-03-28 21:57:02.206  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 21:57:02.210  c.r.r.lock.controller.OrderController    : 订单创建失败，库存不足！</code></pre><ul><li>8081 节点日志</li></ul><pre><code class="java">2020-03-28 21:56:59.135 c.r.r.lock.controller.OrderController : 开始创建订单...........2020-03-28 21:56:59.148 c.r.r.lock.controller.OrderController : 扣减前库存数: 502020-03-28 21:56:59.156 c.r.r.lock.controller.OrderController : 扣减后库存数: 492020-03-28 21:56:59.162 c.r.r.lock.controller.OrderController : 结束创建订单...........2020-03-28 21:56:59.194 c.r.r.lock.controller.OrderController : 开始创建订单...........2020-03-28 21:56:59.217 c.r.r.lock.controller.OrderController : 扣减前库存数: 492020-03-28 21:56:59.236 c.r.r.lock.controller.OrderController : 扣减后库存数: 482020-03-28 21:56:59.528 c.r.r.lock.controller.OrderController : 结束创建订单.................2020-03-28 21:57:02.124 c.r.r.lock.controller.OrderController : 开始创建订单...........2020-03-28 21:57:02.131 c.r.r.lock.controller.OrderController : 扣减前库存数: 52020-03-28 21:57:02.138 c.r.r.lock.controller.OrderController : 扣减后库存数: 42020-03-28 21:57:02.141 c.r.r.lock.controller.OrderController : 结束创建订单...........2020-03-28 21:57:02.191 c.r.r.lock.controller.OrderController : 开始创建订单...........2020-03-28 21:57:02.196 c.r.r.lock.controller.OrderController : 扣减前库存数: 12020-03-28 21:57:02.201 c.r.r.lock.controller.OrderController : 扣减后库存数: 02020-03-28 21:57:02.204 c.r.r.lock.controller.OrderController : 结束创建订单...........2020-03-28 21:57:02.206 c.r.r.lock.controller.OrderController : 开始创建订单...........2020-03-28 21:57:02.210 c.r.r.lock.controller.OrderController : 订单创建失败，库存不足！</code></pre><h5 id="Redis-setnx- 多节点 -finally"><a href="#Redis-setnx- 多节点 -finally" class="headerlink" title="Redis.setnx 多节点 finally"></a>Redis.setnx 多节点 finally</h5><p><code>虽然以上代码已经可以保证分布式下的并发安全，但是代码还存在这问题。假设我们的程序在创建订单的过程中出现异常，那么上述代码就会因为没有及时删除锁，而造成死锁。那么解决方法也比较简单，我们在 finally 块中删除锁，就可以了</code></p><pre><code class="java">@Slf4j@RestController@RequestMapping(&quot;/orders&quot;)public class OrderController {    public static final String ORDER_STOCK_KEY = &quot;order:stock&quot;;    public static final String LOCK_KEY = &quot;lock:key&quot;;    public static final String LOCK_VALUE = &quot;lock:value&quot;;    @Autowired    private RedisTemplate&lt;String, String&gt; redisTemplate;    /**     * 创建订单     *     * @return     */    @GetMapping(&quot;/createOrder&quot;)    public String unsafeDeductOrder() {        // 这里使用 SpringBoot 提供的 setIfAbsent api 模拟 setnx 的效果        // 如果返回 true 表示获取锁成功，正常创建订单。否则失败，不做任何操作        Boolean flag = redisTemplate.opsForValue().setIfAbsent(LOCK_KEY, LOCK_VALUE);        if (!flag) {return &quot;&quot;;}        log.info(&quot; 开始创建订单...........&quot;);        try {String stockNum = redisTemplate.opsForValue().get(ORDER_STOCK_KEY);            if (StringUtils.isEmpty(stockNum)) {log.warn(&quot; 订单创建失败，库存不足！&quot;);                return &quot; 订单创建失败，库存不足！&quot;;            }            int stock = Integer.parseInt(stockNum);            if (stock &lt;= 0) {log.warn(&quot; 订单创建失败，库存不足！&quot;);                return &quot; 订单创建失败，库存不足！&quot;;            }            log.info(&quot; 扣减前库存数: {}&quot;, stock);            redisTemplate.opsForValue().set(ORDER_STOCK_KEY, String.valueOf(stock - 1));            log.info(&quot; 扣减后库存数: {}&quot;, redisTemplate.opsForValue().get(ORDER_STOCK_KEY));        } catch (Exception e) {// do something} finally {            // 注意，在处理完业务后，需要释放掉锁，不然会造成死锁            redisTemplate.delete(LOCK_KEY);        }        log.info(&quot; 结束创建订单...........&quot;);        return &quot; 当前库存数：&quot; + redisTemplate.opsForValue().get(ORDER_STOCK_KEY);    }}</code></pre><hr><h5 id="Redis-setnx- 多节点 -expire- 非原子"><a href="#Redis-setnx- 多节点 -expire- 非原子" class="headerlink" title="Redis.setnx 多节点 expire 非原子"></a>Redis.setnx 多节点 expire 非原子 </h5><p><code> 上述代码已经保证了如果业务代码出现了异常，一样可以正常释放锁，来避免发生死锁。但是并没有完，如果程序运行程中服务器宕机了，那么如上代码还是会因为没有删除锁，而造成程序的死锁。那么我们可以给 setnx 的 key 设置一个 expire 过期时间，这样如果程序在运行中服务宕机了锁也会在 expire 过期时间到达后，进行删除锁</code></p><pre><code class="java">@Slf4j@RestController@RequestMapping(&quot;/orders&quot;)public class OrderController {    public static final String ORDER_STOCK_KEY = &quot;order:stock&quot;;    public static final String LOCK_KEY = &quot;lock:key&quot;;    public static final String LOCK_VALUE = &quot;lock:value&quot;;    @Autowired    private RedisTemplate&lt;String, String&gt; redisTemplate;    /**     * 创建订单     *     * @return     */    @GetMapping(&quot;/createOrder&quot;)    public String unsafeDeductOrder() {        // 这里使用 SpringBoot 提供的 setIfAbsent api 模拟 setnx 的效果        // 如果返回 true 表示获取锁成功，正常创建订单。否则失败，不做任何操作        Boolean flag = redisTemplate.opsForValue().setIfAbsent(LOCK_KEY, LOCK_VALUE);        if (!flag) {return &quot;&quot;;}        // 这里设置 5s 过期，当服务器宕机时 5s 后 redis 会自动删除锁        redisTemplate.expire(LOCK_KEY, 5, TimeUnit.SECONDS);        log.info(&quot; 开始创建订单...........&quot;);        try {String stockNum = redisTemplate.opsForValue().get(ORDER_STOCK_KEY);            if (StringUtils.isEmpty(stockNum)) {log.warn(&quot; 订单创建失败，库存不足！&quot;);                return &quot; 订单创建失败，库存不足！&quot;;            }            int stock = Integer.parseInt(stockNum);            if (stock &lt;= 0) {log.warn(&quot; 订单创建失败，库存不足！&quot;);                return &quot; 订单创建失败，库存不足！&quot;;            }            log.info(&quot; 扣减前库存数: {}&quot;, stock);            redisTemplate.opsForValue().set(ORDER_STOCK_KEY, String.valueOf(stock - 1));            log.info(&quot; 扣减后库存数: {}&quot;, redisTemplate.opsForValue().get(ORDER_STOCK_KEY));        } catch (Exception e) {// do something} finally {            // 注意，在处理完业务后，需要释放掉锁，不然会造成死锁            redisTemplate.delete(LOCK_KEY);        }        log.info(&quot; 结束创建订单...........&quot;);        return &quot; 当前库存数：&quot; + redisTemplate.opsForValue().get(ORDER_STOCK_KEY);    }}</code></pre><hr><h5 id="Redis-setnx- 多节点 -expire- 原子操作"><a href="#Redis-setnx- 多节点 -expire- 原子操作" class="headerlink" title="Redis.setnx 多节点 expire 原子操作"></a>Redis.setnx 多节点 expire 原子操作 </h5><p><code> 上述代码已经保证了如果服务器宕机，一样可以正常释放锁，来避免发生死锁。但是并没有完，如果服务器在 setnx 和 expire 代码中间宕机了，那么如上代码还是会因为没有删除锁，而造成程序的死锁。那么我们可以使用 setnx(key, value, timeout, unit) api 来保证获取锁和过期设置的原子性，来解决上述问题</code></p><pre><code class="java">@Slf4j@RestController@RequestMapping(&quot;/orders&quot;)public class OrderController {    public static final String ORDER_STOCK_KEY = &quot;order:stock&quot;;    public static final String LOCK_KEY = &quot;lock:key&quot;;    public static final String LOCK_VALUE = &quot;lock:value&quot;;    @Autowired    private RedisTemplate&lt;String, String&gt; redisTemplate;    /**     * 创建订单     *     * @return     */    @GetMapping(&quot;/createOrder&quot;)    public String unsafeDeductOrder() {        // 这里使用 SpringBoot 提供的 setIfAbsent api 模拟 setnx 的效果        // 如果返回 true 表示获取锁成功，正常创建订单。否则失败，不做任何操作        // 这里设置 5s 过期，当服务器宕机时 5s 后 redis 会自动删除锁，保证获取锁和过期设置的原子性        Boolean flag = redisTemplate.opsForValue().setIfAbsent(LOCK_KEY, LOCK_VALUE, 5, TimeUnit.SECONDS);        if (!flag) {return &quot;&quot;;}        log.info(&quot; 开始创建订单...........&quot;);        try {String stockNum = redisTemplate.opsForValue().get(ORDER_STOCK_KEY);            if (StringUtils.isEmpty(stockNum)) {log.warn(&quot; 订单创建失败，库存不足！&quot;);                return &quot; 订单创建失败，库存不足！&quot;;            }            int stock = Integer.parseInt(stockNum);            if (stock &lt;= 0) {log.warn(&quot; 订单创建失败，库存不足！&quot;);                return &quot; 订单创建失败，库存不足！&quot;;            }            log.info(&quot; 扣减前库存数: {}&quot;, stock);            redisTemplate.opsForValue().set(ORDER_STOCK_KEY, String.valueOf(stock - 1));            log.info(&quot; 扣减后库存数: {}&quot;, redisTemplate.opsForValue().get(ORDER_STOCK_KEY));        } catch (Exception e) {// do something} finally {            // 注意，在处理完业务后，需要释放掉锁，不然会造成死锁            redisTemplate.delete(LOCK_KEY);        }        log.info(&quot; 结束创建订单...........&quot;);        return &quot; 当前库存数：&quot; + redisTemplate.opsForValue().get(ORDER_STOCK_KEY);    }}</code></pre><hr><h5 id="Redis-setnx- 多节点 -expire- 原子操作超时程序未执行完，添加 -clientId-uuid- 判断，避免释放其他线程锁"><a href="#Redis-setnx- 多节点 -expire- 原子操作超时程序未执行完，添加 -clientId-uuid- 判断，避免释放其他线程锁" class="headerlink" title="Redis.setnx 多节点 expire 原子操作超时程序未执行完，添加 clientId (uuid) 判断，避免释放其他线程锁"></a>Redis.setnx 多节点 expire 原子操作超时程序未执行完，添加 clientId (uuid) 判断，避免释放其他线程锁 </h5><p><code> 上述代码在一般的程序中使用基本上已经没有问题了。但是我们做设计，必须要将场景考虑全。上面我们设置了过期时间为 5s，但是在实际的业务中我们无法确定超时时间设置多少才是正确的。那么问题就来了，假如有 A、B、C 三个线程并发执行创建订单，我们设置了过期时间为 5s，A 线程首先获取到锁，但是程序执行需要 10s，那么 A 线程还没有执行完业务时，锁已经被释放，此时线程 B 获取到锁，B 线程执行业务代码过程中 A 线程业务执行完成，A 线程会释放锁，注意此时 A 线程释放的锁其实是 B 线程的锁，这种情况下如果有多个线程，那么将有大部分的线程释放的锁是不属于自己的，这样的程序是有问题的。如何解决这样的问题呢？我们可以将 lock_value 设置为每个线程独有一个值，在释放锁时判断 lock_value 是否为当前线程所有，如果是则释放锁，如果不是则跳过。这样就可以解决 C 释放 B 、 B 释放 A 锁的问题了</code></p><blockquote><p>流程图如下:</p><div aligh="center">   <img src="http://qiniu.raindrop-wl.cn/Redis-lock.png" srcset="/img/loading.gif" width="100%"></div></blockquote><pre><code class="java">@Slf4j@RestController@RequestMapping(&quot;/orders&quot;)public class OrderController {    public static final String ORDER_STOCK_KEY = &quot;order:stock&quot;;    public static final String LOCK_KEY = &quot;lock:key&quot;;    @Autowired    private RedisTemplate&lt;String, String&gt; redisTemplate;    /**     * 创建订单     *     * @return     */    @GetMapping(&quot;/createOrder&quot;)    public String unsafeDeductOrder() {        // 当前线程 lock_value        String lockValue = UUID.randomUUID().toString();        // 这里使用 SpringBoot 提供的 setIfAbsent api 模拟 setnx 的效果        // 如果返回 true 表示获取锁成功，正常创建订单。否则失败，不做任何操作        // 这里设置 5s 过期，当服务器宕机时 5s 后 redis 会自动删除锁，保证获取锁和过期设置的原子性        Boolean flag = redisTemplate.opsForValue().setIfAbsent(LOCK_KEY, lockValue, 5, TimeUnit.SECONDS);        if (!flag) {return &quot;&quot;;}        log.info(&quot; 开始创建订单...........&quot;);        try {String stockNum = redisTemplate.opsForValue().get(ORDER_STOCK_KEY);            if (StringUtils.isEmpty(stockNum)) {log.warn(&quot; 订单创建失败，库存不足！&quot;);                return &quot; 订单创建失败，库存不足！&quot;;            }            int stock = Integer.parseInt(stockNum);            if (stock &lt;= 0) {log.warn(&quot; 订单创建失败，库存不足！&quot;);                return &quot; 订单创建失败，库存不足！&quot;;            }            log.info(&quot; 扣减前库存数: {}&quot;, stock);            redisTemplate.opsForValue().set(ORDER_STOCK_KEY, String.valueOf(stock - 1));            log.info(&quot; 扣减后库存数: {}&quot;, redisTemplate.opsForValue().get(ORDER_STOCK_KEY));        } catch (Exception e) {// do something} finally {            // 注意，在处理完业务后，需要释放掉锁，不然会造成死锁            // 如果是当前线程的锁，才进行释放            String value = redisTemplate.opsForValue().get(LOCK_KEY);            if (lockValue.equals(value)) {redisTemplate.delete(LOCK_KEY);            }        }        log.info(&quot; 结束创建订单...........&quot;);        return &quot; 当前库存数：&quot; + redisTemplate.opsForValue().get(ORDER_STOCK_KEY);    }}</code></pre><hr><h5 id="Redisson-Java-Client- 解决续租问题"><a href="#Redisson-Java-Client- 解决续租问题" class="headerlink" title="Redisson Java Client 解决续租问题"></a>Redisson Java Client 解决续租问题 </h5><p><code> 上述代码解决掉了线程之间释放锁错误的问题，刚刚提到的无法确定锁过期时间的问题依然存在。对于这个问题的解决方案，目前用的比较多的是 &#39; 续期 &#39; 方式。简单来说就是，启动一个后台线程，定时检查业务代码执行状态，如果到达过期时间业务依然没有执行完，那么就进行 &#39; 续期 &#39; 操作，将过期时间延长，直至业务代码执行完成后，正常释放锁。&#39; 续期 &#39; 操作实现起来还是相对麻烦，而且需要考虑的场景较多，那么目前为止 Redis 增强框架 Redisson 提供了较为完整的续期功能，所以大多数企业都会使用该框架进行分布式锁的使用</code></p><blockquote><p>Redisson: Redisson 是一个 Redis Java 客户端，具有内存数据网格的特性。<br>它提供了更方便和最简单的方式与 Redis 的工作。<br>Redisson 对象提供了关注点分离，这允许您将重点放在数据建模和应用程序逻辑上。</p><div aligh="center">   <img src="http://qiniu.raindrop-wl.cn/redisson-logo.png" srcset="/img/loading.gif" width="100%"></div></blockquote><ul><li>添加依赖</li></ul><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.redisson&lt;/groupId&gt;    &lt;artifactId&gt;redisson-spring-boot-starter&lt;/artifactId&gt;    &lt;version&gt;3.11.0&lt;/version&gt;&lt;/dependency&gt;</code></pre><ul><li>添加配置类</li></ul><pre><code class="java">@Configurationpublic class RedissonConfig {@Value(&quot;${spring.redis.host}&quot;)    private String host;    @Value(&quot;${spring.redis.port}&quot;)    private Integer port;    @Value(&quot;${spring.redis.database}&quot;)    private Integer database;    @Value(&quot;${spring.redis.password}&quot;)    private String password;    @Bean(destroyMethod = &quot;shutdown&quot;)    public RedissonClient redissonClient() {        // 使用单机 Redis        Config config = new Config();        SingleServerConfig serverConfig = config.useSingleServer();        serverConfig.setAddress(String.format(&quot;redis://%s:%s&quot;, host, port));        serverConfig.setTimeout(5000);        serverConfig.setDatabase(database);        serverConfig.setPassword(StringUtils.isEmpty(password) ? null : password);        return Redisson.create(config);    }</code></pre><ul><li>使用</li></ul><pre><code class="java">@Slf4j@RestController@RequestMapping(&quot;/orders&quot;)public class OrderController {    public static final String ORDER_STOCK_KEY = &quot;order:stock&quot;;    public static final String LOCK_KEY = &quot;lock:key&quot;;    @Autowired    private RedisTemplate&lt;String, String&gt; redisTemplate;    @Autowired    private RedissonClient redissonClient;    /**     * 创建订单     *     * @return     */    @GetMapping(&quot;/createOrder&quot;)    public String unsafeDeductOrder() {        // 获取并开启锁        RLock lock = redissonClient.getLock(LOCK_KEY);        lock.lock();        log.info(&quot; 开始创建订单...........&quot;);        try {String stockNum = redisTemplate.opsForValue().get(ORDER_STOCK_KEY);            if (StringUtils.isEmpty(stockNum)) {log.warn(&quot; 订单创建失败，库存不足！&quot;);                return &quot; 订单创建失败，库存不足！&quot;;            }            int stock = Integer.parseInt(stockNum);            if (stock &lt;= 0) {log.warn(&quot; 订单创建失败，库存不足！&quot;);                return &quot; 订单创建失败，库存不足！&quot;;            }            log.info(&quot; 扣减前库存数: {}&quot;, stock);            redisTemplate.opsForValue().set(ORDER_STOCK_KEY, String.valueOf(stock - 1));            log.info(&quot; 扣减后库存数: {}&quot;, redisTemplate.opsForValue().get(ORDER_STOCK_KEY));        } catch (Exception e) {// do something} finally {            // 释放锁            lock.unlock();}        log.info(&quot; 结束创建订单...........&quot;);        return &quot; 当前库存数：&quot; + redisTemplate.opsForValue().get(ORDER_STOCK_KEY);    }}</code></pre><hr><h5 id="总结"><a href="# 总结" class="headerlink" title="总结"></a>总结 </h5><p> 以上就是我们在分布式环境下，使用锁的各种坑及解决方案。在我们日常工作中，已经有前辈封装了非常好的框架供我们解决各类问题，但在使用的同时，我们一定要知道为什么需要这类框架来解决这类问题，问题的本质是什么，这样才能做到触类旁通。</p>]]></content>
    
    
    <categories>
      
      <category>Redis</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>MySQL 表锁</title>
    <link href="/2020/03/21/MySQL-Lock/"/>
    <url>/2020/03/21/MySQL-Lock/</url>
    
    <content type="html"><![CDATA[<center> <font face="黑体" size="6">MySQL 表锁</font> </center><hr><a id="more"></a><h5 id="MySQL- 表锁"><a href="#MySQL- 表锁" class="headerlink" title="MySQL 表锁"></a>MySQL 表锁</h5><p>MySQL 中提供了锁定表 <code>lock tables</code> 和解锁表 <code>unlock tables</code> 的法语，用来对指定对表进行锁定和解锁限制。</p><hr><h5 id="涉及命令"><a href="# 涉及命令" class="headerlink" title="涉及命令"></a>涉及命令</h5><table><thead><tr><th>命令</th><th>含义</th><th>常用</th></tr></thead><tbody><tr><td>select connection_id()</td><td>显示会话 id</td><td>select connection_id() 显示当前会话 id</td></tr><tr><td>show open tables</td><td>显示所有表占用锁的信息（包含全部表）</td><td>show open tables 显示所有表占用锁的信息（包含全部表）</td></tr><tr><td>show open tables where in_user &gt;= 1</td><td>显示所有表占用锁的信息（只包含已加锁的表）</td><td>显示所有表占用锁的信息（只包含已加锁的表）</td></tr><tr><td>lock table tableName1, tableName2… read</td><td>对指定表添加读锁（共享锁）</td><td>lock table user read 对 user 表添加读锁</td></tr><tr><td></td><td></td><td>lock table user, score read 对 user 与 score 表添加读锁</td></tr><tr><td>lock table tableName1, tableName2</td><td>对指定表添加写锁</td><td>lock table user write 对 user 表添加写锁</td></tr><tr><td></td><td></td><td>lock table user, score write 对 user 与 score 表添加写锁</td></tr><tr><td>unlock tables</td><td>对指定表进行解锁</td><td>unlock tables user 释放 user 表的锁</td></tr></tbody></table><hr><h5 id="示例"><a href="# 示例" class="headerlink" title="示例"></a>示例</h5><ul><li><code>lock table read</code> 锁表会将当前会话指定表进行锁定。限制当前会话只能查询该表，如果查询其他表则报错。如果对该表进行写操作也会报错。</li></ul><pre><code class="mysql">-- 查看当前会话 idselect connection_id();+-----------------+| connection_id() |+-----------------+|              64 |+-----------------+-- 使用读锁锁定 student 表lock table student read;Query OK, 0 rows affected (0.00 sec)-- 查看被锁住对表信息，如下表示 student 表被一个会话锁定（in_use = 1）show open tables where in_use &gt;= 1;+----------+---------+--------+-------------+| Database | Table   | In_use | Name_locked |+----------+---------+--------+-------------+| backup   | student |      1 |           0 |+----------+---------+--------+-------------+-- 查询带锁对表没问题select * from student;+--------+----------+| std_id | std_name |+--------+----------+|   1001 | zhangsan ||   1002 | lisi     ||   1003 | wangwu   |+--------+----------+-- 查询未锁定对表则报错select * from teacher;ERROR 1100 (HY000): Table &#39;teacher&#39; was not locked with LOCK TABLES-- 对锁定的表进行插入操作insert into student (std_id, std_name) values (1004, &#39;liuliu&#39;);ERROR 1100 (HY000): Table &#39;studentstudent&#39; was not locked with LOCK TABLES-- 对未锁定对表进行插入操作insert into teacher (teacher_id, teacher_name) values (1004, &#39;liuliu&#39;);ERROR 1100 (HY000): Table &#39;teacher&#39; was not locked with LOCK TABLES-- 再次执行锁表，之前的锁表将自动解锁lock table teacher read;Query OK, 0 rows affected (0.00 sec)-- 查看被锁住对表信息，如下表示 student 表被一个会话锁定（in_use = 1）show open tables where in_use &gt;= 1;+----------+---------+--------+-------------+| Database | Table   | In_use | Name_locked |+----------+---------+--------+-------------+| backup   | teacher |      1 |           0 |+----------+---------+--------+-------------+-- 客户端断开链接后，所有表锁将自动解锁, 重新链接后不再持有锁exit -- 断开链接mysql -uroot -p -- 再次链接show open tables where in_use &gt;= 1;Empty set (0.00 sec)</code></pre><hr><h5 id="注意点"><a href="# 注意点" class="headerlink" title="注意点"></a>注意点 </h5><p> 锁表获取方式：</p><blockquote><p>LOCK TABLES acquires locks as follows:<br>Sort all tables to be locked in an internally defined order. From the user standpoint, this order is undefined.<br>If a table is to be locked with a read and a write lock, put the write lock request before the read lock request.<br>Lock one table at a time until the session gets all locks.<br>This policy ensures that table locking is deadlock free.<br>LOCK TABLES acquires locks as follows:<br>Sort all tables to be locked in an internally defined order. From the user standpoint, this order is undefined.<br>If a table is to be locked with a read and a write lock, put the write lock request before the read lock request.<br>Lock one table at a time until the session gets all locks.<br>This policy ensures that table locking is deadlock free.<br>锁表获取锁的方式如下:<br>按照内部定义的顺序对所有要锁定的表进行排序。<br>从用户的角度来看，这个顺序是未定义的。<br>如果要用读锁和写锁锁定表，请将写锁请求放在读锁请求之前。<br>一次锁定一个表，直到会话获得所有锁。<br>此策略确保表锁定没有死锁。</p></blockquote><p>释放锁对条件：</p><blockquote><ul><li>当会话持有的表锁被释放时，它们都同时被释放会话可以显式地释放锁，也可以在某些条件下隐式地释放锁</li><li>可以使用 unlock tables 命令显示对释放锁</li><li>如果一个会话在已经持有锁的情况下发出一个 LOCK TABLES 命令再次获取锁，那么在授予新锁之前，MySQL 会将已经存在的锁隐式地解除</li><li>如果一个会话开始了一个事务(例如：start transaction)，就会执行一个隐式的 UNLOCK TABLES，从而释放现有的锁。</li><li>如果客户端会话的连接终止，无论是否正常，服务器都会隐式释放会话持有的所有表锁 (事务性和非事务性)。<br> 如果客户端重新连接，锁将不再有效。</li><li></li></ul></blockquote><p>关联锁表：</p><blockquote><p>lock table 命令可能会锁定比我们指定表更多对表。这是因为，如果表中有 trigger，那么 MySQL 为了让功能正常运行，<br>那么会将 trigger 中涉及对表一同 lock</p></blockquote><p><strong>note:</strong> 以上测试都是基于 InnoDB 引擎</p>]]></content>
    
    
    <categories>
      
      <category>MySQL</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>MySQL- 优化</title>
    <link href="/2020/03/18/MySQL-%E4%BC%98%E5%8C%96/"/>
    <url>/2020/03/18/MySQL-%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<center> <font face="黑体" size="6">MySQL- 优化</font> </center><hr><a id="more"></a><h5 id="MySQL-Count- 优化"><a href="#MySQL-Count- 优化" class="headerlink" title="MySQL Count 优化"></a>MySQL Count 优化 </h5><p> 从 user 表中查询 id 大于 10 的所以用户。InnoDB 存储引擎会进行逐行扫描，如果表中数据较多则会有性能问题</p><pre><code class="mysql">select count(*) from user where id &gt; 10;+----------+| count(*) |+----------+| 6597266  |+----------+1 row in setTime: 1.292s</code></pre><p>如果现将所有行数 count 出来，再见去 id &lt;= 10 的记录，速度就会快一些</p><pre><code class="mysql">select (select count(*) - (select count(*) from user where id &lt;= 10) from user) as count;+---------+| count   |+---------+| 6597266 |+---------+</code></pre><h5 id="MySQL-Limit- 优化"><a href="#MySQL-Limit- 优化" class="headerlink" title="MySQL Limit 优化"></a>MySQL Limit 优化</h5><p>limit 常用来进行分页，但是在偏移量很大的时候则会有性能问题</p><p>如下偏移量 100w 时，会先扫描 100w 数据后，在返回后面的 10 条记录，查询数据的效率会有所影响</p><pre><code class="mysql">select * from user order by id limit 1000000, 10;+---------+--------------+---------+| id      | name         | score   |+---------+--------------+---------+| 1000001 | user-999998  | 999998  || 1000002 | user-999999  | 999999  || 1000003 | user-1000000 | 1000000 || 1000004 | user-1000001 | 1000001 || 1000005 | user-1000002 | 1000002 || 1000006 | user-1000003 | 1000003 || 1000007 | user-1000004 | 1000004 || 1000008 | user-1000005 | 1000005 || 1000009 | user-1000006 | 1000006 || 1000010 | user-1000007 | 1000007 |+---------+--------------+---------+10 rows in setTime: 0.207s</code></pre><p>那么如果我们的 id 是自增或递增的，那么我们可以保存上次的偏移量，利用 id 的索引优势跳过前 100w 数据的扫描</p><pre><code class="mysql">select * from user where id &gt; 1000000 order by id limit 10;+---------+--------------+---------+| id      | name         | score   |+---------+--------------+---------+| 1000001 | user-999998  | 999998  || 1000002 | user-999999  | 999999  || 1000003 | user-1000000 | 1000000 || 1000004 | user-1000001 | 1000001 || 1000005 | user-1000002 | 1000002 || 1000006 | user-1000003 | 1000003 || 1000007 | user-1000004 | 1000004 || 1000008 | user-1000005 | 1000005 || 1000009 | user-1000006 | 1000006 || 1000010 | user-1000007 | 1000007 |+---------+--------------+---------+10 rows in setTime: 0.014s</code></pre><h5 id="MySQL-Group-By- 优化"><a href="#MySQL-Group-By- 优化" class="headerlink" title="MySQL Group By 优化"></a>MySQL Group By 优化 </h5><p> 查询 user 表并使用 score 字段进行分组，默认 score 字段没有索引，通过执行计划显示查询语句使用了临时表和非主键字段排序，所以进行了全表扫描</p><pre><code class="mysql">explain select * from user group by score limit 500000, 10;+----+-------------+-------+------------+------+---------------+--------+---------+--------+---------+----------+---------------------------------+| id | select_type | table | partitions | type | possible_keys | key    | key_len | ref    | rows    | filtered | Extra                           |+----+-------------+-------+------------+------+---------------+--------+---------+--------+---------+----------+---------------------------------+| 1  | SIMPLE      | user  | &lt;null&gt;     | ALL  | &lt;null&gt;        | &lt;null&gt; | &lt;null&gt;  | &lt;null&gt; | 6591199 | 100.0    | Using temporary; Using filesort |+----+-------------+-------+------------+------+---------------+--------+---------+--------+---------+----------+---------------------------------+</code></pre><p>下面我们为 score 字段添加索引，我们可以看到仅仅扫描了 limit 锁需要的 5000010 条数据</p><pre><code class="mysql">alter table `user` add index idx_score (`score`);desc user;+-------+--------------+------+-----+---------+----------------+| Field | Type         | Null | Key | Default | Extra          |+-------+--------------+------+-----+---------+----------------+| id    | int(11)      | NO   | PRI | &lt;null&gt;  | auto_increment || name  | varchar(32)  | NO   |     | &lt;null&gt;  |                || score | varchar(255) | YES  | MUL | &lt;null&gt;  |                |+-------+--------------+------+-----+---------+----------------+explain select * from user group by score limit 500000, 10;+----+-------------+-------+------------+-------+---------------+-----------+---------+--------+---------+----------+--------+| id | select_type | table | partitions | type  | possible_keys | key       | key_len | ref    | rows    | filtered | Extra  |+----+-------------+-------+------------+-------+---------------+-----------+---------+--------+---------+----------+--------+| 1  | SIMPLE      | user  | &lt;null&gt;     | index | idx_score     | idx_score | 258     | &lt;null&gt; | 5000010 | 100.0    | &lt;null&gt; |+----+-------------+-------+------------+-------+---------------+-----------+---------+--------+---------+----------+--------+</code></pre><p>下面我们来使用覆盖索引，我们可以看到 extra 字段的只为 using index 代表我们使用到了覆盖索引。那么此时这条查询语句是不需要回表的，所以也会提升部分效率</p><pre><code class="mysql">explain select score from user group by score limit 5000000, 10;+----+-------------+-------+------------+-------+---------------+-----------+---------+--------+---------+----------+-------------+| id | select_type | table | partitions | type  | possible_keys | key       | key_len | ref    | rows    | filtered | Extra       |+----+-------------+-------+------------+-------+---------------+-----------+---------+--------+---------+----------+-------------+| 1  | SIMPLE      | user  | &lt;null&gt;     | index | idx_score     | idx_score | 258     | &lt;null&gt; | 5000010 | 100.0    | Using index |+----+-------------+-------+------------+-------+---------------+-----------+---------+--------+---------+----------+-------------+</code></pre><p>下面我们在使用主键 id 作为分组条件，查看执行计划后，我们看到使用了 PRIMARY 主键索引</p><pre><code class="mysql">explain select * from user group by id limit 5000000, 10;+----+-------------+-------+------------+-------+-------------------+---------+---------+--------+---------+----------+--------+| id | select_type | table | partitions | type  | possible_keys     | key     | key_len | ref    | rows    | filtered | Extra  |+----+-------------+-------+------------+-------+-------------------+---------+---------+--------+---------+----------+--------+| 1  | SIMPLE      | user  | &lt;null&gt;     | index | PRIMARY,idx_score | PRIMARY | 4       | &lt;null&gt; | 5000010 | 100.0    | &lt;null&gt; |+----+-------------+-------+------------+-------+-------------------+---------+---------+--------+---------+----------+--------+</code></pre><p>下面我们在使用主键 id 作为分组条件前提下，加上使用覆盖索引，查看执行计划后，我们看到 extra 字段值为 using index 代表覆盖索引，没有回表操作</p><pre><code class="mysql">explain select id from user group by id limit 5000000, 10;+----+-------------+-------+------------+-------+-------------------+---------+---------+--------+---------+----------+-------------+| id | select_type | table | partitions | type  | possible_keys     | key     | key_len | ref    | rows    | filtered | Extra       |+----+-------------+-------+------------+-------+-------------------+---------+---------+--------+---------+----------+-------------+| 1  | SIMPLE      | user  | &lt;null&gt;     | index | PRIMARY,idx_score | PRIMARY | 4       | &lt;null&gt; | 5085756 | 100.0    | Using index |+----+-------------+-------+------------+-------+-------------------+---------+---------+--------+---------+----------+-------------+</code></pre><p>最后来对比以上全部 Group By 语句的执行效率</p><pre><code class="bash"># 无索引mysql&gt; select * from user group by score limit 5000000, 10... 结果大于 1 分钟# score 字段索引mysql&gt; select * from user group by score limit 5000000, 10;+---------+--------------+---------+| id      | name         | score   |+---------+--------------+---------+| 5500002 | user-5499999 | 5499999 || 58      | user-55      | 55      || 553     | user-550     | 550     || 5503    | user-5500    | 5500    || 55003   | user-55000   | 55000   || 550003  | user-550000  | 550000  || 5500003 | user-5500000 | 5500000 || 5500004 | user-5500001 | 5500001 || 5500005 | user-5500002 | 5500002 || 5500006 | user-5500003 | 5500003 |+---------+--------------+---------+10 rows in setTime: 46.519s# score 字段索引并使用覆盖索引mysql&gt; select score from user group by score limit 5000000, 10;+---------+| score   |+---------+| 5499999 || 55      || 550     || 5500    || 55000   || 550000  || 5500000 || 5500001 || 5500002 || 5500003 |+---------+10 rows in setTime: 1.013s# 主键 id 分组mysql&gt; select * from user group by id limit 5000000, 10;+---------+--------------+---------+| id      | name         | score   |+---------+--------------+---------+| 5000001 | user-4999998 | 4999998 || 5000002 | user-4999999 | 4999999 || 5000003 | user-5000000 | 5000000 || 5000004 | user-5000001 | 5000001 || 5000005 | user-5000002 | 5000002 || 5000006 | user-5000003 | 5000003 || 5000007 | user-5000004 | 5000004 || 5000008 | user-5000005 | 5000005 || 5000009 | user-5000006 | 5000006 || 5000010 | user-5000007 | 5000007 |+---------+--------------+---------+10 rows in setTime: 1.238s# 主键 id 分组并使用覆盖索引mysql&gt; select id from user group by id limit 5000000, 10;+---------+| id      |+---------+| 5000001 || 5000002 || 5000003 || 5000004 || 5000005 || 5000006 || 5000007 || 5000008 || 5000009 || 5000010 |+---------+10 rows in setTime: 0.940s</code></pre><p><strong>note:</strong> 需要 sql_mode 去掉 ONLY_FULL_GROUP_BY</p><hr><p><strong>引用：</strong><br><a href="https://database.51cto.com/art/201910/604945.htm" target="_blank" rel="noopener">MySQL 性能优化之骨灰级高阶神器</a></p>]]></content>
    
    
    <categories>
      
      <category>MySQL</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>MySQL- 设计范式</title>
    <link href="/2020/03/18/MySQL-%E8%AE%BE%E8%AE%A1%E8%8C%83%E5%BC%8F/"/>
    <url>/2020/03/18/MySQL-%E8%AE%BE%E8%AE%A1%E8%8C%83%E5%BC%8F/</url>
    
    <content type="html"><![CDATA[<center> <font face="黑体" size="6">MySQL- 设计范式 </font> </center><hr><a id="more"></a><p><strong> 在使用 MySQL 数据库时，我们通常有一些基本的设计规范需要遵守，这样会让我们在实际使用 MySQL 数据库时，避免前人才过的各种坑 </strong></p><hr><h5 id="MySQL- 设计范式（一）：数据表中所有字段都是不可分割的原子值"><a href="#MySQL- 设计范式（一）：数据表中所有字段都是不可分割的原子值" class="headerlink" title="MySQL 设计范式（一）：数据表中所有字段都是不可分割的原子值"></a>MySQL 设计范式（一）：数据表中所有字段都是不可分割的原子值 </h5><pre><code class="bash"># 如下 address 字段实际可以分割为国家、省份、城市、地区等字段。同时第三条和第一条记录重复（不唯一），所以不符合第一范式mysql&gt; CREATE TABLE `sys_user`  (-&gt;   `id` int(0) NOT NULL AUTO_INCREMENT,    -&gt;   `name` varchar(32) NOT NULL,    -&gt;   `address` varchar(32) NOT NULL,    -&gt;   PRIMARY KEY (`id`)    -&gt; );mysql&gt; insert into sys_user (name, address) values (&#39;zhangsan&#39;, &#39; 中国四川省武侯区桂溪街道 xx 号 &#39;);mysql&gt; insert into sys_user (name, address) values (&#39;lisi&#39;, &#39; 中国四川省武侯区桂溪街道 xx 号 &#39;);mysql&gt; select * from sys_user;+----+----------+------------------------------+| id | name     | address                      |+----+----------+------------------------------+|  1 | zhangsan | 中国四川省武侯区桂溪街道 xx 号 ||  2 | lisi     | 中国四川省武侯区桂溪街道 xx 号 ||  2 | wangwu   | 中国四川省武侯区桂溪街道 xx 号 |+----+----------+------------------------------+# 如下表字段基本不可分割。同时每行数据都是唯一的（必须有主键），所以符合第一范式mysql&gt; CREATE TABLE `sys_user`  (-&gt;   `id` int(0) PRIMARY KEY AUTO_INCREMENT,    -&gt;   `name` varchar(32) NOT NULL,    -&gt;   `country` varchar(32) NOT NULL,    -&gt;   `privence` varchar(32) NOT NULL,    -&gt;   `city` varchar(32) NOT NULL,    -&gt;   `addr` varchar(32) NOT NULL,    -&gt;   PRIMARY KEY (`id`)    -&gt; );mysql&gt; insert into sys_user (name, country, privence, city, addr) values (&#39;zhangsan&#39;, &#39; 中国 &#39;, &#39; 四川 &#39;, &#39; 成都 &#39;, &#39; 武侯区桂溪街道 xx 号 &#39;);mysql&gt; insert into sys_user (name, country, privence, city, addr) values (&#39;lisi&#39;, &#39; 中国 &#39;, &#39; 四川 &#39;, &#39; 成都 &#39;, &#39; 武侯区桂溪街道 xx 号 &#39;);mysql&gt; select * from sys_user;+----+----------+---------+----------+------+---------------------+| id | name     | country | privence | city | addr                |+----+----------+---------+----------+------+---------------------+|  1 | zhangsan | 中国    | 四川     | 成都 | 武侯区桂溪街道 xx 号  ||  2 | lisi     | 中国    | 四川     | 成都 | 武侯区桂溪街道 xx 号  ||  3 | wangwu   | 中国    | 四川     | 成都 | 武侯区桂溪街道 xx 号  |+----+----------+---------+----------+------+---------------------+</code></pre><p><strong>note:</strong> 设计范式只是在大多时候奏效，实际还需要根据业务区划分，例如上面的表，如果没有需求按照 country、city、privence 等字段分别统计 <br>，则无需进行拆分。</p><hr><h5 id="MySQL- 设计范式（二）：建立在第一范式基础上。同时所以非主键字段必须完全依赖主键，不能产生部分依赖"><a href="#MySQL- 设计范式（二）：建立在第一范式基础上。同时所以非主键字段必须完全依赖主键，不能产生部分依赖" class="headerlink" title="MySQL 设计范式（二）：建立在第一范式基础上。同时所以非主键字段必须完全依赖主键，不能产生部分依赖"></a>MySQL 设计范式（二）：建立在第一范式基础上。同时所以非主键字段必须完全依赖主键，不能产生部分依赖 </h5><pre><code class="bash"># 如下表 std_name 只与 std_id 有关，teacher_name 只与 teacher_id 有关。出现除主键以外其他列，只依赖于主键的部分字段mysql&gt; CREATE TABLE `student`  (    -&gt;   `std_id` int,    -&gt;   `std_name` varchar(32),    -&gt;   `teacher_id` int,    -&gt;   `teacher_name` varchar(32),    -&gt;   PRIMARY KEY (`std_id`, `std_name`)    -&gt; );mysql&gt; insert into student (std_id, std_name, teacher_id, teacher_name) values (1001, &#39;zhangsan&#39;, 2001, &#39; 张老师 &#39;);mysql&gt; insert into student (std_id, std_name, teacher_id, teacher_name) values (1002, &#39;lisi&#39;, 2002, &#39; 李老师 &#39;);mysql&gt; insert into student (std_id, std_name, teacher_id, teacher_name) values (1003, &#39;wangwu&#39;, 2001, &#39; 张老师 &#39;);mysql&gt; select * from student;+--------+----------+------------+--------------+| std_id | std_name | teacher_id | teacher_name |+--------+----------+------------+--------------+|   1001 | zhangsan |       2001 | 张老师       ||   1002 | lisi     |       2002 | 李老师       ||   1003 | lisi     |       2001 | 张老师       |+--------+----------+------------+--------------+# 如下拆表后，满足第二范式mysql&gt; CREATE TABLE `student`  (    -&gt;   `std_id` int primary key,    -&gt;   `std_name` varchar(32)    -&gt; );msyql&gt; insert into student (std_id, std_name) values (1001, &#39;zhangsan&#39;);msyql&gt; insert into student (std_id, std_name) values (1002, &#39;lisi&#39;);msyql&gt; insert into student (std_id, std_name) values (1003, &#39;wangwu&#39;);mysql&gt; CREATE TABLE `teacher`  (    -&gt;   `teacher_id` int primary key,    -&gt;   `teacher_name` varchar(32)    -&gt; );mysql&gt; insert into teacher (teacher_id, teacher_name) values (2001, &#39; 张老师 &#39;);mysql&gt; insert into teacher (teacher_id, teacher_name) values (2002, &#39; 李老师 &#39;);mysql&gt; CREATE TABLE `student_teacher`  (    -&gt;   `id` int primary key,    -&gt;   `std_id` int,    -&gt;   `teacher_id` int    -&gt; );mysql&gt; insert into student_teacher (id, std_id, teacher_id) values (1, 1001, 2001);mysql&gt; insert into student_teacher (id, std_id, teacher_id) values (2, 1002, 2002);mysql&gt; insert into student_teacher (id, std_id, teacher_id) values (3, 1003, 2001);mysql&gt; select * from student;+--------+----------+| std_id | std_name |+--------+----------+|   1001 | zhangsan ||   1002 | lisi     ||   1003 | wangwu   |+--------+----------+mysql&gt; select * from teacher;+------------+--------------+| teacher_id | teacher_name |+------------+--------------+|       2001 | zhanglaoshi  ||       2002 | lilaoshi     |+------------+--------------+mysql&gt; select * from student_teacher;+----+--------+------------+| id | std_id | teacher_id |+----+--------+------------+|  1 |   1001 |       2001 ||  2 |   1002 |       2002 ||  3 |   1003 |       2001 |+----+--------+------------+</code></pre><h5 id="MySQL- 设计范式（三）：建立在第二范式基础上。同时非主键字段的其他列之间不能有传递以来关系"><a href="#MySQL- 设计范式（三）：建立在第二范式基础上。同时非主键字段的其他列之间不能有传递以来关系" class="headerlink" title="MySQL 设计范式（三）：建立在第二范式基础上。同时非主键字段的其他列之间不能有传递以来关系"></a>MySQL 设计范式（三）：建立在第二范式基础上。同时非主键字段的其他列之间不能有传递以来关系 </h5><pre><code class="bash"># 如下表 std_email 字段依赖于 id 字段外，还依赖 std_id 字段，产生了依赖传递关系，所以不符合第三范式mysql&gt; CREATE TABLE `student`  (    -&gt;   `std_id` int primary key,    -&gt;   `std_name` varchar(32)    -&gt; );mysql&gt; CREATE TABLE `student_teacher`  (    -&gt;   `id` int primary key,    -&gt;   `std_id` int,    -&gt;   `teacher_id` int,    -&gt;   `std_email` varchar(32)    -&gt; );# 应该将 std_email 字段加入 student 表，依赖于 std_id 字段即可mysql&gt; CREATE TABLE `student`  (    -&gt;   `std_id` int primary key,    -&gt;   `std_name` varchar(32),    -&gt;   `std_email` varchar(32)    -&gt; );mysql&gt; CREATE TABLE `student_teacher`  (    -&gt;   `id` int primary key,    -&gt;   `std_id` int,    -&gt;   `teacher_id` int    -&gt; );</code></pre><div aligh="center">    <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/MySQL- 设计范式 /mysql-standard-logo.jpeg" srcset="/img/loading.gif" width="100%"></div>]]></content>
    
    
    <categories>
      
      <category>MySQL</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>MySQL-Slow-Query</title>
    <link href="/2020/03/17/MySQL-Slow-Query/"/>
    <url>/2020/03/17/MySQL-Slow-Query/</url>
    
    <content type="html"><![CDATA[<center> <font face="黑体" size="6">MySQL-Slow-Query</font> </center><hr><a id="more"></a><p><strong>日常使用 MySQL 数据库时，经常会有一些 SQL 执行比较慢，这有可能是数据量到问题，也有可能是 SQL 本身写的有问题。那么如何让 MySQL 帮我们 </strong><br><strong> 记录这些比较慢到 SQL 语句，便于我们日后优化呢？我们可以使用 MySQL 为我们提供的慢日志功能来满足以上需求</strong></p><h5 id="查看慢日志信息"><a href="# 查看慢日志信息" class="headerlink" title="查看慢日志信息"></a>查看慢日志信息</h5><pre><code class="bash">mysql&gt; show variables like &#39;%slow_query_log%&#39;;+---------------------+--------------------------------------+| Variable_name       | Value                                |+---------------------+--------------------------------------+| slow_query_log      | OFF                                  || slow_query_log_file | /var/lib/mysql/e36ca99c5d19-slow.log |+---------------------+--------------------------------------+</code></pre><h5 id="如何开启慢日志"><a href="# 如何开启慢日志" class="headerlink" title="如何开启慢日志"></a>如何开启慢日志</h5><pre><code class="bash">mysql&gt; set global slow_query_log = 1;Query OK, 0 rows affected (0.05 sec)# 再次查看慢日志mysql&gt; show variables like &#39;%slow_query_log%&#39;;+---------------------+--------------------------------------+| Variable_name       | Value                                |+---------------------+--------------------------------------+| slow_query_log      | ON                                   || slow_query_log_file | /var/lib/mysql/e36ca99c5d19-slow.log |+---------------------+--------------------------------------+</code></pre><p><strong>note:</strong> <code>slow_query_log</code> 值为 <code>ON</code> 表示开启。为 <code>OFF</code> 表示禁用。</p><hr><h5 id="查看慢日志时间"><a href="# 查看慢日志时间" class="headerlink" title="查看慢日志时间"></a>查看慢日志时间</h5><pre><code class="bash">mysql&gt; show variables like &#39;%long_query_time%&#39;;+-----------------+-----------+| Variable_name   | Value     |+-----------------+-----------+| long_query_time | 10.000000 |+-----------------+-----------+</code></pre><h5 id="设置慢日志时间"><a href="# 设置慢日志时间" class="headerlink" title="设置慢日志时间"></a>设置慢日志时间</h5><pre><code class="bash">mysql&gt; set global long_query_time = 3;Query OK, 0 rows affected (0.00 sec)# 再次查看慢日志时间mysql&gt; show variables like &#39;%long_query_time%&#39;;+-----------------+-----------+| Variable_name   | Value     |+-----------------+-----------+| long_query_time | 10.000000 |+-----------------+-----------+</code></pre><p><strong>note:</strong> <code>long_query_time</code> 单位时间为秒，默认为 10 秒。当 SQL 执行时间超过 <code>long_query_time</code> 时，则将执行语句记录到慢日志中。</p><hr><h5 id="查看超过阈值到 -SQL- 数量"><a href="# 查看超过阈值到 -SQL- 数量" class="headerlink" title="查看超过阈值到 SQL 数量"></a>查看超过阈值到 SQL 数量</h5><pre><code class="bash">mysql&gt; show global status like &#39;%slow_queries%&#39;;+---------------+-------+| Variable_name | Value |+---------------+-------+| Slow_queries  | 0     |+---------------+-------+# 执行一条慢 SQLselect sleep(3), id from user limit 1;+----------+----+| sleep(3) | id |+----------+----+|        0 | 10 |+----------+----+1 row in set (3.00 sec)# 再次查看mysql&gt; show global status like &#39;%slow_queries%&#39;;+---------------+-------+| Variable_name | Value |+---------------+-------+| Slow_queries  | 1     |+---------------+-------+# 通过查看慢日志可以看到具体到 SQL$ cat e36ca99c5d19-slow.log  mysqld, Version: 5.7.29-log (MySQL Community Server (GPL)). started with:  Tcp port: 3306  Unix socket: /var/run/mysqld/mysqld.sock  Time                 Id Command    Argument  # Time: 2020-03-17T15:07:38.895767Z  # User@Host: root[root] @ localhost []  Id:    58  # Query_time: 24.006077  Lock_time: 0.000270 Rows_sent: 8  Rows_examined: 8  use backup;  SET timestamp=1584457658;  select sleep(3), id from user;</code></pre><p><strong>note:</strong> 通过慢日志我们就可以定期检查哪些 SQL 执行较慢，是否可以优化了。</p><div aligh="center">    <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/MySQL-Slow-Query/mysql-slow-query.jpeg" srcset="/img/loading.gif" width="100%"></div>]]></content>
    
    
    <categories>
      
      <category>MySQL</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>ZooKeeper 入门</title>
    <link href="/2020/03/17/ZooKeeper/"/>
    <url>/2020/03/17/ZooKeeper/</url>
    
    <content type="html"><![CDATA[<center> <font face="黑体" size="6">ZooKeeper 入门</font> </center><a id="more"></a><h5 id="介绍"><a href="# 介绍" class="headerlink" title="介绍"></a>介绍</h5><p>ZooKeeper 是一个高度可靠到分布式协调框架，用于维护配置信息、统一命名、分布式同步和提供组服务功能。</p><hr><h5 id="Zookeeper- 组成"><a href="#Zookeeper- 组成" class="headerlink" title="Zookeeper 组成"></a>Zookeeper 组成</h5><p>ZooKeeper 简单来讲由两部分组成：</p><ol><li><p>文件系统（节点 + 数据）</p><div aligh="center">    <img src="http://qiniu.raindrop-wl.cn/zookeeper-node.png" srcset="/img/loading.gif" width="100%"></div></li><li><p>通知机制（Watcher）</p></li></ol><hr><h5 id="ZooKeeper- 节点类型"><a href="#ZooKeeper- 节点类型" class="headerlink" title="ZooKeeper 节点类型"></a>ZooKeeper 节点类型</h5><p><code>PERSISTENT</code> 持久化节点<br><code>PERSISTENT_SEQUENTIAL</code> 顺序持久化节点<br><code>EPHEMERAL</code> 临时节点<br><code>EPHEMERAL_SEQUENTIAL</code> 顺序临时节点</p><hr><h5 id="ZooKeeper- 常用命令"><a href="#ZooKeeper- 常用命令" class="headerlink" title="ZooKeeper 常用命令"></a>ZooKeeper 常用命令</h5><table><thead><tr><th>命令</th><th>含义</th><th>示例</th></tr></thead><tbody><tr><td>get /node</td><td>获取节点数据</td><td>get /namespace 获取 /namespace 节点数据</td></tr><tr><td>get /node/subNode</td><td>获取子节点数据</td><td>get /namespace/dev 获取 /namespace/dev 节点数据</td></tr><tr><td>create /node data</td><td>创建节点及数据</td><td>create /namespace raindrop 创建 /namespace 节点数据为 raindrop</td></tr><tr><td>create /node/subNode data</td><td>创建子节点及数据</td><td>create /namespace/dev dbHost 创建 /namespace/dev 节点数据为 dbHost</td></tr><tr><td>create -e /node data</td><td>创建临时节点及数据</td><td>create -e /lock uuid 创建临时节点 /lock 数据为 uuid</td></tr><tr><td>create -s /node data</td><td>创建顺序节点及数据</td><td>create -s /lock uuid 创建顺序节点 /lock 数据为 uuid 数据自动累加</td></tr><tr><td>set /node data</td><td>修改节点数据</td><td>set /namespace rain 修改 /namespace 节点数据为 rain</td></tr><tr><td>set /node/subNode data</td><td>修改子节点数据</td><td>set /namespace/dev dbName 修改 /namespace/dev 节点数据为 dbName</td></tr><tr><td>delete /node</td><td>删除节点</td><td>delete /namespace 删除 /namespace 节点，若存在子节点则不能删除</td></tr><tr><td>deleteall /node</td><td>删除节点，包含子节点</td><td>deleteall /namespace 删除 /namespace 节点及子节点数据</td></tr><tr><td>watcher</td><td>通知机制，一次性</td><td>stat /lock watch 订阅 /lock 节点 watch 时间，创建 /lock 节点时触发</td></tr><tr><td>stat</td><td>查看节点信息</td><td>stat /namespace 查看 /namespace 节点信息</td></tr></tbody></table><hr><h5 id="ZooKeeper- 命令示例"><a href="#ZooKeeper- 命令示例" class="headerlink" title="ZooKeeper 命令示例"></a>ZooKeeper 命令示例</h5><ul><li><code>create</code></li></ul><pre><code class="bash"># 创建跟节点[zk: localhost:2181(CONNECTED) 25] create /namespace environmentCreated /namespace# 创建子节点[zk: localhost:2181(CONNECTED) 26] create /namespace/dev-host 127.0.0.1Created /namespace/dev-host# 创建临时节点，客户端链接关闭后失效（会被删除）[zk: localhost:2181(CONNECTED) 27] create -e /tmp raindropCreated /tmp# 创建顺序节点，注意第二次创建时序列进行了自增[zk: localhost:2181(CONNECTED) 30] create -s /lock uuidCreated /lock0000000010[zk: localhost:2181(CONNECTED) 31] create -s /lock uuidCreated /lock0000000011</code></pre><ul><li><code>get</code></li></ul><pre><code class="bash"># 获取节点数据[zk: localhost:2181(CONNECTED) 32] get /namespaceenvironment[zk: localhost:2181(CONNECTED) 33] get /namespace/dev-host127.0.0.1[zk: localhost:2181(CONNECTED) 34] get /tmpraindrop# 获取不存在的节点或提示错误[zk: localhost:2181(CONNECTED) 41] get /tttorg.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /ttt</code></pre><ul><li><code>set</code></li></ul><pre><code class="bash"># 更新节点数据[zk: localhost:2181(CONNECTED) 36] set /namespace raindrop[zk: localhost:2181(CONNECTED) 37] set /namespace/dev-host 0.0.0.0[zk: localhost:2181(CONNECTED) 38] get /namespaceraindrop[zk: localhost:2181(CONNECTED) 39] get /namespace/dev-host0.0.0.0# 更新不存在节点会提示错误[zk: localhost:2181(CONNECTED) 40] set /ttt 111Node does not exist: /ttt</code></pre><ul><li><code>delete</code></li></ul><pre><code class="bash"># 删除节点后，查询已经不存在[zk: localhost:2181(CONNECTED) 42] delete /tmp[zk: localhost:2181(CONNECTED) 43] get /tmporg.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /tmp# 删除带有子节点的节点会提示错误[zk: localhost:2181(CONNECTED) 44] delete /namespaceNode not empty: /namespace</code></pre><ul><li><code>deleteall</code></li></ul><pre><code class="bash"># 删除节点，包含子节点，删除后查询已经不存在[zk: localhost:2181(CONNECTED) 45] deleteall /namespace[zk: localhost:2181(CONNECTED) 46] get /namespaceorg.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /namespace</code></pre><ul><li><code>watcher</code></li></ul><pre><code class="bash"># stat 订阅创建节点[zk: localhost:2181(CONNECTED) 50] stat -w /namespaceNode does not exist: /namespace[zk: localhost:2181(CONNECTED) 51] create /namespace raindropCreated /namespaceWATCHER::WatchedEvent state:SyncConnected type:NodeCreated path:/namespace# get 订阅节点数据改变[zk: localhost:2181(CONNECTED) 52] get -w /namespaceraindrop[zk: localhost:2181(CONNECTED) 53] set /namespace raindrop666WATCHER::WatchedEvent state:SyncConnected type:NodeDataChanged path:/namespace</code></pre><ul><li><code>stat</code></li></ul><pre><code class="bash"># 查看节点信息，包括版本、长度、子节点等信息[zk: localhost:2181(CONNECTED) 56] stat /namespacecZxid = 0x2actime = Sat Mar 21 00:10:31 CST 2020mZxid = 0x2bmtime = Sat Mar 21 00:10:50 CST 2020pZxid = 0x2acversion = 0dataVersion = 1aclVersion = 0ephemeralOwner = 0x0dataLength = 11numChildren = 0</code></pre><hr><h5 id="ZAB- 协议"><a href="#ZAB- 协议" class="headerlink" title="ZAB 协议"></a>ZAB 协议</h5><p><code>myid</code><br><code>zxid</code> 全局 顺序 唯一 事务 id</p><hr><h5 id="Leader- 选举"><a href="#Leader- 选举" class="headerlink" title="Leader 选举"></a>Leader 选举 </h5><p><code> 半数机制</code></p><p><code>myid</code></p><p><code>zxid</code></p><hr><h5 id="Zookeeper- 使用场景"><a href="#Zookeeper- 使用场景" class="headerlink" title="Zookeeper 使用场景"></a>Zookeeper 使用场景</h5>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Nginx-Mirror</title>
    <link href="/2020/03/16/Nginx-Mirror/"/>
    <url>/2020/03/16/Nginx-Mirror/</url>
    
    <content type="html"><![CDATA[<center> <font face="黑体" size="6">Nginx-Mirror</font> </center><hr><a id="more"></a><h5 id="需求"><a href="# 需求" class="headerlink" title="需求"></a>需求 </h5><p> 今日有一个新的业务需求需要上线，领导要求上线前要充分测试功能及并发能力，最好可以模拟线上的真是流量。<br>基于此，我找到了 Nginx 提供的 nginx_http_mirror_module 模块。</p><hr><h5 id="Nginx-http-mirror-module"><a href="#Nginx-http-mirror-module" class="headerlink" title="Nginx_http_mirror_module"></a>Nginx_http_mirror_module</h5><p><code>Nginx 1.13.4</code> 提供了 Mirror 模块，用于创建源站点的镜像站点，将源站点请求复制到 Mirror 站点来实现原始请求的镜像，Mirror<br>站点的响应将被忽略。</p><div aligh="center">    <img src="http://qiniu.raindrop-wl.cn/nginx-mirror.png" srcset="/img/loading.gif" width="100%"></div><hr><h5 id="复制真实流量，不支持 -Post- 请求体复制"><a href="# 复制真实流量，不支持 -Post- 请求体复制" class="headerlink" title="复制真实流量，不支持 Post 请求体复制"></a>复制真实流量，不支持 Post 请求体复制 </h5><p> 如下配置将实现真实用户请求 80 端入正常访问现有生产 web1 端点，Nginx 同时将流量复制到 /mirror 路径的 web2 端点，不支持 Post 请求</p><pre><code class="bash"># 编辑 nginx.confserver {    listen 80;    server_name localhost;    # 流量复制    location / {        mirror /mirror; # 镜像站点路径        mirror_request_body off;        proxy_pass http://127.0.0.1:8080/web1;    }    location /mirror {if ($request_method != GET) {return 403;}        internal; # 内部访问        proxy_pass http://127.0.0.1:8080/web2;        proxy_pass_request_body off;        proxy_set_header Content-Length &quot;&quot;;        proxy_set_header X-Original-URI $request_uri;    }}</code></pre><hr><h5 id="复制真实流量，支持 -Post- 请求体复制"><a href="# 复制真实流量，支持 -Post- 请求体复制" class="headerlink" title="复制真实流量，支持 Post 请求体复制"></a>复制真实流量，支持 Post 请求体复制 </h5><p> 如下配置将实现真实用户请求 80 端入正常访问现有生产 web1 端点，Nginx 同时将流量复制到 /mirror 路径的 web2 端点</p><pre><code class="bash"># 编辑 nginx.confserver {    listen 80;    server_name localhost;    # 流量复制    location / {        mirror /mirror; # 镜像站点路径        mirror_request_body on; # 此参数为 on 时支持 post 复制，为 off 时不支持复制        proxy_pass http://127.0.0.1:8080/web1;    }    location /mirror {        internal; # 内部访问        proxy_pass http://127.0.0.1:8080/web2;        proxy_pass_request_body on; # 此参数配合 mirror_request_body 参数使用        proxy_set_header X-Original-URI $request_uri;    }}</code></pre><hr><h5 id="镜像站点流量翻倍"><a href="# 镜像站点流量翻倍" class="headerlink" title="镜像站点流量翻倍"></a>镜像站点流量翻倍 </h5><p> 如希望用双倍的流量压测镜像站点，只需要重复配置 mirror 路径即可完成</p><pre><code class="bash"># 编辑 nginx.confserver {    listen 80;    server_name localhost;    location / {        mirror /mirror; # 配置镜像站点        mirror /mirror; # 配置镜像站点        mirror_request_body on;        proxy_pass http://127.0.0.1:8080/web1;    }    location /mirror {        internal; # 内部访问        proxy_pass http://127.0.0.1:8080/web2;        proxy_pass_request_body on;        proxy_set_header X-Original-URI $request_uri;    }}</code></pre><hr><h5 id="镜像站点日志"><a href="# 镜像站点日志" class="headerlink" title="镜像站点日志"></a>镜像站点日志</h5><p>mirror 站点默认不支持写日志，所以需要配合 server 来达到写日志的目的</p><pre><code class="bash">server {    listen 80;    server_name localhost;    location / {        mirror /mirror;        mirror_request_body on;        proxy_pass http://127.0.0.1:8080/web1;    }    location /mirror {        internal; # 内部访问        proxy_pass http://127.0.0.1:8000$request_uri; # 转发到内部 server        proxy_pass_request_body on;        proxy_set_header X-Original-URI $request_uri;    }}server {    listen 8000;    server_name localhost;    location / {        # 在这里写日志        access_log /usr/local/Cellar/openresty/1.15.8.2/nginx/access.log main;        proxy_pass http://127.0.0.1:8080/web2;    }}</code></pre><hr><p><strong>note:</strong> mirror 支持到域为 http、server、location，可以在同一级别域中指定多个 mirror</p>]]></content>
    
    
    <categories>
      
      <category>Nginx</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Mysql High Availability</title>
    <link href="/2020/03/13/Mysql%20High%20Availability/"/>
    <url>/2020/03/13/Mysql%20High%20Availability/</url>
    
    <content type="html"><![CDATA[<center> <font face="黑体" size="6">Mysql + Keepalived 主主热备，搭建高可用集群 </font> </center><a id="more"></a><h3 id="在 -Mysql- 集群部署方案中有很多种组合方式，如 - 主从复制、主主热备、一主多从、多主一从（多源复制）等 - 无论哪种部署方案，都是为了提高 -Mysql- 服务的性能或可用性为目的 - 那么最终使用哪种部署方案，还是要根据需求场景来 - 本次将记录一下，工作中遇到的“主主热备 - 高可用”搭建的方法"><a href="# 在 -Mysql- 集群部署方案中有很多种组合方式，如 - 主从复制、主主热备、一主多从、多主一从（多源复制）等 - 无论哪种部署方案，都是为了提高 -Mysql- 服务的性能或可用性为目的 - 那么最终使用哪种部署方案，还是要根据需求场景来 - 本次将记录一下，工作中遇到的“主主热备 - 高可用”搭建的方法" class="headerlink" title="在 Mysql 集群部署方案中有很多种组合方式，如: 主从复制、主主热备、一主多从、多主一从（多源复制）等. 无论哪种部署方案，都是为了提高 Mysql 服务的性能或可用性为目的. 那么最终使用哪种部署方案，还是要根据需求场景来. 本次将记录一下，工作中遇到的“主主热备 + 高可用”搭建的方法."></a> 在 Mysql 集群部署方案中有很多种组合方式，如: 主从复制、主主热备、一主多从、多主一从（多源复制）等. 无论哪种部署方案，都是为了提高 Mysql 服务的性能或可用性为目的. 那么最终使用哪种部署方案，还是要根据需求场景来. 本次将记录一下，工作中遇到的“主主热备 + 高可用”搭建的方法.</h3><p><strong> 环境如下 </strong>:</p><table><thead><tr><th align="center">Plugin</th><th align="center">Version</th></tr></thead><tbody><tr><td align="center">Centos</td><td align="center">7.2</td></tr><tr><td align="center">MySQL</td><td align="center">5.7</td></tr><tr><td align="center">Keepalived</td><td align="center">1.4.5</td></tr></tbody></table><p><strong> 服务器配置 </strong>:</p><table><thead><tr><th align="center">Server</th><th align="center">Software</th><th align="center">Configure</th></tr></thead><tbody><tr><td align="center">192.168.1.100</td><td align="center">Master1/Slave2/Keepalived-Master</td><td align="center">8 核 + 8g</td></tr><tr><td align="center">192.168.1.101</td><td align="center">Master2/Slave1/Keepalived-Backup</td><td align="center">8 核 + 8g</td></tr><tr><td align="center">192.168.1.110(vip)</td><td align="center">&amp;</td><td align="center">&amp;</td></tr></tbody></table><p><strong>MySQL 主从架构 </strong></p><ol><li><p> 主服务器上面的任何修改都会通过自己的 I/O tread(I/O 线程) 保存在二进制日志 Binary log 里面。</p></li><li><p> 从服务器上面也启动一个 I/O thread，通过配置好的用户名和密码, 连接到主服务器上面请求读取二进制日志，然后把读取到的二进制日志写到本地的一个 Realy log（中继日志）里面。</p></li><li><p> 从服务器上面同时开启一个 SQL thread 定时检查 Realy log(这个文件也是二进制的)，如果发现有更新立即把更新的内容在本机的数据库上面执行一遍。</p></li></ol><div aligh="center">    <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/MySQL- 故障恢复（一）/MySQL.png" srcset="/img/loading.gif" width="100%"></div><p><strong> 实施过程 </strong></p><ul><li><p>192.168.1.100 与 192.168.1.101 主主热备.</p></li><li><p> 使用 Keepalived 搭建虚拟 VIP192.168.1.110，实现对外暴露统一 ip.<br><img src="http://qiniu.raindrop-wl.cn/mysql-keepalived.png" srcset="/img/loading.gif" alt="Mysql-Keepalived"></p></li></ul><h3 id="我们首先来配置主主热备"><a href="# 我们首先来配置主主热备" class="headerlink" title="我们首先来配置主主热备"></a> 我们首先来配置主主热备 </h3><ul><li><p>Master1 192.168.1.100 配置 </p><pre><code class="bash"># 防火墙开发 3306 端口$ firewall-cmd --permanent --zone=public --add-port=3306/tcp$ firewall-cmd --reload#配置 root 用户远程访问权限，配置 mysql 数据同步授权$ ./mysql -uroot -pmysql&gt; grant all on *.* to &#39;root&#39;@&#39;192.168.1.%&#39; identified by &#39;123456&#39;;mysql&gt; flush privileges;mysql&gt; grant replication slave on *.* to &#39;slave&#39;@&#39;192.168.1.%&#39; identified by &#39;123456&#39;;mysql&gt; flush privileges;#配置 my.cnf 如下$ vim /etc/my.cnf  [mysqld]  user=mysql  server-id=1                                    #主从服务器 id，必须保证唯一，值越小优先级越高（master 值小）  port=3306  basedir=/usr/local/mysql  datadir=/usr/local/mysql/data  socket=/tmp/mysql.sock  character-set-server=utf8  auto_increment_offset=1                        #自增起始值 1，因为是 master1 所以为 1  auto_increment_increment=2                     #自增步骤 2，因为目前的是 2 台机器集群，所有步骤为 2  log-bin=mysql-bin                              #开启 binlog 二进制日志（存储的是写操作的 sql 执行日志）  binlog_format=ROW                              #binlog 同步模式  replicate-ignore-db = mysql                    #忽略不同步主从的数据库  replicate-ignore-db = information_schema       #忽略不同步主从的数据库  replicate-ignore-db = performance_schema       #忽略不同步主从的数据库  replicate-ignore-db = test                     #忽略不同步主从的数据库  lower_case_table_names=1                       #大小写敏感，默认为 0 可以不配置  [mysqld_safe]  log-error=/usr/local/mysql/mysqld.log  pid-file=/usr/local/mysql/mysqld.pid  [client]  default-character-set=utf8  socket=/tmp/mysql.sock  [mysql]  default-character-set=utf8  socket=/tmp/mysql.sock#重启 mysql$ system restart mysqld#查看 binlog 日志及 pos 位置$ ./mysql -uroot -pmysql&gt; show master status;+------------------|----------|--------------|--------------------------|-------------------+| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB         | Executed_Gtid_Set |+------------------|----------|--------------|--------------------------|-------------------+| mysql-bin.000001 |      120 |              | mysql,information_schema |                   |+------------------|----------|--------------|--------------------------|-------------------+</code></pre></li><li><p>Master2 192.168.1.101 配置 </p><pre><code class="bash"># 防火墙开发 3306 端口$ firewall-cmd --permanent --zone=public --add-port=3306/tcp$ firewall-cmd --reload#配置 mysql 数据同步授权，配置 root 用户远程访问权限$ ./mysql -uroot -pmysql&gt; grant all on *.* to &#39;root&#39;@&#39;192.168.1.%&#39; identified by &#39;123456&#39;;mysql&gt; flush privileges;mysql&gt; grant replication slave on *.* to &#39;slave&#39;@&#39;192.168.1.%&#39; identified by &#39;123456&#39;;mysql&gt; flush privileges;#配置 my.cnf 如下$ vim /etc/my.cnf  [mysqld]  user=mysql  server-id=2                                    #主从服务器 id，必须保证唯一，值越小优先级越高（master 值小）  port=3306  basedir=/usr/local/mysql  datadir=/usr/local/mysql/data  socket=/tmp/mysql.sock  character-set-server=utf8  auto_increment_offset=2                        #自增起始值 2，因为是 master2 所以为 2  auto_increment_increment=2                     #自增步骤 2，因为目前的是 2 台机器集群，所有步骤为 2  log-bin=mysql-bin                              #开启 binlog 二进制日志（存储的是写操作的 sql 执行日志）  binlog_format=ROW                              #binlog 同步模式  replicate-ignore-db = mysql                    #忽略不同步主从的数据库  replicate-ignore-db = information_schema       #忽略不同步主从的数据库  replicate-ignore-db = performance_schema       #忽略不同步主从的数据库  replicate-ignore-db = test                     #忽略不同步主从的数据库  lower_case_table_names=1                       #大小写敏感，默认为 0 可以不配置  [mysqld_safe]  log-error=/usr/local/mysql/mysqld.log  pid-file=/usr/local/mysql/mysqld.pid  [client]  default-character-set=utf8  socket=/tmp/mysql.sock  [mysql]  default-character-set=utf8  socket=/tmp/mysql.sock#重启 mysql$ system restart mysqld#查看 binlog 日志及 pos 位置$ ./mysql -uroot -pmysql&gt; show master status;+------------------|----------|--------------|--------------------------|-------------------+| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB         | Executed_Gtid_Set |+------------------|----------|--------------|--------------------------|-------------------+| mysql-bin.000001 |      120 |              | mysql,information_schema |                   |+------------------|----------|--------------|--------------------------|-------------------+</code></pre></li></ul><ul><li><p>Master1 做同步操作 </p><pre><code class="bash">$ ./mysql -uroot -pmysql&gt; stop slave;mysql&gt; change master to \        master_host=&#39;192.168.1.101&#39;,        master_port=3306,        master_user=&#39;slave&#39;,        master_password=&#39;123456&#39;,        master_log_file=&#39;mysql-bin.000001&#39;,        master_log_pos=120;mysql&gt; start slave;mysql&gt; show slave status \G;*************************** 1. row ***************************            Slave_IO_State: Waiting for master to send event              Master_Host: 192.168.1.101              Master_User: slave              Master_Port: 3306            Connect_Retry: 60          Master_Log_File: mysql-bin.000001      Read_Master_Log_Pos: 120            Relay_Log_File: mysql-relay-bin.000001            Relay_Log_Pos: 120    Relay_Master_Log_File: mysql-bin.000001          Slave_IO_Running: Yes        Slave_SQL_Running: Yes    .........................    Seconds_Behind_Master: 0    .........................# 如上，只要保证 Slave_IO_Running、Slave_SQL_Running 的值全部为 Yes 就标识 Master1 与 Master2 实现了主从，Master1 同步 Master2 的数据 </code></pre></li><li><p>Master2 做同步操作 </p><pre><code class="bash">$ ./mysql -uroot -pmysql&gt; stop slave;mysql&gt; change master to \        master_host=&#39;192.168.1.100&#39;,        master_port=3306,        master_user=&#39;slave&#39;,        master_password=&#39;123456&#39;,        master_log_file=&#39;mysql-bin.000001&#39;,        master_log_pos=120;mysql&gt; start slave;mysql&gt; show slave status \G;*************************** 1. row ***************************            Slave_IO_State: Waiting for master to send event              Master_Host: 192.168.1.100              Master_User: slave              Master_Port: 3306            Connect_Retry: 60          Master_Log_File: mysql-bin.000001      Read_Master_Log_Pos: 120            Relay_Log_File: mysql-relay-bin.000001            Relay_Log_Pos: 120    Relay_Master_Log_File: mysql-bin.000001          Slave_IO_Running: Yes        Slave_SQL_Running: Yes    .........................    Seconds_Behind_Master: 0    .........................# 如上，只要保证 Slave_IO_Running、Slave_SQL_Running 的值全部为 Yes 就标识 Master2 与 Master1 实现了主从，Master2 同步 Master1 的数据 </code></pre></li></ul><ul><li><p> 主主热备同步验证 </p><pre><code class="shell"># 在 Master1 中操作mysql&gt; create database my_local;mysql&gt; use my_local;mysql&gt; CREATE TABLE `book` (`id` int(11) NOT NULL AUTO_INCREMENT COMMENT &#39; 主键 &#39;,        `book_name` varchar(100) NOT NULL COMMENT &#39; 书名 &#39;,        `author` varchar(100) DEFAULT NULL COMMENT &#39; 作者 &#39;,        `price` varchar(100) DEFAULT NULL COMMENT &#39; 价格 &#39;,        `remark` varchar(100) DEFAULT NULL COMMENT &#39; 备注 &#39;,        PRIMARY KEY (`id`)      ) ENGINE=InnoDB DEFAULT CHARSET=utf8;mysql&gt; insert into book values(1, &quot;Java 深入浅出 &quot;, &quot;Mas&quot;, &quot;50.00&quot;, &quot;Java 入门不错的书！&quot;);mysql&gt; insert into book values(2, &quot;Python 深入浅出 &quot;, &quot;Mas&quot;, &quot;50.00&quot;, &quot;Python 入门不错的书！&quot;);mysql&gt; insert into book values(3, &quot;Golang 深入浅出 &quot;, &quot;Mas&quot;, &quot;50.00&quot;, &quot;Golang 入门不错的书！&quot;);# 在 Master1 中操作mysql&gt; select * from book;+----|-----------------|--------|-------|----------------------+| id | book_name       | author | price | remark               |+----|-----------------|--------|-------|----------------------+|  1 | Java 深入浅出     | Mas    | 50.00 | Java 入门不错的书！      ||  2 | Python 深入浅出   | Mas    | 50.00 | Python 入门不错的书！    ||  3 | Golang 深入浅出   | Mas    | 50.00 | Golang 入门不错的书！    |+----|-----------------|--------|-------|----------------------+# 在 Master2 中操作mysql&gt; use my_local;mysql&gt; select * from book;+----|-----------------|--------|-------|----------------------+| id | book_name       | author | price | remark               |+----|-----------------|--------|-------|----------------------+|  1 | Java 深入浅出     | Mas    | 50.00 | Java 入门不错的书！      ||  2 | Python 深入浅出   | Mas    | 50.00 | Python 入门不错的书！    ||  3 | Golang 深入浅出   | Mas    | 50.00 | Golang 入门不错的书！    |+----|-----------------|--------|-------|----------------------+mysql&gt; CREATE TABLE `user` (`id` int(11) NOT NULL AUTO_INCREMENT COMMENT &#39; 主键 &#39;,        `name` varchar(100) NOT NULL COMMENT &#39; 姓名 &#39;,        `email` varchar(100) DEFAULT NULL COMMENT &#39; 邮件 &#39;,        `phone` varchar(100) DEFAULT NULL COMMENT &#39; 手机号 &#39;,        `remark` varchar(100) DEFAULT NULL COMMENT &#39; 备注 &#39;,        PRIMARY KEY (`id`)      ) ENGINE=InnoDB DEFAULT CHARSET=utf8;mysql&gt; insert into user values(1, &quot;Wang Liang&quot;, &quot;727474430@qq.com&quot;, &quot;18888888888&quot;, &quot; 管理员 &quot;);mysql&gt; insert into user values(2, &quot;Wang Er&quot;, &quot;727474430@qq.com&quot;, &quot;18666666666&quot;, &quot; 普通用户 &quot;);mysql&gt; insert into user values(3, &quot;Wang San&quot;, &quot;727474430@qq.com&quot;, &quot;18555555555&quot;, &quot; 正常人 &quot;);# 在 Master2 中操作mysql&gt; select * from user;+----|------------|------------------|-------------|----------+| id | name       | email            | phone       | remark   |+----|------------|------------------|-------------|----------+|  1 | Wang Liang | 727474430@qq.com | 18888888888 | 管理员    ||  2 | Wang Er    | 727474430@qq.com | 18666666666 | 普通用户  ||  3 | Wang San   | 727474430@qq.com | 18555555555 | 正常人   |+----|------------|------------------|-------------|----------+# 在 Master1 中操作mysql&gt; use my_local;mysql&gt; select * from user;+----|------------|------------------|-------------|----------+| id | name       | email            | phone       | remark   |+----|------------|------------------|-------------|----------+|  1 | Wang Liang | 727474430@qq.com | 18888888888 | 管理员    ||  2 | Wang Er    | 727474430@qq.com | 18666666666 | 普通用户  ||  3 | Wang San   | 727474430@qq.com | 18555555555 | 正常人   |+----|------------|------------------|-------------|----------+# 至此 192.168.1.100 与 192.168.1.101 主主同步已经配置成功 </code></pre></li></ul><h3 id="接下来我们配置 -Keepalived-ip- 飘逸高可用"><a href="# 接下来我们配置 -Keepalived-ip- 飘逸高可用" class="headerlink" title="接下来我们配置 Keepalived ip 飘逸高可用"></a> 接下来我们配置 Keepalived ip 飘逸高可用 </h3><ul><li><p> 安装 Keepalived，在 192.168.1.100、192.168.1.101 做相同的操作 </p><pre><code class="bash"># 安装依赖$ yum install -y openssl-devel wget$ yum install -y libnfnetlink-devel$ yum -y install libssl-dev libnl libnl-devel# 下载 keepalived$ cd /usr/local/src$ wget http://www.keepalived.org/software/keepalived-1.3.5.tar.gz &amp;&amp; tar -zxvf keepalived-1.3.5.tar.gz$ cd keepalived-1.3.5 &amp;&amp; ./configure --prefix=/usr/local/keepalived$ make &amp;&amp; make install$ cp /usr/local/src/keeyalived-1.3.5/keepalived/etc/init.d/keepalived /etc/rc.d/init.d$ cp /usr/local/keepalived/etc/sysconfig/keepalived /etc/sysconfig/$ mkdir /etc/keepalived$ cp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived/$ cp /usr/local/keepalived/sbin/keepalived /usr/sbin/# 开机启动echo &quot;/etc/init.d/keepalived start&quot; &gt;&gt; /etc/rc.local</code></pre></li><li><p> 在 Master1 中操作 </p><pre><code class="bash"># 备份一下配置文件，如果配置错误可以还原$ cp /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak$ vim /etc/keepalived/keepalived.conf  global_defs {  notification_email {727474430@qq.com}  notification_email_from 727474430@qq.com  smtp_server 127.0.0.1  smtp_connect_timeout 30  router_id MASTER-HA  }  vrrp_script chk_mysql_port {     #检测 mysql 服务是否在运行。有很多方式，比如进程，用脚本检测等等      script &quot;/opt/chk_mysql.sh&quot;   #这里通过脚本监测      interval 2                   #脚本执行间隔，每 2s 检测一次      weight -5                    #脚本结果导致的优先级变更，检测失败（脚本返回非 0）则优先级 -5      fall 2                       #检测连续 2 次失败才算确定是真失败。会用 weight 减少优先级（1-255 之间）      rise 1                       #检测 1 次成功就算成功。但不修改优先级  }  vrrp_instance VI_1 {      state MASTER      interface eth0               #指定虚拟 ip 的网卡接口      mcast_src_ip 192.168.1.100      virtual_router_id 51         #路由器标识，MASTER 和 BACKUP 必须是一致的      priority 101                 #定义优先级，数字越大，优先级越高，在同一个 vrrp_instance 下，MASTER 的优先级必须大于 BACKUP 的优先级。这样 MASTER 故障恢复后，就可以将 VIP 资源再次抢回来      advert_int 1      authentication {          auth_type PASS          auth_pass 1111      }      virtual_ipaddress {192.168.1.110}      track_script {chk_mysql_port}    }# 编写 keepalived 检测脚本$ vim /opt/chk_mysql.sh  #!/bin/bash  counter=$(netstat -na|grep &quot;LISTEN&quot;|grep &quot;3306&quot;|wc -l)  if [&quot;${counter}&quot; -eq 0 ]; then      /etc/init.d/keepalived stop  fi# 授权$ chmod 755 /opt/chk_mysql.sh# 启动 keepalived$ /etc/init.d/keepalived start</code></pre></li><li><p> 在 Master2 中操作 </p><pre><code class="bash"># 备份一下配置文件，如果配置错误可以还原$ cp /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak$ vim /etc/keepalived/keepalived.conf  global_defs {  notification_email {727474430@qq.com}  notification_email_from 727474430@qq.com  smtp_server 127.0.0.1  smtp_connect_timeout 30  router_id MASTER-HA  }  vrrp_script chk_mysql_port {     #检测 mysql 服务是否在运行。有很多方式，比如进程，用脚本检测等等      script &quot;/opt/chk_mysql.sh&quot;   #这里通过脚本监测      interval 2                   #脚本执行间隔，每 2s 检测一次      weight -5                    #脚本结果导致的优先级变更，检测失败（脚本返回非 0）则优先级 -5      fall 2                       #检测连续 2 次失败才算确定是真失败。会用 weight 减少优先级（1-255 之间）      rise 1                       #检测 1 次成功就算成功。但不修改优先级  }  vrrp_instance VI_1 {      state MASTER      interface eth0               #指定虚拟 ip 的网卡接口      mcast_src_ip 192.168.1.101      virtual_router_id 51         #路由器标识，MASTER 和 BACKUP 必须是一致的      priority 101                 #定义优先级，数字越大，优先级越高，在同一个 vrrp_instance 下，MASTER 的优先级必须大于 BACKUP 的优先级。这样 MASTER 故障恢复后，就可以将 VIP 资源再次抢回来      advert_int 1      authentication {          auth_type PASS          auth_pass 1111      }      virtual_ipaddress {192.168.1.110}      track_script {chk_mysql_port}    }# 编写 keepalived 检测脚本$ vim /opt/chk_mysql.sh  #!/bin/bash  counter=$(netstat -na|grep &quot;LISTEN&quot;|grep &quot;3306&quot;|wc -l)  if [&quot;${counter}&quot; -eq 0 ]; then      /etc/init.d/keepalived stop  fi# 授权$ chmod 755 /opt/chk_mysql.sh# 启动 keepalived$ /etc/init.d/keepalived start</code></pre></li><li><p> 配置防火墙规则 </p><pre><code class="bash"># 在 Master1、Master2 中做相同操作$ vim /etc/sysconfig/iptables  # 加入如下三行配置  -A INPUT -s 182.148.15.0/24 -d 224.0.0.18 -j ACCEPT       #允许组播地址通信  -A INPUT -s 182.148.15.0/24 -p vrrp -j ACCEPT             #允许 VRRP（虚拟路由器冗余协）通信  -A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT    #开放 mysql 的 3306 端口# 重启防火墙$ /etc/init.d/iptables restart</code></pre></li></ul><h3 id="Mysql-Keepalived- 故障转义高可用测试"><a href="#Mysql-Keepalived- 故障转义高可用测试" class="headerlink" title="Mysql Keepalived 故障转义高可用测试"></a>Mysql Keepalived 故障转义高可用测试 </h3><ul><li><p> 使用客户端连接 keepalived 所创建的 vip，查看是否可以连接并看到对应的数据.</p><pre><code class="bash">$ mysql -h192.168.1.110 -uroot -p123456mysql&gt; use my_local;mysql&gt; select * from user;+----|------------|------------------|-------------|----------+| id | name       | email            | phone       | remark   |+----|------------|------------------|-------------|----------+|  1 | Wang Liang | 727474430@qq.com | 18888888888 | 管理员    ||  2 | Wang Er    | 727474430@qq.com | 18666666666 | 普通用户  ||  3 | Wang San   | 727474430@qq.com | 18555555555 | 正常人   |+----|------------|------------------|-------------|----------+</code></pre></li><li><p> 查看当前 vip 所在地址 </p><pre><code class="bash"># 因为默认 vip 是创建在 master1 上的，所以我们首先在 master1 上执行$ ip addr  eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000  link/ether 52:54:00:3c:25:42 brd ff:ff:ff:ff:ff:ff  inet 192.168.1.100/27 brd 182.148.15.255 scope global eth0  inet 192.168.1.110/32 scope global eth0                              // 这个 32 位子网掩码的 vip 地址表示该资源目前还在 master1 机器上  inet 192.168.1.100/27 brd 82.48.115.255 scope global secondary eth0:0  inet6 fe80::5054:ff:fe3c:2542/64 scope link  valid_lft forever preferred_lft forever# 停止 Master1 上的 mysql 服务，根据配置如果 mysql 服务停止了，keepalived 也随之停止，然后 vip 将会漂移到 Master2 上.$ /etc/init.d/mysql stop  eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000  link/ether 52:54:00:3c:25:42 brd ff:ff:ff:ff:ff:ff  inet 192.168.1.100/27 brd 182.148.15.255 scope global eth0  inet 192.168.1.100/27 brd 82.48.115.255 scope global secondary eth0:0  inet6 fe80::5054:ff:fe3c:2542/64 scope link  valid_lft forever preferred_lft forever# 如上，如果 32 位子网掩码的 vip 没有了，就证明只是 vip 在 Master1 上已经停止# 查看 Master1 的系统日志，可以看到 vip 资源切换的过程$ tail -f /var/log/message  Apr 15 17:17:43 localhost Keepalived_vrrp[23037]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:17:48 localhost Keepalived_vrrp[23037]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:17:48 localhost Keepalived_vrrp[23037]: VRRP_Instance(VI_1) Sending/queueing gratuitous ARPs on eth0 for 192.168.1.110  Apr 15 17:17:48 localhost Keepalived_vrrp[23037]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:17:48 localhost Keepalived_vrrp[23037]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:17:48 localhost Keepalived_vrrp[23037]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:17:48 localhost Keepalived_vrrp[23037]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:39 localhost Keepalived_healthcheckers[23036]: Stopped  Apr 15 17:30:39 localhost Keepalived_vrrp[23037]: VRRP_Instance(VI_1) sent 0 priority  Apr 15 17:30:39 localhost Keepalived_vrrp[23037]: VRRP_Instance(VI_1) removing protocol VIPs.# 此时切换到 Master2 上执行$ ip addr  eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000  link/ether 52:54:00:3c:25:42 brd ff:ff:ff:ff:ff:ff  inet 192.168.1.101/27 brd 182.148.15.255 scope global eth0  inet 192.168.1.110/32 scope global eth0                              // 这个 32 位子网掩码的 vip 地址表示该资源目前还在 master2 机器上  inet6 fe80::5054:ff:fe3c:2542/64 scope link  valid_lft forever preferred_lft forever# 查看 Master2 的系统日志，可以看到 vip 资源切换的过程$ tail -f /var/log/message  Apr 15 17:30:41 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:41 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:41 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:41 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: VRRP_Instance(VI_1) Sending/queueing gratuitous ARPs on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110# 再次启动 Master1 上的 mysql 服务、然后启动 keepalived 服务，我们可以看到 vip 此时漂移回 Master1 服务器上$ /etc/init.d/mysql start$ /etc/init.d/keepalived start$ ip addr  eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000  link/ether 52:54:00:3c:25:42 brd ff:ff:ff:ff:ff:ff  inet 192.168.1.100/27 brd 182.148.15.255 scope global eth0  inet 192.168.1.110/32 scope global eth0                              // 这个 32 位子网掩码的 vip 地址表示该资源目前还在 master1 机器上  inet 192.168.1.100/27 brd 82.48.115.255 scope global secondary eth0:0  inet6 fe80::5054:ff:fe3c:2542/64 scope link  valid_lft forever preferred_lft forever# 查看日志$ tail -f /var/log/message  Apr 15 17:30:41 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:41 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:41 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:41 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: VRRP_Instance(VI_1) Sending/queueing gratuitous ARPs on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110# 在查看 Master2 上，vip 已经不存在了，漂移回 Master1 上了$ ip addr  eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000  link/ether 52:54:00:3c:25:42 brd ff:ff:ff:ff:ff:ff  inet 192.168.1.101/27 brd 182.148.15.255 scope global eth0  inet 192.168.1.101/27 brd 82.48.115.255 scope global secondary eth0:0  inet6 fe80::5054:ff:fe3c:2542/64 scope link  valid_lft forever preferred_lft forever# 查看日志$ tail -f /var/log/message  Apr 15 17:30:41 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: VRRP_Instance(VI_1) Sending/queueing gratuitous ARPs on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:40:41 localhost Keepalived_vrrp[8731]: VRRP_Instance(VI_1) Received advert with higher priority 101, ours 99  Apr 15 17:40:41 localhost Keepalived_vrrp[8731]: VRRP_Instance(VI_1) Entering BACKUP STATE  Apr 15 17:40:41 localhost Keepalived_vrrp[8731]: VRRP_Instance(VI_1) removing protocol VIPs.# 同样如果停止 Master1 或 Master2 上的 Keepalived 服务，vip 同样也会漂移，再次启动 Keepalived 服务，vip 会再次漂移回来.</code></pre></li></ul><h5 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q &amp; A"></a>Q &amp; A</h5><ul><li><p> 单向同步:<br> 可以重新执行 change master 同步操作，只不过这样同步后，只能同步在此之后的数据，不能能同步之前丢失的数据.</p></li><li><p> 主从报错:</p><pre><code class="bash"># 通过命令查询错误信息，主要查看一下字段mysql&gt; show slave status \G;       Slave_IO_Running: Yes       Slave_SQL_Running: No       Last_Error: 1008       Last_Error: Error Message &#39;Can&#39;t drop database &#39;lcp&#39;; database doesn&#39;t exist&#39; on query. Default database: &#39;lcp&#39;. Query: &#39;drop database lcp&#39;# 通过以上信息看出来，是数据库不存在而导致的主从查询失败. 原因是在主库和从库同时做了相同的操作也导致的报错. 解决这个问题，我们需要先查看一下错误日志，然后定位到问题所在的位置，在然后找一下一共有多少条错误，最后将 binlog 指针下移错误次数位置即可解决.# 查看错误日志文件地址mysql&gt; show global variables like &#39;%log%&#39;;# 查看错误日志文$ cat error.log# 执行 binlog 指针下移 2 位mysql&gt; stop slave;mysql&gt; set global_sql_slave_skip_counter=2mysql&gt; start slave;# 再次查看主从状态mysql&gt; show slave status \G;       Slave_IO_Running: Yes       Slave_SQL_Running: Yes</code></pre></li></ul><h5 id="抢占模式"><a href="# 抢占模式" class="headerlink" title="抢占模式:"></a> 抢占模式:</h5><ul><li><p> 主服务正常工作时，虚拟 IP 会在主上，备不提供服务，当主服务优先级低于备的时候，备会自动抢占虚拟 IP，这时，主不提供服务，备提供服务。也就是说，工作在抢占模式下，不分主备，只管优先级.</p></li><li><p> 这种方式通过参数 nopreempt（一般设置在 advert_int 的那一行下面）来控制。不管 priority 优先级，只要 MASTER 机器发生故障，VIP 资源就会被切换到 BACKUP 上。并且当 MASTER 机器恢复后，也不会去将 VIP 资源抢占回来，直至 BACKUP 机器发生故障时，才能自动切换回来.</p></li><li><p>nopreempt 这个参数只能用于 state 为 backup 的情况，所以在配置的时候要把 master 和 backup 的 state 都设置成 backup，这样才会实现 keepalived 的非抢占模式！</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Mysql</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>MySQL-Command</title>
    <link href="/2020/03/13/MySQL-Command/"/>
    <url>/2020/03/13/MySQL-Command/</url>
    
    <content type="html"><![CDATA[<center> <font face="黑体" size="6">MySQL-Command</font> </center><hr><a id="more"></a><h5 id="Other-Related"><a href="#Other-Related" class="headerlink" title="Other Related"></a>Other Related</h5><table><thead><tr><th> 命令 </th><th> 含义 </th><th> 常用 </th></tr></thead><tbody><tr><td>show processlist</td><td> 查看当前链接此数据库的进程信息 </td><td>show processlist</td></tr><tr><td>show profile</td><td> 查询当前会话中最后一条语句执行的资源使用情况，如果显示空，表示未开始 profile，开启 profile set profling=1</td><td>profile</td></tr><tr><td>show profiles</td><td> 以列表形式展示服务器中最近执行的语句资源使用情况，显示记录数量由 profiling_history_size 控制，默认 15 条 </td><td>profiles</td></tr><tr><td>show profile cpu,swaps for query queryId</td><td> 查询指定 query 语句的指定资源使用情况（这里是 CPU、SWAPS）</td><td>show profile cpu,swaps for query 1</td></tr><tr><td>show variables like ‘%engine%’</td><td> 查看 MySQL 默认引擎 </td><td>show variables like ‘%engine%’</td></tr><tr><td>show variables like ‘%query_cache%’</td><td> 查看 是否开启查询缓存 <code>have_query_cache</code> 是否支持缓存 <code>query_cache_type</code> 是否开启缓存 </td><td>show variables like ‘%query_cache%’</td></tr><tr><td>show variables like ‘%buffer_pool%’</td><td> 查看页内存信息 </td><td>show variables like ‘%buffer_pool%’</td></tr></tbody></table><ul><li><code>show processlist</code></li></ul><pre><code class="mysql">show processlist;+------+------+-----------------+------+---------+------+----------+------------------+| Id   | User | Host            | db   | Command | Time | State    | Info             |+------+------+-----------------+------+---------+------+----------+------------------+| 1175 | root | localhost:49797 | test | Query   | 0    | starting | show processlist || 1182 | root | localhost:50587 | test | Query   | 0    | &lt;null&gt;   | CALL batchInsert || 1183 | root | localhost:50629 | test | Sleep   | 294  |          | &lt;null&gt;           |+------+------+-----------------+------+---------+------+----------+------------------+</code></pre><ul><li><code>show profile</code></li></ul><pre><code class="mysql">show profile;+----------------------+----------+| Status               | Duration |+----------------------+----------+| starting             | 0.000031 || checking permissions | 0.000003 || Opening tables       | 0.001230 || init                 | 0.000017 || System lock          | 0.000004 || optimizing           | 0.000003 || statistics           | 0.000008 || preparing            | 0.000014 || executing            | 0.000003 || Sending data         | 1.645334 || end                  | 0.000004 || query end            | 0.000009 || closing tables       | 0.000004 || freeing items        | 0.000032 || cleaning up          | 0.000028 |+----------------------+----------+# 通过 query_id 查询show profile cpu, swaps for query 1;+----------------+----------+----------+------------+-------+| Status         | Duration | CPU_user | CPU_system | Swaps |+----------------+----------+----------+------------+-------+| starting       | 0.000517 | 0.000227 | 0.000333   | 0     || query end      | 0.000003 | 0.000002 | 0.000002   | 0     || closing tables | 0.000002 | 0.000001 | 0.000000   | 0     || freeing items  | 0.000014 | 0.000003 | 0.000012   | 0     || cleaning up    | 0.000005 | 0.000004 | 0.000000   | 0     |+----------------+----------+----------+------------+-------+</code></pre><ul><li><code>show profiles</code></li></ul><pre><code class="mysql">show profiles;+----------+--------------+-----------------------------------+| Query_ID | Duration     | Query                             |+----------+--------------+-----------------------------------+| 1        |     0.000844 | show variables like &#39;profiling%&#39;  || 2        |     0.00387  | select * from score               || 3        |     1.646724 | select count(*) from user         |+----------+--------------+-----------------------------------+</code></pre><ul><li><code>show variables</code></li></ul><pre><code class="mysql">show variables like &#39;%engine%&#39;;+----------------------------------+--------+| Variable_name                    | Value  |+----------------------------------+--------+| default_storage_engine           | InnoDB || default_tmp_storage_engine       | InnoDB || disabled_storage_engines         |        || internal_tmp_disk_storage_engine | InnoDB |+----------------------------------+--------+show variables like &#39;%query_cache%&#39;;+------------------------------+---------+| Variable_name                | Value   |+------------------------------+---------+| have_query_cache             | YES     || query_cache_limit            | 1048576 || query_cache_min_res_unit     | 4096    || query_cache_size             | 1048576 || query_cache_type             | OFF     || query_cache_wlock_invalidate | OFF     |+------------------------------+---------+show variables like &#39;%buffer_pool%&#39;;+-------------------------------------+----------------+| Variable_name                       | Value          |+-------------------------------------+----------------+| innodb_buffer_pool_chunk_size       | 134217728      || innodb_buffer_pool_dump_at_shutdown | ON             || innodb_buffer_pool_dump_now         | OFF            || innodb_buffer_pool_dump_pct         | 25             || innodb_buffer_pool_filename         | ib_buffer_pool || innodb_buffer_pool_instances        | 1              || innodb_buffer_pool_load_abort       | OFF            || innodb_buffer_pool_load_at_startup  | ON             || innodb_buffer_pool_load_now         | OFF            || innodb_buffer_pool_size             | 134217728      |+-------------------------------------+----------------+</code></pre><hr><h5 id="Table-Related"><a href="#Table-Related" class="headerlink" title="Table Related"></a>Table Related</h5><table><thead><tr><th> 命令 </th><th> 含义 </th><th> 常用 </th></tr></thead><tbody><tr><td>describe <code>tableName</code> / desc <code>tableName</code></td><td> 查看表的详情信息 </td><td>describe user; / desc user;</td></tr><tr><td>show create table <code>tableName</code></td><td> 查看表的创建语句 </td><td>show create table user;</td></tr><tr><td>create table <code>tableName</code> (<code>column</code> type desc)</td><td> 创建表 </td><td>create table <code>user</code> (id int primary key)</td></tr><tr><td>drop table <code>tableName</code></td><td> 删除表 </td><td>drop table <code>user</code></td></tr></tbody></table><ul><li><code>describe table</code></li></ul><pre><code class="mysql">describe user;+-------+--------------+------+-----+---------+----------------+| Field | Type         | Null | Key | Default | Extra          |+-------+--------------+------+-----+---------+----------------+| id    | int(11)      | NO   | PRI | NULL    | auto_increment || name  | varchar(32)  | NO   |     | NULL    |                || age   | varchar(32)  | NO   |     | NULL    |                || city  | varchar(32)  | NO   |     | NULL    |                || tmp   | varchar(255) | YES  |     | NULL    |                |+-------+--------------+------+-----+---------+----------------+# desc 等价于 describedesc user;+-------+--------------+------+-----+---------+----------------+| Field | Type         | Null | Key | Default | Extra          |+-------+--------------+------+-----+---------+----------------+| id    | int(11)      | NO   | PRI | NULL    | auto_increment || name  | varchar(32)  | NO   |     | NULL    |                || age   | varchar(32)  | NO   |     | NULL    |                || city  | varchar(32)  | NO   |     | NULL    |                || tmp   | varchar(255) | YES  |     | NULL    |                |+-------+--------------+------+-----+---------+----------------+</code></pre><ul><li><code>show create table</code></li></ul><pre><code class="mysql">show create table user;+-------+------------------------------------------------------------+| Table | Create Table                                               |+-------+------------------------------------------------------------+| user  | CREATE TABLE `user` (                                      ||  `id` int(11) NOT NULL AUTO_INCREMENT,                             ||  `name` varchar(32) CHARACTER SET utf8 NOT NULL,                   ||  `age` varchar(32) CHARACTER SET utf8 NOT NULL,                    ||  `city` varchar(32) CHARACTER SET utf8 NOT NULL,                   ||  `tmp` varchar(255) DEFAULT NULL,                                  ||  PRIMARY KEY (`id`)                                                || ) ENGINE=InnoDB AUTO_INCREMENT=18 DEFAULT CHARSET=latin1           |+-------+------------------------------------------------------------+1 row in set (0.00 sec)</code></pre><ul><li><code>create table</code></li></ul><pre><code class="mysql">CREATE TABLE `user` (`id` int(11) NOT NULL AUTO_INCREMENT,  `name` varchar(32) CHARACTER SET utf8 NOT NULL,  `age` varchar(32) CHARACTER SET utf8 NOT NULL,  PRIMARY KEY (`id`));</code></pre><ul><li><code>drop table</code></li></ul><pre><code class="mysql">drop table user;Query OK, 0 rows affected (0.05 sec)select * from user;ERROR 1146 (42S02): Table &#39;backup.user&#39; doesn&#39;t exist</code></pre><hr><h5 id="Binlog-Related"><a href="#Binlog-Related" class="headerlink" title="Binlog Related"></a>Binlog Related</h5><table><thead><tr><th> 命令 </th><th> 含义 </th><th> 常用 </th></tr></thead><tbody><tr><td>show variables like</td><td> 查询变量相关配置信息 </td><td>show variables like ‘%log_bin%’</td></tr><tr><td>show binlog events in ‘binlogfile’\G;</td><td> 查询 binlog 文件格式化后内容 </td><td></td></tr><tr><td>mysqlbinlog -v binlogFile</td><td> 查询 binlog 文件内容 </td><td>mysqlbinlog -v mysql-bin.000001</td></tr></tbody></table><ul><li><code>show variable binlog</code></li></ul><pre><code class="mysql">show variables like &#39;%log_bin%&#39;;+---------------------------------+--------------------------------+| Variable_name                   | Value                          |+---------------------------------+--------------------------------+| log_bin                         | ON                             || log_bin_basename                | /var/lib/mysql/mysql-bin       || log_bin_index                   | /var/lib/mysql/mysql-bin.index || log_bin_trust_function_creators | OFF                            || log_bin_use_v1_row_events       | OFF                            || sql_log_bin                     | ON                             |+---------------------------------+--------------------------------+</code></pre><ul><li><code>show binlog events</code></li></ul><pre><code class="mysql"># 查看当前 binlog 文件show master status \G;*************************** 1. row ***************************             File: mysql-bin.000001         Position: 10178     Binlog_Do_DB: backup Binlog_Ignore_DB:Executed_Gtid_Set:# 查询 binlog 详情show binlog events in &#39;mysql-bin.000001&#39;\G;...*************************** 44. row ***************************   Log_name: mysql-bin.000001        Pos: 2848 Event_type: Table_map  Server_id: 1End_log_pos: 2906       Info: table_id: 143 (backup.user)*************************** 45. row ***************************   Log_name: mysql-bin.000001        Pos: 2906 Event_type: Write_rows  Server_id: 1End_log_pos: 2951       Info: table_id: 143 flags: STMT_END_F*************************** 46. row ***************************   Log_name: mysql-bin.000001        Pos: 2951 Event_type: Xid  Server_id: 1End_log_pos: 2982       Info: COMMIT /* xid=808 */*************************** 47. row ***************************   Log_name: mysql-bin.000001        Pos: 2982 Event_type: Anonymous_Gtid  Server_id: 1End_log_pos: 3047       Info: SET @@SESSION.GTID_NEXT= &#39;ANONYMOUS&#39;*************************** 48. row ***************************   Log_name: mysql-bin.000001        Pos: 3047 Event_type: Query  Server_id: 1End_log_pos: 3145       Info: drop database backup...</code></pre><ul><li><code>mysqlbinlog -v</code></li></ul><pre><code class="bash">...# at 2906#200313 14:03:59 server id 1  end_log_pos 2951 CRC32 0x17496f50         Write_rows: table id 143 flags: STMT_END_FBINLOG &#39;z5JrXhMBAAAAOgAAAFoLAAAAAI8AAAAAAAEABmJhY2t1cAAEdXNlcgAEAw8PDwZgAGAAYAAAj7jcTQ==z5JrXh4BAAAALQAAAIcLAAAAAI8AAAAAAAEAAgAE//ARAAAAAAI0MABQb0kX&#39;/*!*/;### INSERT INTO `backup`.`user`### SET###   @1=17###   @2=&#39;&#39;###   @3=&#39;40&#39;###   @4=&#39;&#39;# at 2951#200313 14:03:59 server id 1  end_log_pos 2982 CRC32 0x76e6e0db         Xid = 808COMMIT/*!*/;# at 2982#200313 14:04:38 server id 1  end_log_pos 3047 CRC32 0x00bc8281         Anonymous_GTID  last_committed=10       sequence_number=11      rbr_only=noSET @@SESSION.GTID_NEXT= &#39;ANONYMOUS&#39;/*!*/;# at 3047#200313 14:04:38 server id 1  end_log_pos 3145 CRC32 0xbc32a2d6         Query   thread_id=41    exec_time=0     error_code=0SET TIMESTAMP=1584108278/*!*/;SET @@session.pseudo_thread_id=41/*!*/;drop database backup/*!*/;# at 3145#200313 14:06:59 server id 1  end_log_pos 3192 CRC32 0x68a2c9ea         Rotate to mysql-bin.000002  pos: 4SET @@SESSION.GTID_NEXT= &#39;AUTOMATIC&#39; /* added by mysqlbinlog */ /*!*/;DELIMITER ;# End of log file/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/;...</code></pre><hr><h5 id="Index-Related"><a href="#Index-Related" class="headerlink" title="Index Related"></a>Index Related</h5><table><thead><tr><th> 命令 </th><th> 含义 </th><th> 常用 </th></tr></thead><tbody><tr><td>show index from tableName</td><td> 查看表的索引信息 </td><td>show index from user;</td></tr><tr><td>alter table <code>tableName</code> add primary key (<code>column</code>)</td><td> 添加主键索引 </td><td>alter table user add primary key (<code>id</code>);</td></tr><tr><td>alter table <code>tableName</code> add unique (<code>column</code>)</td><td> 添加唯一索引 </td><td>alter table user add unique (<code>name</code>);</td></tr><tr><td>alter table <code>tableName</code> add fulltext (<code>column</code>)</td><td> 添加全文索引 </td><td>alter table user add fulltext (<code>name</code>);</td></tr><tr><td>alter table <code>tableName</code> add index <code>indexName</code> (<code>column</code>)</td><td> 添加普通索引 </td><td>alter table user add index idx_name (<code>name</code>);</td></tr><tr><td>alter table <code>tableName</code> add index <code>indexName</code> (<code>column1</code>, <code>column2</code>, …)</td><td> 添加联合索引 </td><td>alter table user add index idx_name (<code>name</code>,<code>age</code>,<code>sex</code>);</td></tr><tr><td>alter table <code>tableName</code> add constraint FK_ID foreign key (<code>column</code>) references tableName (<code>column</code>)</td><td> 添加外建 </td><td>alter table user add constraint FK_SID foreign key (<code>sid</code>) references score (<code>id</code>);</td></tr><tr><td>alter table <code>tableName</code> drop primary key</td><td> 删除主键 </td><td>alter table user drop primary key;</td></tr><tr><td>alter table <code>tableName</code> drop index <code>indexName</code></td><td> 删除索引（包含唯一索引）</td><td>alter table user drop index <code>name</code>;</td></tr><tr><td>alter table <code>tableName</code> drop foreign key FK_ID</td><td> 删除外建 </td><td>alter table user drop foreign key FK_SID;</td></tr></tbody></table><ul><li><code>show index</code></li></ul><pre><code class="mysql">show index from student;+---------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+| Table   | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment |+---------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+| student |          0 | PRIMARY  |            1 | std_id      | A         |           2 |     NULL | NULL   |      | BTREE      |         |               |+---------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+</code></pre><ul><li><code>alter table add</code></li></ul><pre><code class="mysql">-- 添加主键索引，注意查看 Key 字段desc student;+----------+-------------+------+-----+---------+-------+| Field    | Type        | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+-------+| std_id   | int(11)     | NO   |     | NULL    |       || std_name | varchar(32) | YES  |     | NULL    |       |+----------+-------------+------+-----+---------+-------+alter table student add primary key (`std_id`);Query OK, 0 rows affected (0.11 sec)desc student;+----------+-------------+------+-----+---------+-------+| Field    | Type        | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+-------+| std_id   | int(11)     | NO   | PRI | NULL    |       || std_name | varchar(32) | YES  |     | NULL    |       |+----------+-------------+------+-----+---------+-------+-- 添加唯一索引，注意查看 Key 字段alter table student add unique (`std_name`);Query OK, 0 rows affected (0.05 sec)desc student;+----------+-------------+------+-----+---------+-------+| Field    | Type        | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+-------+| std_id   | int(11)     | NO   | PRI | NULL    |       || std_name | varchar(32) | YES  | UNI | NULL    |       |+----------+-------------+------+-----+---------+-------+-- 添加普通索引，注意查看 Key 字段alter table student add index idx_std_name (`std_name`);Query OK, 0 rows affected (0.04 sec)desc student;+----------+-------------+------+-----+---------+-------+| Field    | Type        | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+-------+| std_id   | int(11)     | NO   | PRI | NULL    |       || std_name | varchar(32) | YES  | MUL | NULL    |       |+----------+-------------+------+-----+---------+-------+-- 添加复合索引show index from student;+---------+------------+-------------+--------------+-------------+| Table   | Non_unique | Key_name    | Seq_in_index | Column_name |+---------+------------+-------------+--------------+-------------+| student |          0 | PRIMARY     |            1 | std_id      || student |          1 | idx_id_name |            1 | std_id      || student |          1 | idx_id_name |            2 | std_name    |+---------+------------+-------------+--------------+-------------+</code></pre><ul><li><code>alter table drop</code></li></ul><pre><code class="mysql">-- 删除主键索引，注意查看 Key 字段desc student;+----------+-------------+------+-----+---------+-------+| Field    | Type        | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+-------+| std_id   | int(11)     | NO   | PRI | NULL    |       || std_name | varchar(32) | YES  |     | NULL    |       |+----------+-------------+------+-----+---------+-------+alter table student drop primary key;Query OK, 3 rows affected (0.08 sec)desc student;+----------+-------------+------+-----+---------+-------+| Field    | Type        | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+-------+| std_id   | int(11)     | NO   | MUL | NULL    |       || std_name | varchar(32) | YES  |     | NULL    |       |+----------+-------------+------+-----+---------+-------+-- 删除索引（包含唯一索引），注意查看 Key 字段desc student;+----------+-------------+------+-----+---------+-------+| Field    | Type        | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+-------+| std_id   | int(11)     | NO   | PRI | NULL    |       || std_name | varchar(32) | YES  | MUL | NULL    |       |+----------+-------------+------+-----+---------+-------+alter table student drop index idx_stu_name;Query OK, 0 rows affected (0.03 sec)desc student;+----------+-------------+------+-----+---------+-------+| Field    | Type        | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+-------+| std_id   | int(11)     | NO   | PRI | NULL    |       || std_name | varchar(32) | YES  |     | NULL    |       |+----------+-------------+------+-----+---------+-------+</code></pre><hr><h5 id="Join-Search-Related"><a href="#Join-Search-Related" class="headerlink" title="Join Search Related"></a>Join Search Related</h5><table><thead><tr><th> 命令 </th><th> 含义 </th><th> 常用 </th></tr></thead><tbody><tr><td>join</td><td> 内链接（只查询两张表关联字段相等的记录）</td><td>select u.name, s.score from user u join score s on u.sid = s.id;</td></tr><tr><td>inner join</td><td> 内链接（只查询两张表关联字段相等的记录）</td><td>select u.name, s.score from user u inner join score s on u.sid = s.id;</td></tr><tr><td>left join</td><td> 左链接（以左表为主，两张表关联字段相等则显示右表数据，否则补 null）</td><td>select u.name, s.score from user u left join score s on u.sid = s.id;</td></tr><tr><td>left outer join</td><td> 左链接（以左表为主，两张表关联字段相等则显示右表数据，否则补 null）</td><td>select u.name, s.score from user u left outer join score s on u.sid = s.id;</td></tr><tr><td>right join</td><td> 右链接（以右表为主，两张表关联字段相等则显示左表数据，否则补 null）</td><td>select u.name, s.score from user u right join score s on u.sid = s.id;</td></tr><tr><td>right outer join</td><td> 右链接（以右表为主，两张表关联字段相等则显示左表数据，否则补 null）</td><td>select u.name, s.score from user u right outer join score s on u.sid = s.id;</td></tr><tr><td>full join</td><td> 全链接（将查询两张表的全部记录）</td><td>select u.name, s.score from user u full join score s on u.sid = s.id;</td></tr></tbody></table><ul><li> 准备数据 </li></ul><pre><code class="mysql">select * from user;+----+----------+| id | name     |+----+----------+| 1  | zhangsan || 2  | lisi     || 3  | wangwu   |+----+----------+select * from score;+----+-------+-----+| id | score | uid |+----+-------+-----+| 1  | 80    | 1   || 2  | 88    | 2   || 3  | 100   | 4   |+----+-------+-----+</code></pre><ul><li> 内链接 </li></ul><pre><code class="mysql">select u.name, s.score from `user` u join score s on u.id = s.uid;+----------+-------+| name     | score |+----------+-------+| zhangsan | 80    || lisi     | 88    |+----------+-------+select u.name, s.score from `user` u inner join score s on u.id = s.uid;+----------+-------+| name     | score |+----------+-------+| zhangsan | 80    || lisi     | 88    |+----------+-------+</code></pre><ul><li> 左链接 </li></ul><pre><code class="mysql">select u.name, s.score from`user`u left join score s on u.id = s.uid;+----------+--------+| name     | score  |+----------+--------+| zhangsan | 80     || lisi     | 88     || wangwu   | &lt;null&gt; |+----------+--------+select u.name, s.score from`user`u left outer join score s on u.id = s.uid;+----------+--------+| name     | score  |+----------+--------+| zhangsan | 80     || lisi     | 88     || wangwu   | &lt;null&gt; |+----------+--------+</code></pre><ul><li> 右链接 </li></ul><pre><code class="mysql">select u.name, s.score from `user` u right join score s on u.id = s.uid;+----------+-------+| name     | score |+----------+-------+| zhangsan | 80    || lisi     | 88    || &lt;null&gt;   | 100   |+----------+-------+select u.name, s.score from `user` u right outer join score s on u.id = s.uid;+----------+-------+| name     | score |+----------+-------+| zhangsan | 80    || lisi     | 88    || &lt;null&gt;   | 100   |+----------+-------+</code></pre><ul><li> 全链接 </li></ul><pre><code class="mysql">select u.name,s.score from `user` u left join score s on u.id = s.uid union select u.name, s.score from user u right join score s on u.id = s.uid;+----------+--------+| name     | score  |+----------+--------+| zhangsan | 80     || lisi     | 88     || wangwu   | &lt;null&gt; || &lt;null&gt;   | 100    |+----------+--------+</code></pre><p><strong>note</strong>: MySQL 不支持 full join 需要使用 union 方式代替 </p><hr><div aligh="center">    <img src="http://qiniu.raindrop-wl.cn/join-search.png" srcset="/img/loading.gif" width="100%"></div>]]></content>
    
    
    <categories>
      
      <category>MySQL</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>MySQL- 故障恢复（二）</title>
    <link href="/2020/03/11/MySQL-%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
    <url>/2020/03/11/MySQL-%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<center> <font face="黑体" size="6">MySQL 故障恢复方法（二）</font> </center><hr><a id="more"></a><h5 id="背景"><a href="# 背景" class="headerlink" title="背景"></a>背景</h5><ul><li>Master 192.168.0.1</li><li>Slave1 192.168.0.2</li><li>Slave2 192.168.0.3</li></ul><p>小明 11:00 接到告警通知，Master 节点出现异常，因为基于 MyCat 做了故障切换，目前服务应该可以正常 <br> 使用。因为此时 Slave1 节点可以负责读写工作。就在庆幸架构做的好时，接到用户反馈，线上服务已不可用<br>，排查后发现数据库被删。此时小明内心一万只草泥马飘过。</p><div aligh="center">    <img src="http://qiniu.raindrop-wl.cn/MySQL.png" srcset="/img/loading.gif" width="100%"></div><p><strong>note:</strong> 线上环境 MySQL 架构为一主两从，使用 MyCat 作为中间件配置读写分离。</p><hr><h5 id="解决方案"><a href="# 解决方案" class="headerlink" title="解决方案"></a>解决方案</h5><blockquote><p>因为此时是数据库被删，那么就不可以简单粗暴使用备份的方式解决了。我们需要使用 Binlog 日志到方式来 <br> 恢复数据。说干就干，步骤如下。</p></blockquote><ol><li><strong>停止 MyCat 防止数据写入</strong></li></ol><pre><code class="bash">$ mycat stop</code></pre><ol start="2"><li><strong>中断当前 Binlog</strong></li></ol><pre><code class="mysql">-- flush logs 命令会中断当前 binlog 文件写入，并新启一个 binlog 文件接收后续命令show master status \G;*************************** 1. row ***************************                     File: mysql-bin.000001                 Position: 439             Binlog_Do_DB: backup         Binlog_Ignore_DB:        Executed_Gtid_Set:flush logs;show master status \G;*************************** 1. row ***************************                     File: mysql-bin.000002                 Position: 154             Binlog_Do_DB: backup         Binlog_Ignore_DB:        Executed_Gtid_Set:</code></pre><ol start="3"><li><strong>查看备份文件 MASTER_LOG_POS 位置</strong></li></ol><pre><code class="bash"># 在备份 MySQL 时，一定要添加 `--master-data` 参数。$ more mysql-backup.sql...---- Position to start replication or point-in-time recovery from--CHANGE MASTER TO MASTER_LOG_FILE=&#39;mysql-bin.000001&#39;, MASTER_LOG_POS=1890;---- Table structure for table `user`--DROP TABLE IF EXISTS `user`;/*!40101 SET @saved_cs_client     = @@character_set_client */;/*!40101 SET character_set_client = utf8 */;CREATE TABLE `user` (`id` int(11) NOT NULL AUTO_INCREMENT,  `name` varchar(32) CHARACTER SET utf8 NOT NULL,  `age` varchar(32) CHARACTER SET utf8 NOT NULL,  `city` varchar(32) CHARACTER SET utf8 NOT NULL,  PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=14 DEFAULT CHARSET=latin1;/*!40101 SET character_set_client = @saved_cs_client */;...</code></pre><ol start="4"><li><strong>查看 Binlog 日志</strong></li></ol><pre><code class="mysql">-- 查看 binlog 信息show variables like &#39;%log_bin%&#39;;+---------------------------------+--------------------------------+| Variable_name                   | Value                          |+---------------------------------+--------------------------------+| log_bin                         | ON                             || log_bin_basename                | /var/lib/mysql/mysql-bin       || log_bin_index                   | /var/lib/mysql/mysql-bin.index || log_bin_trust_function_creators | OFF                            || log_bin_use_v1_row_events       | OFF                            || sql_log_bin                     | ON                             |+---------------------------------+--------------------------------+# 第一种方式，使用 show binlog 命令show binlog events in &#39;mysql-bin.000001&#39;\G;# 这里我们看到 drop databases backup 语句在 position 3047 开始位置...*************************** 44. row ***************************   Log_name: mysql-bin.000001        Pos: 2848 Event_type: Table_map  Server_id: 1End_log_pos: 2906       Info: table_id: 143 (backup.user)*************************** 45. row ***************************   Log_name: mysql-bin.000001        Pos: 2906 Event_type: Write_rows  Server_id: 1End_log_pos: 2951       Info: table_id: 143 flags: STMT_END_F*************************** 46. row ***************************   Log_name: mysql-bin.000001        Pos: 2951 Event_type: Xid  Server_id: 1End_log_pos: 2982       Info: COMMIT /* xid=808 */*************************** 47. row ***************************   Log_name: mysql-bin.000001        Pos: 2982 Event_type: Anonymous_Gtid  Server_id: 1End_log_pos: 3047       Info: SET @@SESSION.GTID_NEXT= &#39;ANONYMOUS&#39;*************************** 48. row ***************************   Log_name: mysql-bin.000001        Pos: 3047 Event_type: Query  Server_id: 1End_log_pos: 3145       Info: drop database backup...</code></pre><pre><code class="bash"># 第二种方式，查看 binlog 二进制文件。$ mysqlbinlog -v mysql-bin.000001# 主要查看 drop database backup 语句在 position 3047 开始...# at 2906#200313 14:03:59 server id 1  end_log_pos 2951 CRC32 0x17496f50         Write_rows: table id 143 flags: STMT_END_FBINLOG &#39;z5JrXhMBAAAAOgAAAFoLAAAAAI8AAAAAAAEABmJhY2t1cAAEdXNlcgAEAw8PDwZgAGAAYAAAj7jcTQ==z5JrXh4BAAAALQAAAIcLAAAAAI8AAAAAAAEAAgAE//ARAAAAAAI0MABQb0kX&#39;/*!*/;### INSERT INTO `backup`.`user`### SET###   @1=17###   @2=&#39;&#39;###   @3=&#39;40&#39;###   @4=&#39;&#39;# at 2951#200313 14:03:59 server id 1  end_log_pos 2982 CRC32 0x76e6e0db         Xid = 808COMMIT/*!*/;# at 2982#200313 14:04:38 server id 1  end_log_pos 3047 CRC32 0x00bc8281         Anonymous_GTID  last_committed=10       sequence_number=11      rbr_only=noSET @@SESSION.GTID_NEXT= &#39;ANONYMOUS&#39;/*!*/;# at 3047#200313 14:04:38 server id 1  end_log_pos 3145 CRC32 0xbc32a2d6         Query   thread_id=41    exec_time=0     error_code=0SET TIMESTAMP=1584108278/*!*/;SET @@session.pseudo_thread_id=41/*!*/;drop database backup/*!*/;# at 3145#200313 14:06:59 server id 1  end_log_pos 3192 CRC32 0x68a2c9ea         Rotate to mysql-bin.000002  pos: 4SET @@SESSION.GTID_NEXT= &#39;AUTOMATIC&#39; /* added by mysqlbinlog */ /*!*/;DELIMITER ;# End of log file/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/;...</code></pre><ol start="5"><li><p><strong>查找删除语句所在 position</strong></p><p><code>show binlog events in &#39;mysql-bin.000001&#39;\G;</code></p><div aligh="center">    <img src="http://qiniu.raindrop-wl.cn/pos1.png" srcset="/img/loading.gif" width="100%"></div><p><code>mysqlbinlog -v mysql-bin.000001</code></p> <div aligh="center">     <img src="http://qiniu.raindrop-wl.cn/pos2.png" srcset="/img/loading.gif" width="100%" "> </div></li><li><p><strong>创建数据库</strong></p></li></ol><pre><code class="mysql">-- Mastercreate database backup;show databases;+--------------------+| Database           |+--------------------+| information_schema || backup             || mysql              || performance_schema || sys                |+--------------------+-- Slave1、Slave2show databases;+--------------------+| Database           |+--------------------+| information_schema || backup             || mysql              || performance_schema || sys                |+--------------------+</code></pre><ol start="7"><li><strong>使用备份文件恢复数据</strong></li></ol><pre><code class="bash"># 指定数据库恢复，因为备份文件中可能有多个数据库$ mysql -uroot -p backup &lt; backup.sql</code></pre><pre><code class="mysql">-- 查看已恢复数据 Mastershow tables;+------------------+| Tables_in_backup |+------------------+| user             |+------------------+select * from user;+----+------+-----+------+| id | name | age | city |+----+------+-----+------+| 10 | 小黑 | 18  | N 市  || 11 | 小白 | 20  | N 市  || 12 | 小红 | 12  | X 市  || 13 | 小蓝 | 18  | X 市  |+----+------+-----+------+-- 查看已恢复数据 Slave1、Slave2show tables;+------------------+| Tables_in_backup |+------------------+| user             |+------------------+select * from user;+----+------+-----+------+| id | name | age | city |+----+------+-----+------+| 10 | 小黑 | 18  | N 市  || 11 | 小白 | 20  | N 市  || 12 | 小红 | 12  | X 市  || 13 | 小蓝 | 18  | X 市  |+----+------+-----+------+</code></pre><ol start="8"><li><strong>按照 Binlog 恢复到 position 之前位置</strong></li></ol><pre><code class="bash"># 首先我们需要记住备份文件中 MASTER_LOG_POS 位置 1890# 其次我们需要记住 binlog 日志中 drop 语句之前的 pos 位置 3047# 执行 mysqlbinlog 命令恢复数据，-d 指定数据库 --start-position 为备份文件中的pos 位置， --end-position 为 drop 语句前的 pos 位置。如果为报错则为执行成功$ mysqlbinlog -d backup --start-position 1890 --stop-position 3047 mysql-bin.000001 | mysql -uroot -p</code></pre><ol start="9"><li><strong>查询恢复数据</strong></li></ol><pre><code class="mysql">-- Masterselect * from user;+----+------+-----+------+| id | name | age | city |+----+------+-----+------+| 10 | 小黑 | 18  | N 市  || 11 | 小白 | 20  | N 市  || 12 | 小红 | 12  | X 市  || 13 | 小蓝 | 18  | X 市  || 14 | 小紫 | 13  | X 市  || 15 | 小粉 | 14  | z 市  || 16 | 小黄 | 22  | z 市  || 17 | 小绿 | 33  | z 市  |+----+------+-----+------+-- Slave1、Slave2select * from user;+----+------+-----+------+| id | name | age | city |+----+------+-----+------+| 10 | 小黑 | 18  | N 市  || 11 | 小白 | 20  | N 市  || 12 | 小红 | 12  | X 市  || 13 | 小蓝 | 18  | X 市  || 14 | 小紫 | 13  | X 市  || 15 | 小粉 | 14  | z 市  || 16 | 小黄 | 22  | z 市  || 17 | 小绿 | 33  | z 市  |+----+------+-----+------+</code></pre><ol start="10"><li><strong>开启 MyCat</strong></li></ol><pre><code class="bash">$ mycat start</code></pre><hr><h5 id="总结"><a href="# 总结" class="headerlink" title="总结"></a>总结</h5><ul><li>经过上面一系列到操作，最终恢复了数据和主从架构。这次我们使用了基于 binlog 二进制日志恢复数据的方法。这种方法操作上虽然会有复杂性，但是恢复数据的能力要比之前的暴力方式强得多。</li><li>当然，我们在日常数据库管理中，还是要按职能分配权限。不要以公司规模小、业务量不大、数据不多为接口给自己带来不必要的麻烦！</li></ul><div aligh="center">    <img src="http://qiniu.raindrop-wl.cn/over.png" srcset="/img/loading.gif" width="100%"></div>]]></content>
    
    
    <categories>
      
      <category>MySQL</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>MySQL- 故障恢复（一）</title>
    <link href="/2020/03/11/MySQL-%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <url>/2020/03/11/MySQL-%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<center> <font face="黑体" size="6">MySQL 故障恢复方法（一）</font> </center><hr><a id="more"></a><h5 id="背景"><a href="# 背景" class="headerlink" title="背景"></a>背景</h5><ul><li>Master 192.168.0.1</li><li>Slave1 192.168.0.2</li><li>Slave2 192.168.0.3</li></ul><p>小明 11:00 接到告警通知，Master 节点出现异常，因为基于 MyCat 做了故障切换，目前服务应该可以正常 <br> 使用。因为此时 Slave1 节点可以负责读写工作。半分钟后 Master 节点重启成功，MySQL 自动启动后，线上 <br> 服务开始报错，排查日志后发现，此时主从数据库数据已不同步，导致报错。</p><div aligh="center">    <img src="http://qiniu.raindrop-wl.cn/MySQL.png" srcset="/img/loading.gif" width="100%"></div><p><strong>note:</strong> 线上环境 MySQL 架构为一主两从，使用 MyCat 作为中间件配置读写分离。</p><hr><h5 id="解决方案"><a href="# 解决方案" class="headerlink" title="解决方案"></a>解决方案</h5><blockquote><p>因为此时只是数据不同步，那么可以确定的是，Slave1 节点的数据是最全的，那么简单粗暴使用备份的方式 <br> 恢复数据。说干就干，步骤如下。</p></blockquote><ol><li><strong>停止 MyCat 防止数据写入</strong></li></ol><pre><code class="bash">$ sh mycat stop</code></pre><ol start="2"><li><strong>停止主从复制</strong></li></ol><pre><code class="bash"># Slave1、Slave2mysql&gt; stop slave;mysql&gt; show slave status \G;*************************** 1. row ***************************               Slave_IO_State:                  Master_Host: 192.168.0.2                  Master_User: slave                  Master_Port: 3306                Connect_Retry: 60              Master_Log_File: mysql-bin.000002          Read_Master_Log_Pos: 2705               Relay_Log_File: 2af2354ad45b-relay-bin.000006                Relay_Log_Pos: 320        Relay_Master_Log_File: mysql-bin.000002             Slave_IO_Running: No            Slave_SQL_Running: No              Replicate_Do_DB: backup*************************** 1. row ***************************               Slave_IO_State:                  Master_Host: 192.168.0.3                  Master_User: slave                  Master_Port: 3306                Connect_Retry: 60              Master_Log_File: mysql-bin.000002          Read_Master_Log_Pos: 2705               Relay_Log_File: 2af2354ad45b-relay-bin.000006                Relay_Log_Pos: 320        Relay_Master_Log_File: mysql-bin.000002             Slave_IO_Running: No            Slave_SQL_Running: No              Replicate_Do_DB: backup</code></pre><ol start="3"><li><strong>重置主从关系</strong></li></ol><pre><code class="bash"># Mastermysql&gt; resrt master;mysql&gt; show master status \G;*************************** 1. row ***************************                         File: mysql-bin.000001                     Position: 154                 Binlog_Do_DB: backup             Binlog_Ignore_DB:            Executed_Gtid_Set:# Slave1、Slave2mysql&gt; reset slave;mysql&gt; show slave status \G;*************************** 1. row ***************************               Slave_IO_State:                  Master_Host: 192.168.0.2                  Master_User: slave                  Master_Port: 3306                Connect_Retry: 60              Master_Log_File:          Read_Master_Log_Pos: 4               Relay_Log_File: 2af2354ad45b-relay-bin.000001                Relay_Log_Pos: 4        Relay_Master_Log_File:             Slave_IO_Running: No            Slave_SQL_Running: No              Replicate_Do_DB: backup*************************** 1. row ***************************               Slave_IO_State:                  Master_Host: 192.168.0.3                  Master_User: slave                  Master_Port: 3306                Connect_Retry: 60              Master_Log_File:          Read_Master_Log_Pos: 4               Relay_Log_File: 2af2354ad45b-relay-bin.000001                Relay_Log_Pos: 4        Relay_Master_Log_File:             Slave_IO_Running: No            Slave_SQL_Running: No              Replicate_Do_DB: backup</code></pre><ol start="4"><li><strong>导出 Slave1 数据</strong></li></ol><pre><code class="bash"># 导出 backup 库$ mysqldump -uroot -p backup &gt; backup.sql# 拷贝到 Master 服务器$ scp backup.sql root@192.168.0.1:/mysql</code></pre><ol start="5"><li><strong>导入 Master 库</strong></li></ol><pre><code class="bash"># 删除数据库mysql&gt; drop database backup;# 创建数据库mysql&gt; create database backup;# 导入数据$ mysql -uroot -p backup &lt; backup.sql</code></pre><ol start="6"><li><strong>重新配置主从关系</strong></li></ol><pre><code class="bash"># Slave1、Slave2mysql&gt; change master to       master_host=&#39;192.168.0.1&#39;,       master_port=3306,       master_user=&#39;slave&#39;,       master_password=&#39;slave123&#39;,       master_log_file=&#39;mysql-bin.000001&#39;       master_log_pos=154;</code></pre><ol start="7"><li><strong>开启主从</strong></li></ol><pre><code class="bash"># Salve1、Slave2mysql&gt; start slave;mysql&gt; show slave status \G;*************************** 1. row ***************************               Slave_IO_State: Waiting for master to send event                  Master_Host: 192.168.0.2                  Master_User: slave                  Master_Port: 3306                Connect_Retry: 60              Master_Log_File: mysql-bin.000001          Read_Master_Log_Pos: 154               Relay_Log_File: 2af2354ad45b-relay-bin.000003                Relay_Log_Pos: 367        Relay_Master_Log_File: mysql-bin.000001             Slave_IO_Running: Yes            Slave_SQL_Running: Yes              Replicate_Do_DB: backup*************************** 1. row ***************************               Slave_IO_State: Waiting for master to send event                  Master_Host: 192.168.0.3                  Master_User: slave                  Master_Port: 3306                Connect_Retry: 60              Master_Log_File: mysql-bin.000001          Read_Master_Log_Pos: 154               Relay_Log_File: 2af2354ad45b-relay-bin.000003                Relay_Log_Pos: 367        Relay_Master_Log_File: mysql-bin.000001             Slave_IO_Running: Yes            Slave_SQL_Running: Yes              Replicate_Do_DB: backup</code></pre><ol start="8"><li><strong>开启 MyCat</strong></li></ol><pre><code class="bash">$ mycat start</code></pre><hr><h5 id="总结"><a href="# 总结" class="headerlink" title="总结"></a>总结 </h5><p> 经过上面一系列到操作，最终恢复了数据和主从架构。虽然此方法可以恢复数据，但是前提是至少有一台 MySQL 节 <br> 点数据是未丢失到，只有满足这个前提，才能使用这种简单粗暴到方法。</p><div aligh="center">    <img src="http://qiniu.raindrop-wl.cn/over.png" srcset="/img/loading.gif" width="100%"></div>]]></content>
    
    
    <categories>
      
      <category>MySQL</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Docker Jenkins Develop Springboot</title>
    <link href="/2019/12/25/Docker%20Jenkins%20Develop%20Springboot/"/>
    <url>/2019/12/25/Docker%20Jenkins%20Develop%20Springboot/</url>
    
    <content type="html"><![CDATA[<p><strong>Jenkins Deployment Nginx And SpringBoot Instance</strong></p><a id="more"></a><p><strong>需求:</strong><br>  由于公司项目的不断增加，新需求不断的增加，导致每部署一次项目都是一次折磨（项目打包、jar 包上传、启动、监控日志…）。所以决定通过以 Jenkins 持续集成的方式，部署公司项目（Nginx 前端、Tomcat 后端）。</p><p><strong>方案</strong><br>  在本次搭建中我们将基于 Centos7.2 + Docker 来实现需求。主要是在 Docker 中部署 Jenkins，挂在宿主机 Jdk、Maven、Nginx、Jenkins_home，在容器中进行 Jenkins 相关配置管理。</p><p><strong>实现</strong>  </p><ul><li><p>Setp 1: Jdk1.8</p><pre><code class="bash"># 下载并安装 jdk1.8$ mkdir /usr/local/jdk1.8$ wget http://download.oracle.com/otn-pub/java/jdk/8u161-b12/2f38c3b165be4555a1fa6e98c45e0808/jdk-8u161-linux-x64.tar.gz &amp;&amp; tar -zxvf jdk-8u161-linux-x64.tar.gz /usr/local/jdk1.8# 配置环境变量$ vim /etc/profileexport JAVA_HOME=/usr/local/jdk1.8export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.java:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport PATH=$PATH:$JAVA_HOME/bin$ source /etc/profile# 运行 java -version 验证安装是否成功$ java -version</code></pre></li><li><p>Setp 2: Maven3.5</p><pre><code class="bash"># 下载并安装 maven3.5$ mkdir /usr/local/maven3.5$ wget http://mirrors.tuna.tsinghua.edu.cn/apache/maven/maven-3/3.6.0/binaries/apache-maven-3.6.0-bin.tar.gz &amp;&amp; tar -zxvf apache-maven-3.6.0-bin.tar.gz /usr/local/maven3.5# 配置环境变量$ vim /etc/profileexport M2_HOME=/usr/local/maven3.5export PATH=$PATH:$M2_HOME/bin# 运行 mvn -v 验证是否安装成功$ mvn -v</code></pre></li><li><p>Setp 3: Nginx1.14</p><pre><code class="bash"># 下载并安装 nginx$ wget -c https://nginx.org/download/nginx-1.14.0.tar.gz &amp;&amp; tar -zxvf nginx-1.14.0.tar.gz# 编译安装$ cd nginx-1.14.0 &amp;&amp; ./configure$ make &amp;&amp; make install# 查看安装路径$ whereis nginx# 启动 nginx、停止、退出、重启$ cd /usr/local/nginx/sbin$ ./nginx $ ./nginx -s stop$ ./nginx -s quit$ ./nginx -s reload# 配置开机启动$ vi /etc/rc.loca# 在最后一行添加$ /usr/local/nginx/sbin/nginx# 配置权限$ chmod 755 rc.local</code></pre></li><li><p>Setp 4: DockerCe</p><pre><code class="bash"># 安装依赖$ sudo yum install -y yum-utils \ device-mapper-persistent-data \ lvm2# 添加 repo 源$ sudo yum-config-manager \ --add-repo https://download.docker.com/linux/centos/docker-ce.repo# 安装 dockerce$ sudo yum-config-manager --enable docker-ce-edge$ sudo yum-config-manager --enable docker-ce-test$ sudo yum install docker-ce# 启动 docker、启动容器$ sudo systemctl start docker$ sudo docker run hello-world</code></pre></li><li><p>Setp 5: Docker 镜像拉取并启动容器</p><pre><code class="bash"># 拉取镜像$ docker pull jenkins/jenkins:lts# 启动容器同时挂载所需文件$ docker run -d \ --name my_jenkins \ -v /usr/local/jdk1.8:/usr/local/jdk1.8 \ -v /usr/local/maven3.5:/usr/local/maven3.5 \ -v /home/jenkins_home:/var/jenkins_home \ -p 8080 \ jenkins/jenkins:lts# 查看容器启动日志，获取 jenkins 初始密码$ docker logs -f containerId</code></pre><p><img src="http://qiniu.raindrop-wl.cn/jenkins_init_pass.jpg" srcset="/img/loading.gif" alt="jenkins_init_pass"></p></li><li><p>Setp 6: Jenkins 配置 <br> 登录 Jenkins，访问宿主机 8080 端口，第一次登录需要初始密码，就是我们上一步获取的密码。<br><img src="http://qiniu.raindrop-wl.cn/jenkins_login.jpg" srcset="/img/loading.gif" alt="jenkins_login"></p><p>选择安装推荐的插件即可<br><img src="http://qiniu.raindrop-wl.cn/jenkins_init_plugin.jpg" srcset="/img/loading.gif" alt="jenkins_init_plugin"></p><p>安装好插件以后，我们可以配置一个用户作为以后登录 Jenkins 的用户，这里就不做过多介绍了。</p></li><li><p>Setp 7: Jenkins 环境、任务配置 <br> 安装所需插件，Maven Integration Plugin、Nodejs、Publish Over SSH、Subversion、Ding<br><img src="http://qiniu.raindrop-wl.cn/jenkins_plugin_maven.png" srcset="/img/loading.gif" alt="jenkins_plugin_maven"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_plugin_nodejs.png" srcset="/img/loading.gif" alt="jenkins_plugin_nodejs"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_plugin_ssh.png" srcset="/img/loading.gif" alt="jenkins_plugin_ssh"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_plugin_svn.png" srcset="/img/loading.gif" alt="jenkins_plugin_svn"></p><p>服务器配置 Publish over ssh<br><img src="http://qiniu.raindrop-wl.cn/jenkins_config.png" srcset="/img/loading.gif" alt="jenkins_config"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_ssh_01.png" srcset="/img/loading.gif" alt="jenkins_ssh_01"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_ssh_02.png" srcset="/img/loading.gif" alt="jenkins_ssh_02"></p><p>配置 jdk、maven、nodejs，按照以下步骤来操作.<br><img src="http://qiniu.raindrop-wl.cn/jenkins_sys_config.png" srcset="/img/loading.gif" alt="jenkins_sys_config"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_sys_jdk.png" srcset="/img/loading.gif" alt="jenkins_sys_jdk"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_sys_maven.png" srcset="/img/loading.gif" alt="jenkins_sys_maven"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_sys_nodejs.png" srcset="/img/loading.gif" alt="jenkins_sys_nodejs"></p></li><li><p>Setp 8: 基础环境配置好了，下面我们开始正式配置前端任务，后端任务<br><img src="http://qiniu.raindrop-wl.cn/jenkins_project_web_01.png" srcset="/img/loading.gif" alt="jenkins_project_web_01"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_project_web_02.png" srcset="/img/loading.gif" alt="jenkins_project_web_02"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_project_web_03.png" srcset="/img/loading.gif" alt="jenkins_project_web_03"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_project_web_04.png" srcset="/img/loading.gif" alt="jenkins_project_web_04"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_project_web_05.png" srcset="/img/loading.gif" alt="jenkins_project_web_05"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_project_web_06.png" srcset="/img/loading.gif" alt="jenkins_project_web_06"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_project_web_07.png" srcset="/img/loading.gif" alt="jenkins_project_web_07"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_project_web_08.png" srcset="/img/loading.gif" alt="jenkins_project_web_08"></p><pre><code class="bash">#!/bin/bash -lDATE=$(date +%Y%m%d)TARFILE=tb-cams-web.tar.gzWORKSPACE=/home/webapps/tb-camsDISTFILE=$WORKSPACE/distBACKUP=$WORKSPACE/backupTMP=$WORKSPACE/tmpcd $WORKSPACEif [! -d $BACKUP];thenecho &quot;backup directory does not exists, new backup directory&quot;mkdir $BACKUPfiif [! -d $DISTFILE];thenecho &quot;dist directory does not exists, new dist directory&quot;mkdir $DISTFILEfimv $DISTFILE/$TARFILE $BACKUP/$TARFILE.$DATEmv $TMP/$TARFILE $DISTFILE/cd $DISTFILE &amp;&amp; tar -zxvf $TARFILEecho &quot;Cams web deploy success&quot;</code></pre></li><li><p>后端<br><img src="http://qiniu.raindrop-wl.cn/jenkins_project_admin_01.png" srcset="/img/loading.gif" alt="jenkins_project_admin_01"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_project_admin_02.png" srcset="/img/loading.gif" alt="jenkins_project_admin_02"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_project_admin_03.png" srcset="/img/loading.gif" alt="jenkins_project_admin_03"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_project_admin_04.png" srcset="/img/loading.gif" alt="jenkins_project_admin_04"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_project_admin_05.png" srcset="/img/loading.gif" alt="jenkins_project_admin_05"></p><pre><code class="bash">#!/bin/bash -lDATE=$(date +%Y%m%d)WARFILE=tb-cams.warWORKSPACE=/home/webapps/tb-camsLOGFILE=$WORKSPACE/logsBACKUP=$WORKSPACE/backupcd $WORKSPACEif [! -d $BACKUP];thenecho &quot;backup directory does not exists, new backup directory&quot;mkdir $BACKUPfiif [! -d $LOGFILE];thenecho &quot;logs directory does not exists, new logs directory&quot;mkdir $LOGFILEfiPID=$(ps -ef | grep $WARFILE | grep -v grep | awk &#39;{print $2}&#39;)if [-z &quot;$PID&quot;];thenecho &quot;$WARFILE is not started&quot;elseecho &quot;$WARFILE is a startup task, kill process $PID&quot;kill -9 $PIDfimv $WARFILE $BACKUP/$WARFILE.$DATEmv $WORKSPACE/tmp/$WARFILE .rm -rf $WORKSPACE/tmp/$WARFILEjava -jar $WARFILE --spring.profiles.active=stg &gt; logs/cams.log &amp;</code></pre></li></ul>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
      <category>Docker</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Spring Boot Kotlin Jwt Token</title>
    <link href="/2019/04/06/SpringBood-Kotlin-Token/"/>
    <url>/2019/04/06/SpringBood-Kotlin-Token/</url>
    
    <content type="html"><![CDATA[<p><strong>Spring Boot Kotlin Jwt Token</strong></p><a id="more"></a><h3 id="本篇记录了，基于 Spring-Boot、Kotlin、Jwt 的 Token 接口认证功能的项目内容"><a href="# 本篇记录了，基于 Spring-Boot、Kotlin、Jwt 的 Token 接口认证功能的项目内容" class="headerlink" title="本篇记录了，基于 Spring Boot、Kotlin、Jwt 的 Token 接口认证功能的项目内容"></a>本篇记录了，基于 Spring Boot、Kotlin、Jwt 的 Token 接口认证功能的项目内容 </h3><p>  <strong> 环境如下</strong></p><table><thead><tr><th align="center">Plugin</th><th align="center">Version</th></tr></thead><tbody><tr><td align="center">SpringBoot</td><td align="center">2.0.8.RELEASE</td></tr><tr><td align="center">Kotlin</td><td align="center">1.2.71</td></tr><tr><td align="center">Java-Jwt</td><td align="center">3.3</td></tr></tbody></table><h3 id="时序图"><a href="# 时序图" class="headerlink" title="时序图"></a>时序图</h3><p>  <img src="http://qiniu.raindrop-wl.cn/kotlin-jwt.png" srcset="/img/loading.gif" alt="kotlin-jwt"></p><h3 id="项目配置"><a href="# 项目配置" class="headerlink" title="项目配置"></a>项目配置</h3><ul><li><p>Maven 依赖如下:</p><pre><code class="xml">&lt;!-- Spring Boot --&gt;&lt;parent&gt;&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&lt;version&gt;2.0.8.RELEASE&lt;/version&gt;&lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt;&lt;properties&gt;    &lt;java.version&gt;1.8&lt;/java.version&gt;    &lt;kotlin.version&gt;1.2.71&lt;/kotlin.version&gt;&lt;/properties&gt;&lt;dependencies&gt;    &lt;!-- Web --&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;!-- Jwt --&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.auth0&lt;/groupId&gt;        &lt;artifactId&gt;java-jwt&lt;/artifactId&gt;        &lt;version&gt;3.3.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;!-- FastJson --&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.alibaba&lt;/groupId&gt;        &lt;artifactId&gt;fastjson&lt;/artifactId&gt;        &lt;version&gt;1.2.49&lt;/version&gt;    &lt;/dependency&gt;    &lt;!-- Kotlin --&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.fasterxml.jackson.module&lt;/groupId&gt;        &lt;artifactId&gt;jackson-module-kotlin&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.jetbrains.kotlin&lt;/groupId&gt;        &lt;artifactId&gt;kotlin-reflect&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.jetbrains.kotlin&lt;/groupId&gt;        &lt;artifactId&gt;kotlin-stdlib-jdk8&lt;/artifactId&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt;    &lt;sourceDirectory&gt;${project.basedir}/src/main/kotlin&lt;/sourceDirectory&gt;    &lt;testSourceDirectory&gt;${project.basedir}/src/test/kotlin&lt;/testSourceDirectory&gt;    &lt;plugins&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;        &lt;/plugin&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.jetbrains.kotlin&lt;/groupId&gt;            &lt;artifactId&gt;kotlin-maven-plugin&lt;/artifactId&gt;            &lt;configuration&gt;                &lt;args&gt;                    &lt;arg&gt;-Xjsr305=strict&lt;/arg&gt;                &lt;/args&gt;                &lt;compilerPlugins&gt;                    &lt;plugin&gt;spring&lt;/plugin&gt;                &lt;/compilerPlugins&gt;            &lt;/configuration&gt;            &lt;dependencies&gt;                &lt;dependency&gt;                    &lt;groupId&gt;org.jetbrains.kotlin&lt;/groupId&gt;                    &lt;artifactId&gt;kotlin-maven-allopen&lt;/artifactId&gt;                    &lt;version&gt;${kotlin.version}&lt;/version&gt;                &lt;/dependency&gt;            &lt;/dependencies&gt;        &lt;/plugin&gt;    &lt;/plugins&gt;&lt;/build&gt;</code></pre></li><li><p>JwtUtil.kt 工具类，实现了签名、解析、校验、获取用户名的相关方法.</p><pre><code class="kotlin">package com.raindrop.auth.utilsimport com.auth0.jwt.JWTimport com.auth0.jwt.algorithms.Algorithmimport com.auth0.jwt.interfaces.Claimimport java.util.*/*** Jwt 工具类** @author Raindrop*/open class JwtUtil {    companion object {        /* 秘钥 */        private val secret = &quot;raindrop-666&quot;        /* 过期时间 15 分钟 */        private val expireTime = 15 * 60 * 1000        /**        * 生成 Token        *        * @param username 用户名        * @return token 令牌        */        fun sign(username: String): String {var createDate = Date()            var expireDate = Date(System.currentTimeMillis() + expireTime)            var claims = mapOf(&quot;username&quot; to username)            return JWT.create()                    .withHeader(claims)                    .withSubject(username)                    .withIssuedAt(createDate)                    .withExpiresAt(expireDate)                    .sign(Algorithm.HMAC512(secret))        }        /**        * 解析 Token        *        * @param token 令牌        * @return claim        */        fun parse(token: String): MutableMap&lt;String, Claim&gt;? {return JWT.decode(token).claims        }        /**        * 检验 Token        *        * @param token 令牌        * @return 有效 true 无效 false        */        fun verifyToken(token: String): Boolean {            return try {JWT.require(Algorithm.HMAC512(secret)).build().verify(token)                true            } catch (e: Exception) {false}        }        /**        * 获取用户名        *        * @param token 令牌        * @return 用户名        */        fun getUserName(token: String) = JWT.decode(token).getClaim(&quot;username&quot;).asString()        /**        * 刷新 token        *        * @param token 原 token        * @return 新 token        */        fun refresh(token: String): String {var createDate = Date()            var expireDate = Date(System.currentTimeMillis() + expireTime)            var username = parse(token)!![&quot;sub&quot;]!!.asString()            var header = mapOf(&quot;username&quot; to username)            return JWT.create()                    .withHeader(header)                    .withSubject(username)                    .withIssuedAt(createDate)                    .withExpiresAt(expireDate)                    .sign(Algorithm.HMAC512(secret))        }    }}</code></pre></li><li><p>AuthInterceptor.kt 拦截器，请求前进行拦截. 如果请求方法为 OPTIONS，则放过不进行拦截，关于 OPTIONS 请求方法，主要是在发送 PUT、DELETE 或 Content-Type application/json 请求前进行 <strong> 预检 </strong>，浏览器会先询问服务器，当前请求域名是否在服务器允许的范围内，如果允许则浏览器会发出正式的 XMLHttpRequest 请求，否则会报错. 此拦截器对<strong> 登录 </strong> 接口不进行拦截.</p><pre><code class="kotlin">package com.raindrop.auth.interceptorsimport com.alibaba.fastjson.JSONimport com.raindrop.auth.model.ResultEntityimport com.raindrop.auth.model.buildResultEntityimport com.raindrop.auth.utils.JwtUtilimport org.slf4j.LoggerFactoryimport org.springframework.stereotype.Componentimport org.springframework.web.servlet.HandlerInterceptorimport javax.servlet.http.HttpServletRequestimport javax.servlet.http.HttpServletResponse@Componentclass AuthInterceptor : HandlerInterceptor {private val logger = LoggerFactory.getLogger(this.javaClass)    private val options = &quot;OPTIONS&quot;    override fun preHandle(request: HttpServletRequest, response: HttpServletResponse, handler: Any): Boolean {if (request.method == options) return true        var authorization = request.getHeader(&quot;Authorization&quot;)        if (authorization != null) {var token = authorization.substring(7)            if (JwtUtil.verifyToken(token)) {logger.info(&quot;Auth Success Token Effective...&quot;)                return true            }        }        logger.info(&quot;Auth Fail Token Invalid...&quot;)        response.writer.write(JSON.toJSONString(buildUnauthorizedResultEntity()))        return false    }    fun buildUnauthorizedResultEntity(): ResultEntity {        return buildResultEntity {            code = 403            message = &quot;Auth Fail&quot;        }    }}</code></pre></li><li><p>AuthConfig.kt 拦截器配置，此处将 <strong> 登录 </strong> 接口过滤，不进行拦截，其他全部接口，全部需要携带 token 并认证通过后，方可访问.</p><pre><code class="kotlin">package com.raindrop.auth.configimport com.raindrop.auth.interceptors.AuthInterceptorimport org.springframework.context.annotation.Configurationimport org.springframework.web.servlet.config.annotation.InterceptorRegistryimport org.springframework.web.servlet.config.annotation.WebMvcConfigurer@Configurationclass AuthConfig : WebMvcConfigurer {    /**      * 添加拦截器      */    override fun addInterceptors(registry: InterceptorRegistry) {var excludePath = listOf(&quot;/auth/login&quot;, &quot;/auth/guest&quot;, &quot;/auth/refresh&quot;)        registry.addInterceptor(AuthInterceptor()).excludePathPatterns(excludePath)    }}</code></pre></li><li><p>ResultEntity.kt 通用返回实体，此处使用了 kotlin 高级语法，从而可以使用 dsl 方式构建通用返回实体.</p><pre><code class="kotlin">package com.raindrop.auth.modelimport java.io.Serializabledata class ResultEntity(        var code: Int = 200,        var message: String = &quot;success&quot;,        var data: Any = &quot;&quot;) : Serializablefun buildResultEntity(builder: ResultEntity.() -&gt; Unit) = ResultEntity().apply(builder)</code></pre></li><li><p>User.kt 用户实体.</p><pre><code class="kotlin">package com.raindrop.auth.modelclass User(        var username: String,        var password: String,        var nickName: String)</code></pre></li><li><p>IUserService.kt 用户服务接口.</p><pre><code class="kotlin">package com.raindrop.auth.serviceinterface IUserService {    /**      * 登录      *      * @param username 用户名      * @param password 用户密码      * @return      */    fun login(username: String, password: String): Boolean}</code></pre></li><li><p>UserServiceImpl.kt 用户服务实现.</p><pre><code class="kotlin">package com.raindrop.auth.service.implimport com.raindrop.auth.service.IUserServiceimport org.springframework.stereotype.Service@Serviceclass UserServiceImpl : IUserService {    /**    * 登录    *    * @param username 用户名    * @param password 用户密码    * @return    */    override fun login(username: String, password: String): Boolean = true}</code></pre></li><li><p>AuthController.kt 业务 Controller，/login 接口不进行拦截，账号密码正确后，返回 token. /users 接口需要拦截，需认证通过后携带正确的 token 后，方可访问.</p><pre><code class="kotlin">package com.raindrop.auth.webimport com.raindrop.auth.model.ResultEntityimport com.raindrop.auth.model.Userimport com.raindrop.auth.model.buildResultEntityimport com.raindrop.auth.service.IUserServiceimport com.raindrop.auth.utils.JwtUtilimport org.slf4j.LoggerFactoryimport org.springframework.beans.factory.annotation.Autowiredimport org.springframework.web.bind.annotation.GetMappingimport org.springframework.web.bind.annotation.PostMappingimport org.springframework.web.bind.annotation.RequestMappingimport org.springframework.web.bind.annotation.RestController@RestController@RequestMapping(&quot;/auth&quot;)class AuthController {private val logger = LoggerFactory.getLogger(this.javaClass)    @Autowired    lateinit var userService: IUserService    /**    * 登录    *    * @param username 用户名    * @param password 用户密码    * @return    */    @PostMapping(&quot;/login&quot;)    fun login(username: String, password: String): ResultEntity {if (username == null) {logger.warn(&quot;Login Fail, UserName Is Null&quot;)            throw IllegalArgumentException(&quot; 登录失败，用户不存在 &quot;)        }        if (password == null) {logger.warn(&quot;Login Fail, Password Is Null&quot;)            throw IllegalArgumentException(&quot; 登录失败，账号或密码错误 &quot;)        }        if (userService.login(username, password)) {var token = JwtUtil.sign(username)            return buildResultEntity {data = token}        }        return buildResultEntity {            code = 400            message = &quot; 登录失败 &quot;        }    }    /**    * 获取用户列表    *    * @return    */    @GetMapping(&quot;/users&quot;)    fun getUserList(): ResultEntity {        var users = listOf(User(&quot;wl&quot;, &quot;wl&quot;, &quot;wl&quot;),                User(&quot;lv&quot;, &quot;lv&quot;, &quot;lv&quot;),                User(&quot;ee&quot;, &quot;ee&quot;, &quot;ee&quot;)        )        return buildResultEntity {data = users}    }</code></pre></li></ul><pre><code>    @PostMapping(&quot;/refresh&quot;)    fun refreshToken(token: String): String = if (JwtUtil.verifyToken(token)) JwtUtil.refresh(token) else &quot;Token Invalid&quot;    @GetMapping(&quot;/guest&quot;)    fun getGuestMessage(): ResultEntity {        return buildResultEntity {data = &quot;Hello Guest, You are handsome!&quot;}    }}```</code></pre><ul><li><p>AuthTokenApplication.kt 启动类.</p><pre><code class="kotlin">package com.raindrop.authimport org.springframework.boot.autoconfigure.SpringBootApplicationimport org.springframework.boot.runApplication@SpringBootApplicationclass AuthTokenApplicationfun main(args: Array&lt;String&gt;) {runApplication&lt;AuthTokenApplication&gt;(*args)}</code></pre></li></ul><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><ul><li><p>无登录时访问 GET <a href="http://localhost:8888/auth/guest" target="_blank" rel="noopener">http://localhost:8888/auth/guest</a> ， 可以访问，因为该接口并未被过滤器拦截.<br><img src="http://qiniu.raindrop-wl.cn/jwt-users-login.png" srcset="/img/loading.gif" alt="jwt-guest"></p></li><li><p>无登录时访问 GET <a href="http://localhost:8888/auth/users" target="_blank" rel="noopener">http://localhost:8888/auth/users</a> ， 此时无意外提醒未授权，因为此接口被过滤器拦截.<br><img src="http://qiniu.raindrop-wl.cn/jwt-users-unlogin.png" srcset="/img/loading.gif" alt="jwt-users-unlogin"></p></li><li><p>访问登录接口 POST <a href="http://localhost:8888/auth/login" target="_blank" rel="noopener">http://localhost:8888/auth/login</a> ， 认证成功，并返回 token.<br><img src="http://qiniu.raindrop-wl.cn/jwt-login.png" srcset="/img/loading.gif" alt="jwt-login"></p></li><li><p>此时再次访问 GET <a href="http://localhost:8888/auth/users" target="_blank" rel="noopener">http://localhost:8888/auth/users</a> ， 可以正确获取结果.<br><img src="http://qiniu.raindrop-wl.cn/jwt-users-login.png" srcset="/img/loading.gif" alt="jwt-users-login"></p></li><li><p>token 过期，刷新 token 访问 POST <a href="http://localhost:8888/auth/refresh" target="_blank" rel="noopener">http://localhost:8888/auth/refresh</a> ， 认证原 token 成功后，返回新 token.<br><img src="http://qiniu.raindrop-wl.cn/jwt-refresh-token.png" srcset="/img/loading.gif" alt="jwt-refresh"></p><p>Source: <a href="https://github.com/727474430/Kotlin-Jwt-Token" target="_blank" rel="noopener">Link</a></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Java Atomic</title>
    <link href="/2019/04/06/Java%20Atomic/"/>
    <url>/2019/04/06/Java%20Atomic/</url>
    
    <content type="html"><![CDATA[<p><strong>Java 中”i++”是线程安全得吗? 一次面试题引发的学习 </strong></p><a id="more"></a><h3 id="什么是原子操作？"><a href="# 什么是原子操作？" class="headerlink" title="什么是原子操作？"></a> 什么是原子操作？</h3><ul><li><p> 所谓原子操作, 可以简单理解为一次不可分割的操作, 同时可以保证线程安全. 例如:</p><pre><code class="java">  int i = 1;</code></pre></li><li><p> 如上代码表示原子操作, 即一次性赋值, 没有多余的中间操作.</p></li></ul><h3 id="那么 i- 是否是原子操作呢"><a href="# 那么 i- 是否是原子操作呢" class="headerlink" title="那么 i++ 是否是原子操作呢?"></a> 那么 i++ 是否是原子操作呢?</h3><ul><li><p> 同样的方式来分析 i++ 操作. 可以分为三步:</p><ol><li> 获取上一次 i 值.</li><li> 将 i 的值 +1.</li><li> 赋值给 i.</li></ol></li><li><p> 由上可见 i++ 并非不可分割操作, 所以 i++ 并不是原子操作, 即 i++ 并非线程安全.</p></li></ul><h3 id="那么在 java 中如何保证自增操作的线程安全呢"><a href="# 那么在 java 中如何保证自增操作的线程安全呢" class="headerlink" title="那么在 java 中如何保证自增操作的线程安全呢?"></a> 那么在 java 中如何保证自增操作的线程安全呢?</h3><ul><li><p> 方法有 3 种:</p><ol><li> 利用同步–Synchronized.</li><li> 利用 Java 提供给我们的 AtomicInteger、AtomicLong…</li><li> 利用 Lock.</li></ol></li><li><p> 我们来看几种不同的方式获得的结果.</p><pre><code class="java">  public class IncrementTest {      public static int count = 0;      public static Counter counter = new Counter();      public static AtomicInteger atomicInteger = new AtomicInteger(0);      public volatile static int countVolatile = 0;      public static Lock lock = new ReentrantLock();      public static int countLock = 0;      public static void main(String[] args) {for (int i = 0; i &lt; 10; i++) {new Thread(() -&gt; {for (int j = 0; j &lt; 1000; j++) {                          count++;                          counter.increment();                          atomicInteger.getAndIncrement();                          countVolatile++;                          lockIncrement();}              }).start();}          try {Thread.sleep(3000);          } catch (InterruptedException e) {e.printStackTrace();          }          System.out.println(&quot;static int -&gt; &quot; + count);          System.out.println(&quot;counter -&gt; &quot; + counter.getValue());          System.out.println(&quot;atomicInteger -&gt; &quot; + atomicInteger.get());          System.out.println(&quot;volatile int -&gt; &quot; + countVolatile);          System.out.println(&quot;count lock -&gt; &quot; + countLock);      }      public static void lockIncrement() {lock.lock();          countLock++;          lock.unlock();}  }  class Counter {      private int value;      public synchronized int getValue() {return value;}      public synchronized int increment() {return ++value;}      public synchronized int decrement() {return --value;}  }</code></pre></li><li><p> 上述代码我们定义了四个类型的变量:</p><ol><li> 静态 int.</li><li>AtomicInteger Java 提供原子操作.</li><li>Counter 同步方式.</li><li>volatile 可见性关键字 (这里不对该关键字做讨论).</li></ol></li><li><p> 我们来看一下运行结果:</p><p><img src="http://qiniu.raindrop-wl.cn/increment.png" srcset="/img/loading.gif" alt="increment"></p></li><li><p> 可见,Java 中可以保证自增为线程安全的方法是 Atomic 以及 Synchronized.</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Mac Alfred Workflows</title>
    <link href="/2019/04/06/My%20Mac%20Alfred%20Workflows/"/>
    <url>/2019/04/06/My%20Mac%20Alfred%20Workflows/</url>
    
    <content type="html"><![CDATA[<p><strong>This blog records myself using alfred wordflows</strong></p><a id="more"></a><h3 id="Following-Plugin-In-No-Particular-Order"><a href="#Following-Plugin-In-No-Particular-Order" class="headerlink" title="Following Plugin In No Particular Order"></a>Following Plugin In No Particular Order</h3><table><thead><tr><th align="center">Name</th><th align="center">Function</th><th align="center">Shortcut</th></tr></thead><tbody><tr><td align="center">CodeVar</td><td align="center">define variable</td><td align="center"><code>xt</code>     name(chinese)</td></tr><tr><td align="center">CodeVar</td><td align="center">define variable</td><td align="center"><code>dt</code>     name(chinese)</td></tr><tr><td align="center">DS_Store</td><td align="center">delete macos generating .ds_store file</td><td align="center"><code>dsc</code>    current folder</td></tr><tr><td align="center">encode-decode</td><td align="center">command encoding</td><td align="center"><code>encode</code> string</td></tr><tr><td align="center">encode-decode</td><td align="center">command encoding</td><td align="center"><code>decode</code> string</td></tr><tr><td align="center">github_search</td><td align="center">fast search github repository info</td><td align="center"><code>github</code> repo name</td></tr><tr><td align="center">Hash</td><td align="center">hash encoding(md5 sha1 sha512…)</td><td align="center"><code>hash</code>   string</td></tr><tr><td align="center">Kill Process</td><td align="center">kill target process</td><td align="center"><code>kill</code>   target process</td></tr><tr><td align="center">kuaidichaxun</td><td align="center">fast query kuaidi</td><td align="center"><code>kd</code>     order number</td></tr><tr><td align="center">StackOverflow</td><td align="center">fast query StackOverflow in problem</td><td align="center"><code>.so</code>    problem</td></tr><tr><td align="center">V2EX</td><td align="center">fast query v2ex in info</td><td align="center"><code>v2ex</code>   info</td></tr><tr><td align="center">YouDao</td><td align="center">youdao translate</td><td align="center"><code>yd</code>     info</td></tr><tr><td align="center">QR code</td><td align="center">fast generator QR code</td><td align="center"><code>qr</code>     info</td></tr></tbody></table><h3 id="Using-Example-Image-Style"><a href="#Using-Example-Image-Style" class="headerlink" title="Using Example Image Style"></a>Using Example Image Style</h3><ul><li><p>CodeVar<br><img src="http://qiniu.raindrop-wl.cn/xt.png" srcset="/img/loading.gif" alt="img"></p></li><li><p>DS<sub>Store</sub><br><img src="http://qiniu.raindrop-wl.cn/dsc.png" srcset="/img/loading.gif" alt="img"></p></li><li><p>encode-decode<br><img src="http://qiniu.raindrop-wl.cn/encode.png" srcset="/img/loading.gif" alt="img"><br><img src="http://qiniu.raindrop-wl.cn/decode.png" srcset="/img/loading.gif" alt="img"></p></li><li><p>github<sub>search</sub><br><img src="http://qiniu.raindrop-wl.cn/github.png" srcset="/img/loading.gif" alt="img"></p></li><li><p>Hash<br><img src="http://qiniu.raindrop-wl.cn/hash.png" srcset="/img/loading.gif" alt="img"></p></li><li><p>Kill Process<br>![img](<a href="http://qiniu.raindrop-wl.cn/kill" target="_blank" rel="noopener">http://qiniu.raindrop-wl.cn/kill</a> process.png)</p></li><li><p>Kd<br><img src="http://qiniu.raindrop-wl.cn/kd.png" srcset="/img/loading.gif" alt="img"></p></li><li><p>StackOverFlow<br><img src="http://qiniu.raindrop-wl.cn/stackoverflow.png" srcset="/img/loading.gif" alt="img"></p></li><li><p>V2EX<br><img src="http://qiniu.raindrop-wl.cn/v2ex.png" srcset="/img/loading.gif" alt="img"></p></li><li><p>YouDao<br><img src="http://qiniu.raindrop-wl.cn/yd.png" srcset="/img/loading.gif" alt="img"></p></li><li><p>QR Code<br><img src="http://qiniu.raindrop-wl.cn/qr.png" srcset="/img/loading.gif" alt="img"></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Maven Project</title>
    <link href="/2019/01/05/Maven%20Project/"/>
    <url>/2019/01/05/Maven%20Project/</url>
    
    <content type="html"><![CDATA[<p><strong>Maven</strong> 主要用于项目构建、依赖管理、项目信息管理</p><a id="more"></a><h1 id="Maven 作用"><a href="#Maven 作用" class="headerlink" title="Maven 作用?"></a>Maven 作用?</h1><h3 id="自动下载依赖"><a href="# 自动下载依赖" class="headerlink" title="自动下载依赖"></a>自动下载依赖</h3><ul><li><p>当我们在 pom.xml 配置文件做了相应的配置之后,maven 会自动从远程仓库下载对应 jar 包</p></li><li><p>同时每个 jar 包内部也配有 pom.xml, 其中包含了该 jar 包所需要的其他依赖,maven 也可以同时帮助我们自动下载. 帮助我们开发人员省去了寻找 jar 包所花费的不必要时间.</p></li></ul><h3 id="热部署、热编译"><a href="# 热部署、热编译" class="headerlink" title="热部署、热编译"></a>热部署、热编译</h3><ul><li>当 Web 项目运行时, 我们对源代码进行修改后, 需要重启服务器或重新部署代码, 就可以自动被服务器所加载.</li></ul><h3 id="打包"><a href="# 打包" class="headerlink" title="打包"></a>打包</h3><ul><li>使用 Maven 可以直接打包 war 或 jar 项目.</li></ul><h1 id="Maven 项目结构"><a href="#Maven 项目结构" class="headerlink" title="Maven 项目结构"></a>Maven 项目结构</h1><table><thead><tr><th align="center">Path</th><th align="center">Meaning</th></tr></thead><tbody><tr><td align="center">src/main/java</td><td align="center">存放项目. java 文件</td></tr><tr><td align="center">src/main/resource</td><td align="center">存放项目资源文件</td></tr><tr><td align="center">src/test/java</td><td align="center">存放项目测试类. java 文件</td></tr><tr><td align="center">src/test/resource</td><td align="center">存放项目测试相关资源文件</td></tr><tr><td align="center">target</td><td align="center">项目输出目录</td></tr><tr><td align="center">pom.xml</td><td align="center">Maven 核心配置文件</td></tr></tbody></table><h1 id="Maven 使用"><a href="#Maven 使用" class="headerlink" title="Maven 使用"></a>Maven 使用 </h1><h3 id="从官网下载后进行解压 - 然后配置到环境变量即可通过命令行使用"><a href="# 从官网下载后进行解压 - 然后配置到环境变量即可通过命令行使用" class="headerlink" title="从官网下载后进行解压, 然后配置到环境变量即可通过命令行使用."></a> 从官网下载后进行解压, 然后配置到环境变量即可通过命令行使用.</h3><ul><li>mvn -v 查看版本号(测试环境变量是否配置成功).</li></ul><h3 id="命令行方式创建 Maven 项目"><a href="# 命令行方式创建 Maven 项目" class="headerlink" title="命令行方式创建 Maven 项目"></a>命令行方式创建 Maven 项目</h3><ul><li>mvn archetype:generate -DgroupId=com.raindrop -DartifactId=MavenTest -DarchetypeArtifactId=maven-archetype-quicktart -DinteractiveMode=false</li></ul><h1 id="Maven 常用命令"><a href="#Maven 常用命令" class="headerlink" title="Maven 常用命令"></a>Maven 常用命令</h1><table><thead><tr><th align="center">Command</th><th align="center">Meaning</th></tr></thead><tbody><tr><td align="center">mvn -v</td><td align="center">查看版本号</td></tr><tr><td align="center">mvn compile</td><td align="center">编译源代码</td></tr><tr><td align="center">mvn package</td><td align="center">根据项目生成 jar</td></tr><tr><td align="center">mvn deploy</td><td align="center">发布项目</td></tr><tr><td align="center">mvn test-compile</td><td align="center">编译测试源代码</td></tr><tr><td align="center">mvn test</td><td align="center">运行程序中单元测试</td></tr><tr><td align="center">mvn site</td><td align="center">生成项目相关信息网站</td></tr><tr><td align="center">mvn clean</td><td align="center">清除项目中已经生成的内容</td></tr><tr><td align="center">mvn install</td><td align="center">在本地 Repository 中安装 jar</td></tr><tr><td align="center">mvn eclipse:eclipse</td><td align="center">生成 Eclipse 项目相关文件</td></tr><tr><td align="center">mvn tomcat:run</td><td align="center">启动 tomcat 服务</td></tr><tr><td align="center">mvn spring-boot:run</td><td align="center">启动 Spring Boot 服务</td></tr><tr><td align="center">mvn clean package -DskipTests</td><td align="center">清除并重新打包, 跳过 test 包</td></tr><tr><td align="center">mvn eclipse:clean</td><td align="center">清除 Project 编译内容</td></tr><tr><td align="center">mvn clean package</td><td align="center">清除并重新打包</td></tr></tbody></table><h1 id="Maven 配置 jar 包"><a href="#Maven 配置 jar 包" class="headerlink" title="Maven 配置 jar 包"></a>Maven 配置 jar 包</h1><ul><li><p>Maven Repository Location:</p><pre><code class="xml">&lt;https://mvnrepository.com/&gt;&lt;dependency&gt;  &lt;groupId&gt;org.json&lt;/groupId&gt;  &lt;artifactId&gt;json&lt;/artifactId&gt;  &lt;version&gt;20160212&lt;/version&gt;&lt;/dependency&gt;</code></pre></li></ul>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Git Command(2)</title>
    <link href="/2019/01/05/Git%20Command(2)/"/>
    <url>/2019/01/05/Git%20Command(2)/</url>
    
    <content type="html"><![CDATA[<p><strong>Git brach command</strong></p><a id="more"></a><h3 id="如何创建一个分支"><a href="# 如何创建一个分支" class="headerlink" title="如何创建一个分支"></a> 如何创建一个分支 </h3><ul><li><p> 第一种方式：</p><pre><code class="bash"># 创建分支$ git branch &#39;branch-name&#39;# 切换分支$ git checkout &#39;branch-name&#39;</code></pre></li><li><p> 第二种方式 (I prefer to), 这种方式在创建分支后即切换到分支:</p><pre><code class="bash">$ git checkout -b &#39;branch-name&#39;</code></pre></li></ul><h3 id="学会了创建分支 - 接下来我们学习删除分支"><a href="# 学会了创建分支 - 接下来我们学习删除分支" class="headerlink" title="学会了创建分支, 接下来我们学习删除分支"></a> 学会了创建分支, 接下来我们学习删除分支 </h3><ul><li> 以下命令即可简单删除指定分支:<pre><code class="bash">$ git branch -d &#39;branch-name&#39;</code></pre></li></ul><h3 id="接下来我们学习如何合并分支"><a href="# 接下来我们学习如何合并分支" class="headerlink" title="接下来我们学习如何合并分支"></a> 接下来我们学习如何合并分支 </h3><ul><li><p> 首先来看默认 fast-forward 方式:</p><pre><code class="bash"># 这种方式执行后会提示我们使用点上 ff 方式合并, 默认情况下执行结果如下$ git merge &#39;branch-name&#39;</code></pre></li><li><p> 接下来我们看一下除了 ff 方式合并, 正常开时遇到的合并方式 </p><pre><code class="bash"># 首先创建分支 \`dev\`, 完成之后修改 README.org 文件并提交$ git checkout -b dev$ vim README.org$ git commit -am &quot;dev commit content&quot;# 然后切换到 master 分支, 修改 README.org 文件并提交$ git checkout master$ vim README.org$ git commit -am &quot;master commit content&quot;# 最后合并分支查看提示$ git merge dev</code></pre></li><li><p> 此时 git 提示我们 Readme 文件产生冲突, 请解决冲突后在进行合并. 然后我们打开 README.org 文件看到如下内容:<br> 该文件目前以 ===== 分割, HEAD -&gt; 表示当前分支提交到内容, dev -&gt; 表示另一个分支提交到内容. 此时我们需要将冲突解决后, 在进行合并集合完成目的.</p></li><li><p> 如上图所示，解决为该内容后就可以进行合并啦！</p><pre><code class="bash">$ git merge dev</code></pre></li></ul><h3 id="查看分支情况"><a href="# 查看分支情况" class="headerlink" title="查看分支情况"></a> 查看分支情况 </h3><ul><li> 通过带参数的 git log 进行查看, 如下图 <pre><code class="bash">$ git log --graph --pretty=oneline --abbrev-commit</code></pre></li></ul><h3 id="合并分支（普通合并）"><a href="# 合并分支（普通合并）" class="headerlink" title="合并分支（普通合并）"></a> 合并分支（普通合并）</h3><ul><li>git default useing fast-forward mode merge. we can pass prohibit(禁止) ff. use ordinary(普通) merge. ordinary merge will generate a new commit obejct.<pre><code class="bash">$ git merge --no-ff -m &quot;merge with no-ff&quot; dev</code></pre></li></ul><h3 id="分支管理策略"><a href="# 分支管理策略" class="headerlink" title="分支管理策略"></a> 分支管理策略 </h3><ul><li><p> 一般来说工作中使用 3 个分支进行开发就足够了.<br>master 主分支用来发布 <br>dev    日常开发使用分支 <br>bug    修改 bug 时使用分支 </p></li><li><p>master 分支应该是非常稳定的, 也就是仅仅用来进行新版本发布, 一般不再上面做开发,dev 分支应该是平常用了进行新功能开发的分支,dev 分支是不稳定的. 当我们新功能开发完成并测试通过后, 即可将 dev 合并到 master 中进行发布. 而 bug 分支我们只用来解决日常 bug, 解决后合并到 dev 分支即可.</p></li></ul><h3 id="Git-Branch-Relevent-Common-Command"><a href="#Git-Branch-Relevent-Common-Command" class="headerlink" title="Git Branch Relevent Common Command"></a>Git Branch Relevent Common Command</h3><table><thead><tr><th align="center">Command</th><th align="center">Meaning</th></tr></thead><tbody><tr><td align="center">git branch -v</td><td align="center"> 查看每一个分支最后一次提交 </td></tr><tr><td align="center">git branch -a</td><td align="center"> 查看本地和远程分支情况 </td></tr><tr><td align="center">git branch -merged</td><td align="center"> 查看已经与当前分支合并过的分支 </td></tr><tr><td align="center">git branch -no-merge</td><td align="center"> 查看已经与当前分支未合并的分支 </td></tr><tr><td align="center">git branch -r</td><td align="center"> 查看远程分支情况 </td></tr><tr><td align="center">git branch dev</td><td align="center"> 创建分支 dev</td></tr><tr><td align="center">git checkout dev</td><td align="center"> 切换到分支 dev</td></tr><tr><td align="center">git checkout -b dev</td><td align="center"> 创建同时切换到 dev 分支 </td></tr><tr><td align="center">git merge dev</td><td align="center"> 合并 dev 分支 </td></tr><tr><td align="center">git branch -d dev</td><td align="center"> 删除 dev 分支 </td></tr><tr><td align="center">git merge -no -ff -m”message”</td><td align="center"> 合并分支并禁用 fast-forward</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>Git</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Git Command(1)</title>
    <link href="/2019/01/05/Git%20Command(1)/"/>
    <url>/2019/01/05/Git%20Command(1)/</url>
    
    <content type="html"><![CDATA[<p><strong>Git rollback command</strong></p><a id="more"></a><h3 id="Revoke-Operation"><a href="#Revoke-Operation" class="headerlink" title="Revoke Operation"></a>Revoke Operation</h3><ul><li><p>Basic command</p><pre><code class="bash">$ git checkout -- [file]</code></pre></li><li><p>When file just in work area conduct modify, Not yet(还没有) commit to temporary(暂存) storage.<br>You can use this command, To achieve effect(来达到效果)</p><pre><code class="bash">$ git reset HEAD</code></pre></li><li><p>If you in work area conduct the modify, And commit to temporary. `git checkout &#x2013; [file]` command<br>it’s invalid(就无效了).<br>This time should use `git reset HEAD` command to achieve effect.</p><pre><code class="bash">$ git checkout HEAD [file]</code></pre></li><li><p>This command just will two on the top combine(组合起来), Direct use HEAD cover(覆盖) temporary and<br>word area.</p></li></ul><hr><h3 id="Rollback-Version"><a href="#Rollback-Version" class="headerlink" title="Rollback Version"></a>Rollback Version</h3><ul><li><p>Basic command</p><pre><code class="bash">$ git reset --hard HEAD~n</code></pre></li><li><p>In git `HEAD` express current version. This command just rollback to `~` after appoint version.</p><pre><code class="bash">$ git reset --hard commit_id</code></pre></li><li><p>This command just rollback to `commit<sub>id</sub>` version.<br>In git see commit<sub>id</sub> the method: git reflog command.</p></li></ul><hr><h3 id="Delete-Summary"><a href="#Delete-Summary" class="headerlink" title="Delete Summary"></a>Delete Summary</h3><ul><li><p>Basic command</p><pre><code class="bash">$ git rm</code></pre></li><li><p>This command will delete word area and temporary in content.</p></li><li><p>If delete file after, Want to get back(想要找回) just got us(刚刚被我们) delete the file.Use `git checkout HEAD [file]` command to achieve effect. Permise is(前提是) not commit.</p></li><li><p>If delete file after and commit, Then you need use `git reset &#x2013;hard HEAD~1` rollback<br>to one on top version, Can achieve effect(可以达到效果).</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Git</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Java Excel Opreator</title>
    <link href="/2019/01/05/Java%20Excel%20Operator/"/>
    <url>/2019/01/05/Java%20Excel%20Operator/</url>
    
    <content type="html"><![CDATA[<p><strong>记录一次 Apache POI 学习</strong></p><a id="more"></a><h3 id="POI- 介绍"><a href="#POI- 介绍" class="headerlink" title="POI 介绍"></a>POI 介绍</h3><ul><li><p>通过 Java 程序操作 Office 相关组件(本次需求是对 Excel 提出).</p></li><li><p>底层基于 XML, 提供海量数据 (500W) 操作, 支持 xls/xlsx 格式.</p></li></ul><h3 id="使用 - 模拟用户列表导入与导出 Excel"><a href="# 使用 - 模拟用户列表导入与导出 Excel" class="headerlink" title="使用: 模拟用户列表导入与导出 Excel."></a>使用: 模拟用户列表导入与导出 Excel.</h3><ul><li><p>封装一下工具类:</p><pre><code class="java">/*** 指定数据导出到 Excel** @param data* @param out*/public static void exportExcel(List&lt;User&gt; data, OutputStream out) {   HSSFWorkbook workbook = null;   try {       // 创建工作博       workbook = new HSSFWorkbook();       // 合并单元格       CellRangeAddress cellRangeAddress = new CellRangeAddress(0, 0, 0, 4);       // 创建头标题样式       HSSFCellStyle headStyle = createCellStyle(workbook, (short) 16);       // 创建列标题样式       HSSFCellStyle colStyle = createCellStyle(workbook, (short) 13);       // sheet       HSSFSheet sheet = workbook.createSheet(&quot; 用户名单 &quot;);       // 添加合并单元格对象       sheet.addMergedRegion(cellRangeAddress);       // 默认列宽度       sheet.setDefaultColumnWidth(25);       // 创建行       HSSFRow row = sheet.createRow(0);       // 创建单元格       HSSFCell cell = row.createCell(0);       // 加载单元格样式       cell.setCellStyle(headStyle);       cell.setCellValue(&quot; 用户列表 &quot;);       // 创建列标题       HSSFRow titleRow = sheet.createRow(1);       String[] titles = {&quot; 用户名 &quot;, &quot; 年龄 &quot;, &quot; 性别 &quot;, &quot; 邮箱 &quot;, &quot; 手机 &quot;};       // 添加每列标题及样式       for (int i = 0; i &lt; titles.length; i++) {HSSFCell newCell = titleRow.createCell(i);           newCell.setCellStyle(colStyle);           newCell.setCellValue(titles[i]);       }       // 创建单元格 写入数据       if (data != null) {for (int i = 0; i &lt; data.size(); i++) {User user = data.get(i);               // 写入每行数据(前两行已经被占用)               HSSFRow newRow = sheet.createRow(i + 2);               // 姓名               HSSFCell c1 = newRow.createCell(0);               c1.setCellValue(user.getName());               // 年龄               HSSFCell c2 = newRow.createCell(1);               c2.setCellValue(user.getAge());               // 性别               HSSFCell c3 = newRow.createCell(2);               c3.setCellValue(user.getSex() == 1 ? &quot; 男 &quot; : &quot; 女 &quot;);               // 邮箱               HSSFCell c4 = newRow.createCell(3);               c4.setCellValue(user.getEmail());               // 手机               HSSFCell c5 = newRow.createCell(4);               c5.setCellValue(user.getPhone());           }       }       // 写入到文件       workbook.write(out);   } catch (Exception e) {e.printStackTrace();   } finally {       // 关闭       try {workbook.close();       } catch (IOException e) {e.printStackTrace();       }   }}/*** 单元格样式配置** @param workbook* @param fontSize* @return*/private static HSSFCellStyle createCellStyle(HSSFWorkbook workbook, short fontSize) {HSSFCellStyle style = workbook.createCellStyle();   // 水平居中   style.setAlignment(HorizontalAlignment.CENTER);   // 垂直居中   style.setVerticalAlignment(VerticalAlignment.CENTER);   // 字体   HSSFFont font = workbook.createFont();   font.setBold(true);   font.setFontHeightInPoints(fontSize);   // 加载字体   style.setFont(font);   return style;}/*** Excel 文件导入** @param file* @return*/public static List&lt;User&gt; importExcel(File file) {   FileInputStream inputStream = null;   List&lt;User&gt; list = null;   HSSFWorkbook workbook = null;   try {list = new ArrayList&lt;&gt;();       inputStream = new FileInputStream(file);       // 读取文件       workbook = new HSSFWorkbook(inputStream);       // 读取 sheet       HSSFSheet sheet = workbook.getSheetAt(0);       // 读取行(行数大于 2)       if (sheet.getPhysicalNumberOfRows() &gt; 2) {           User user = null;           // 跳过前两行           for (int i = 2; i &lt; sheet.getPhysicalNumberOfRows(); i++) {               // 单元格               Row row0 = sheet.getRow(i);               user = new User();               // 封装数据               Cell cell0 = row0.getCell(0);               user.setName(cell0.getStringCellValue());               Cell cell1 = row0.getCell(1);               user.setAge(cell1.getStringCellValue());               Cell cell2 = row0.getCell(2);               user.setSex(cell2.getStringCellValue().equals(&quot; 男 &quot;) ? 1 : 0);               Cell cell3 = row0.getCell(3);               user.setEmail(cell3.getStringCellValue());               Cell cell4 = row0.getCell(4);               user.setPhone(cell4.getStringCellValue());               list.add(user);           }       }       workbook.close();} catch (Exception e) {e.printStackTrace();   } finally {       try {inputStream.close();       } catch (IOException e) {e.printStackTrace();       }   }   return list;}</code></pre><ul><li>工具类已经写好了, 下面我们来看一下 Controller 层代码.</li></ul><pre><code class="java">/*** Export Excel Api** @param request* @param response* @return*/@PostMapping(&quot;/v1/export&quot;)public String exportExcel(HttpServletRequest request, HttpServletResponse response) {   ServletOutputStream out = null;   try {List&lt;User&gt; list = (List&lt;User&gt;) request.getSession().getAttribute(&quot;users&quot;);       if (list != null) {response.setContentType(&quot;application/vnd.ms-excel;charset=gb2312&quot;);           response.setHeader(&quot;Content-Disposition&quot;, &quot;attachment;filename = &quot; + new String(&quot; 用户列表.xls&quot;.getBytes(), &quot;ISO-8859-1&quot;));           out = response.getOutputStream();           ExportExcelUtil.exportExcel(list, out);       }   } catch (Exception e) {e.printStackTrace();   }   return null;}/*** Import Excel Api** @param request* @param response* @param file* @return*/@PostMapping(&quot;/v1/import&quot;)public String importExcel(HttpServletRequest request, HttpServletResponse response, MultipartFile file) {if (file != null &amp;&amp; !file.isEmpty()) {String filePath = request.getSession().getServletContext().getRealPath(&quot;/&quot;) + file.getOriginalFilename();       try {file.transferTo(new File(filePath));       } catch (IOException e) {e.printStackTrace();       }   }   return &quot;redirect:/users/v1/upload&quot;;}/*** Find Specify File And Import** @param request* @param response* @return*/@RequestMapping(&quot;/v1/upload&quot;)public String fileUpload(HttpServletRequest request, HttpServletResponse response) {String filePath = request.getSession().getServletContext().getRealPath(&quot;/&quot;);   File uploadDest = new File(filePath);   String[] fileNames = uploadDest.list();   for (int i = 0; i &lt; fileNames.length; i++) {       // 打印出文件名       System.out.println(fileNames[i]);       List&lt;User&gt; list = ExportExcelUtil.importExcel(new File(filePath + fileNames[i]));       List&lt;User&gt; old = (List&lt;User&gt;) request.getSession().getAttribute(&quot;users&quot;);       old.addAll(list);   }   return &quot;user&quot;;}</code></pre><p>Source: <a href="https://github.com/727474430/Apache-POI" target="_blank" rel="noopener">link</a></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
