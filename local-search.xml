<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Idea Plugin</title>
    <link href="/2020/04/09/Idea%20Plugin/"/>
    <url>/2020/04/09/Idea%20Plugin/</url>
    
    <content type="html"><![CDATA[<p><strong>Intellij Idea</strong> 插件推荐</p><a id="more"></a><h3 id="关于那些常用的 -Intellij-Idea- 插件推荐"><a href="# 关于那些常用的 -Intellij-Idea- 插件推荐" class="headerlink" title="关于那些常用的 Intellij Idea 插件推荐"></a>关于那些常用的 Intellij Idea 插件推荐</h3><ul><li>在我们日常开发过程中, 都难免或多或少有自己喜欢得一些插件, 有的可以提升我们的开发效率, 有的则可以美化我们的工作窗口, 今天笔者将推荐一些自己在开发过程中使用的插件, 当然是基于现在最流行的 Java 开发 Idea 而言.</li></ul><h3 id="进入正题"><a href="# 进入正题" class="headerlink" title="进入正题"></a>进入正题</h3><ul><li><p><strong>Translation</strong></p><p>首先推荐这个插件, 因为笔者英文不太好 (其实是很不好), 那么我就喜欢一款即时翻译得插件, 来帮助我在日常开发中随时翻译一些不懂得内容, 安装方式很简单, 在 Intellij 中依次选择 Preferences -&gt; Plugins -&gt; Search in repositories -&gt; 搜索 Translation 安装即可(其他插件一样), 插件使用得方式很简单, 只需要执行默认快捷键 “<strong>Alt + 1</strong>“ 就 OK 啦, 简直 easy 妈妈再也不用担心我们英文了！<br> 下面我们看一下使用效果:</p><p><img src="http://qiniu.raindrop-wl.cn/translation.png" srcset="/img/loading.gif" alt="img"></p></li><li><p><strong>Maven Helper</strong></p><p>日常工作中大部分项目都通过 Maven 来进行管理(当然现在也有很多基于 Gredle 开发的项目), 那就不得不提这个插件了. 这个插件可以将当前 Maven 项目的依赖树、依赖冲突、依赖列表帮我们完整的展示出来, 并且有很客观的呈现. 同时该插件提供了可以搜索得功能(简直完美)！下面我们看一下使用效果.</p><p><img src="http://qiniu.raindrop-wl.cn/maven.png" srcset="/img/loading.gif" alt="img"></p></li><li><p><strong>Grep Console</strong></p><p>该插件帮助我们将不同级别的日志用不同颜色标记起来.</p><p><img src="http://qiniu.raindrop-wl.cn/grep-console.png" srcset="/img/loading.gif" alt="img"></p></li><li><p><strong>ideaVim</strong></p><p>重度 Vim 使用人员离不开的插件, 在 Intellij 中下载次数也是摇摇领先, 喜欢 Vim 模式得同学们不要错过了！快捷键都是可以自定义的, 下面看一下自定义快捷键.</p><p><img src="http://qiniu.raindrop-wl.cn/ideavim.png" srcset="/img/loading.gif" alt="img"></p></li><li><p><strong>FindBugs-IDEA</strong></p><p>这个插件相信很多同学已经在 Eclipse 中接触过了, 当然 Idea 中同样提供了该插件帮助我们开发人员第一时间找到有漏洞得代码, 该插件提供了单独得插件窗口.</p><p><img src="http://qiniu.raindrop-wl.cn/findbugs.png" srcset="/img/loading.gif" alt="img"></p></li><li><p><strong>JRebel</strong></p><p>这个插件是一款热部署插件, 如果你得项目没有合适的热部署功能的话推荐你使用该插件, 配置简单使用简单, 当我们开启项目时只需要选择 JRebel 开启就行了.</p><p><img src="http://qiniu.raindrop-wl.cn/jrebel.png" srcset="/img/loading.gif" alt="img"></p></li><li><p><strong>BashSupport</strong></p><p>一款可以识别 shell 得插件, 让我们可以在 Idea 中轻松构建.sh 代码并且执行.</p><p><img src="http://qiniu.raindrop-wl.cn/bash.png" srcset="/img/loading.gif" alt="img"></p></li><li><p><strong>Markdown Navigator</strong></p><p>markdown 语法器插件, 通过该插件我们可以轻松的在 idea 中构建.md 文件, 并且使用 markdown 语法进行文件编写.</p><p><img src="http://qiniu.raindrop-wl.cn/markdown.png" srcset="/img/loading.gif" alt="img"></p></li><li><p><strong>Alibaba Cloud Toolkit</strong></p><p>阿里巴巴提供的 Idea 插件，可以链接阿里云 ECS、远程服务器、文件上传、部署 ECS 等等.</p><p><img src="http://qiniu.raindrop-wl.cn/alibaba-cloud.png" srcset="/img/loading.gif" alt="img"><br><img src="http://qiniu.raindrop-wl.cn/alibaba-cloud-01.png" srcset="/img/loading.gif" alt="img"></p></li><li><p><strong>ASM Bytecode Outline</strong></p><p>字节码展示插件</p><p><img src="http://qiniu.raindrop-wl.cn/ASM-bytecode.png" srcset="/img/loading.gif" alt="img"></p></li><li><p>好啦! 到这里笔者常用得 idea 插件已经贡献出来给大家了, 希望大家可以从中找到自己喜爱的插件并用于开发中. 感谢大家观看!</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Redis 分布式锁</title>
    <link href="/2020/03/26/Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
    <url>/2020/03/26/Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</url>
    
    <content type="html"><![CDATA[<center> <font face="黑体" size="6">Redis 分布式锁</font> </center><a id="more"></a><h3 id="背景"><a href="# 背景" class="headerlink" title="背景"></a>背景 </h3><p> 随着互联网应用从单体应用部署，到分布式部署，除了有好的方面外，随之而带来的问题也不断涌现。其中，最为重要的数据一致性问题，在分布式情况下并发对共享数据源进行写操作带来的数据 <br> 安全问题，都需要优先考虑在程序设计之中。<br>本次将从单体应用出发，到分布式集群部署，一步一步模拟在高并发程序下，不断涌现出的数据一致性问题，并对问题逐步解决的记录。</p><h5 id="环境"><a href="# 环境" class="headerlink" title="环境"></a>环境 </h5><p> 首先使用 SpringBoot 搭建一个基础的 Web 服务</p><p><code>pom.xml</code></p><pre><code class="xml">&lt;dependencies&gt;    &lt;!-- Web --&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;!-- Redis --&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;</code></pre><p><code>application.yml</code></p><pre><code class="yaml"># 端口server:  port: 8080spring:  application:    name: redis-lock  # 缓存配置  redis:    host: localhost    port: 6379    database: 0    password:</code></pre><hr><h5 id="无锁单节点"><a href="# 无锁单节点" class="headerlink" title="无锁单节点"></a>无锁单节点 </h5><p><code> 首先我们来看在单节点情况下，不使用锁进行资源保护，对订单接口进行并发访问带来对问题</code></p><pre><code class="java">@Slf4j@RestController@RequestMapping(&quot;/orders&quot;)public class OrderController {    public static final String ORDER_STOCK_KEY = &quot;order:stock&quot;;    @Autowired    private RedisTemplate&lt;String, String&gt; redisTemplate;    /**     * 创建订单，使用 Redis 模拟数据源     *     *     * @return     */    @GetMapping(&quot;/createOrder&quot;)    public String unsafeDeductOrder() {log.info(&quot; 开始创建订单...........&quot;);        String stockNum = redisTemplate.opsForValue().get(ORDER_STOCK_KEY);        if (StringUtils.isEmpty(stockNum)) {log.warn(&quot; 订单创建失败，库存不足！&quot;);            return &quot; 订单创建失败，库存不足！&quot;;        }        int stock = Integer.parseInt(stockNum);        if (stock &lt;= 0) {log.warn(&quot; 订单创建失败，库存不足！&quot;);            return &quot; 订单创建失败，库存不足！&quot;;        }        log.info(&quot; 扣减前库存数: {}&quot;, stock);        redisTemplate.opsForValue().set(ORDER_STOCK_KEY, String.valueOf(stock - 1));        log.info(&quot; 扣减后库存数: {}&quot;, redisTemplate.opsForValue().get(ORDER_STOCK_KEY));        log.info(&quot; 结束创建订单...........&quot;);        return &quot; 当前库存数：&quot; + redisTemplate.opsForValue().get(ORDER_STOCK_KEY);    }}</code></pre><p><code>初始化订单库存</code></p><pre><code class="bash">redis&gt; set order:stock 50OKredis&gt; get order:stock50</code></pre><p><code>使用 Jmeter 模拟 200 并发，对创建订单接口进行访问，如果程序正常，应该在创建 50 个订单后，返回库存不足</code></p><div aligh="center">    <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/Redis 分布式锁 /jmeter-200c.png" srcset="/img/loading.gif" width="100%"></div><div aligh="center">    <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/Redis 分布式锁 /jmeter-create-order.png" srcset="/img/loading.gif" width="100%"></div><p><code>查看结果，所有请求都成功了。但是我们可以看到日志中存在严重的重复扣减库存，这在真实环境是可怕的问题。同时查看最后一个请 求返回都结果，显示当前库存为 46 远比我们都预期差的多</code></p><pre><code class="java">2020-03-28 20:38:00.718  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 20:38:00.718  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 20:38:00.718  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 20:38:01.013  c.r.r.lock.controller.OrderController    : 扣减前库存数: 502020-03-28 20:38:01.013  c.r.r.lock.controller.OrderController    : 扣减前库存数: 502020-03-28 20:38:01.013  c.r.r.lock.controller.OrderController    : 扣减前库存数: 50......2020-03-28 20:38:01.168  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 20:38:01.158  c.r.r.lock.controller.OrderController    : 扣减后库存数: 492020-03-28 20:38:01.169  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 20:38:01.158  c.r.r.lock.controller.OrderController    : 扣减前库存数: 492020-03-28 20:38:01.169  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 20:38:01.158  c.r.r.lock.controller.OrderController    : 扣减前库存数: 49</code></pre><div aligh="center">    <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/Redis 分布式锁 /jmeter-result-01.png" srcset="/img/loading.gif" width="100%"></div><div aligh="center">    <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/Redis 分布式锁 /jmeter-result-tree-01.png" srcset="/img/loading.gif" width="100%"></div><hr><h5 id="Sync- 锁单节点"><a href="#Sync- 锁单节点" class="headerlink" title="Sync 锁单节点"></a>Sync 锁单节点 </h5><p><code> 在单体应用的情况下，我们可以通过使用锁的方式来避免上述问题。这里简单使用 synchronized 锁</code></p><pre><code class="java">@Slf4j@RestController@RequestMapping(&quot;/orders&quot;)public class OrderController {    public static final String ORDER_STOCK_KEY = &quot;order:stock&quot;;    @Autowired    private RedisTemplate&lt;String, String&gt; redisTemplate;    /**     * 创建订单，添加 synchronized 锁     *     * @return     */    @GetMapping(&quot;/createOrder&quot;)    public synchronized String unsafeDeductOrder() {log.info(&quot; 开始创建订单...........&quot;);        String stockNum = redisTemplate.opsForValue().get(ORDER_STOCK_KEY);        if (StringUtils.isEmpty(stockNum)) {log.warn(&quot; 订单创建失败，库存不足！&quot;);            return &quot; 订单创建失败，库存不足！&quot;;        }        int stock = Integer.parseInt(stockNum);        if (stock &lt;= 0) {log.warn(&quot; 订单创建失败，库存不足！&quot;);            return &quot; 订单创建失败，库存不足！&quot;;        }        log.info(&quot; 扣减前库存数: {}&quot;, stock);        redisTemplate.opsForValue().set(ORDER_STOCK_KEY, String.valueOf(stock - 1));        log.info(&quot; 扣减后库存数: {}&quot;, redisTemplate.opsForValue().get(ORDER_STOCK_KEY));        log.info(&quot; 结束创建订单...........&quot;);        return &quot; 当前库存数：&quot; + redisTemplate.opsForValue().get(ORDER_STOCK_KEY);    }}</code></pre><p><code>初始化订单库存</code></p><pre><code class="bash">redis&gt; set order:stock 50OKredis&gt; get order:stock50</code></pre><p><code>使用 Jmeter 模拟 200 并发，对创建订单接口进行访问，如果程序正常，应该在创建 50 个订单后，返回库存不足</code></p><div aligh="center">    <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/Redis 分布式锁 /jmeter-200c.png" srcset="/img/loading.gif" width="100%"></div><div aligh="center">    <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/Redis 分布式锁 /jmeter-create-order.png" srcset="/img/loading.gif" width="100%"></div><p><code>查看结果，所有请求都成功了。查看响应结果也正常，无重复扣减库存，在扣减了 50 个库存后，正常返回无库存</code></p><pre><code class="java">2020-03-28 20:26:56.227  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 20:26:56.461  c.r.r.lock.controller.OrderController    : 扣减前库存数: 502020-03-28 20:26:56.466  c.r.r.lock.controller.OrderController    : 扣减后库存数: 492020-03-28 20:26:56.467  c.r.r.lock.controller.OrderController    : 结束创建订单...........2020-03-28 20:26:56.469  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 20:26:56.471  c.r.r.lock.controller.OrderController    : 扣减前库存数: 492020-03-28 20:26:56.476  c.r.r.lock.controller.OrderController    : 扣减后库存数: 482020-03-28 20:26:56.476  c.r.r.lock.controller.OrderController    : 结束创建订单...........2020-03-28 20:26:56.478  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 20:26:56.480  c.r.r.lock.controller.OrderController    : 扣减前库存数: 482020-03-28 20:26:56.483  c.r.r.lock.controller.OrderController    : 扣减后库存数: 472020-03-28 20:26:56.484  c.r.r.lock.controller.OrderController    : 结束创建订单.................2020-03-28 20:26:56.831  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 20:26:56.833  c.r.r.lock.controller.OrderController    : 扣减前库存数: 22020-03-28 20:26:56.835  c.r.r.lock.controller.OrderController    : 扣减后库存数: 12020-03-28 20:26:56.836  c.r.r.lock.controller.OrderController    : 结束创建订单...........2020-03-28 20:26:56.837  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 20:26:56.839  c.r.r.lock.controller.OrderController    : 扣减前库存数: 12020-03-28 20:26:56.842  c.r.r.lock.controller.OrderController    : 扣减后库存数: 02020-03-28 20:26:56.842  c.r.r.lock.controller.OrderController    : 结束创建订单...........2020-03-28 20:26:56.843  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 20:26:56.845  c.r.r.lock.controller.OrderController    : 订单创建失败，库存不足！</code></pre><div aligh="center">    <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/Redis 分布式锁 /jmeter-result-02.png" srcset="/img/loading.gif" width="100%"></div><hr><h5 id="Sync- 锁多节点"><a href="#Sync- 锁多节点" class="headerlink" title="Sync 锁多节点"></a>Sync 锁多节点 </h5><p><code> 如上，在单节点部署情况下使用 synchronized 锁可以解决问题，那么我们再来看看多节点集群部署情况下，是否能正常运行</code></p><ul><li>启动 8080 端口应用</li></ul><pre><code class="yaml"># 端口server:  port: 8080</code></pre><ul><li>启动 8081 端口应用</li></ul><pre><code class="yaml"># 端口server:  port: 8081</code></pre><p><code>使用 Nginx 做负载，将流量分别打入两个应用</code></p><pre><code class="conf">upstream backend {    server localhost:8080;    server localhost:8081;}server {    listen 80;    server_name localhost;    location / {proxy_pass http://backend;}}</code></pre><p><code>初始化订单库存</code></p><pre><code class="bash">redis&gt; set order:stock 50OKredis&gt; get order:stock50</code></pre><p><code>使用 Jmeter 模拟 200 并发，访问 Nginx 入口，对两个节点进行负载均衡。如果程序正常，应该在创建 50 个订单后，返回库存不足</code></p><div aligh="center">    <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/Redis 分布式锁 /jmeter-200c.png" srcset="/img/loading.gif" width="100%"></div><div aligh="center">    <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/Redis 分布式锁 /jmeter-create-order-nginx.png" srcset="/img/loading.gif" width="100%"></div><p><code>查看结果，所有请求都成功了。查看响应结发现存在重复扣减库存情况</code></p><ul><li>8080 节点日志</li></ul><pre><code class="java">2020-03-28 21:00:03.203  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 21:00:03.260  c.r.r.lock.controller.OrderController    : 扣减前库存数: 502020-03-28 21:00:03.270  c.r.r.lock.controller.OrderController    : 扣减后库存数: 492020-03-28 21:00:03.271  c.r.r.lock.controller.OrderController    : 结束创建订单.................2020-03-28 21:00:03.684  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 21:00:03.688  c.r.r.lock.controller.OrderController    : 扣减前库存数: 262020-03-28 21:00:03.693  c.r.r.lock.controller.OrderController    : 扣减后库存数: 252020-03-28 21:00:03.693  c.r.r.lock.controller.OrderController    : 结束创建订单..............2020-03-28 21:00:04.162  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 21:00:04.164  c.r.r.lock.controller.OrderController    : 订单创建失败，库存不足！</code></pre><ul><li>8081 节点日志</li></ul><pre><code class="java">2020-03-28 21:00:03.203  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 21:00:03.264  c.r.r.lock.controller.OrderController    : 扣减前库存数: 502020-03-28 21:00:03.274  c.r.r.lock.controller.OrderController    : 扣减后库存数: 492020-03-28 21:00:03.274  c.r.r.lock.controller.OrderController    : 结束创建订单.................2020-03-28 21:00:03.687  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 21:00:03.690  c.r.r.lock.controller.OrderController    : 扣减前库存数: 262020-03-28 21:00:03.695  c.r.r.lock.controller.OrderController    : 扣减后库存数: 252020-03-28 21:00:03.695  c.r.r.lock.controller.OrderController    : 结束创建订单..............2020-03-28 21:00:04.162  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 21:00:04.164  c.r.r.lock.controller.OrderController    : 订单创建失败，库存不足！</code></pre><div aligh="center">    <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/Redis 分布式锁 /jmeter-result-02.png" srcset="/img/loading.gif" width="100%"></div><hr><h5 id="Redis-setnx- 多节点"><a href="#Redis-setnx- 多节点" class="headerlink" title="Redis.setnx 多节点"></a>Redis.setnx 多节点 </h5><p><code> 我们可以看到，当在分布式情况下 synchronized 锁就无能为力了，因为集群中当每个节点都是在单独的 jvm 中运行的， 所以 synchronized 只能在当前 jvm 下保证并发安全。我们可以使用 redis 提供的 setnx 命令进行加锁，来保证集群情况下的并发安全</code></p><blockquote><p>redis.setnx: 命令在指定的 key 不存在时，为 key 设置指定的值。如果指定的 key 存在，则不做任何操作。</p></blockquote><pre><code class="java">@Slf4j@RestController@RequestMapping(&quot;/orders&quot;)public class OrderController {    public static final String ORDER_STOCK_KEY = &quot;order:stock&quot;;    public static final String LOCK_KEY = &quot;lock:key&quot;;    public static final String LOCK_VALUE = &quot;lock:value&quot;;    @Autowired    private RedisTemplate&lt;String, String&gt; redisTemplate;    /**     * 创建订单     *     * @return     */    @GetMapping(&quot;/createOrder&quot;)    public String unsafeDeductOrder() {        // 这里使用 SpringBoot 提供的 setIfAbsent api 模拟 setnx 的效果        // 如果返回 true 表示获取锁成功，正常创建订单。否则失败，不做任何操作        Boolean flag = redisTemplate.opsForValue().setIfAbsent(LOCK_KEY, LOCK_VALUE);        if (!flag) {return &quot;&quot;;}        log.info(&quot; 开始创建订单...........&quot;);        String stockNum = redisTemplate.opsForValue().get(ORDER_STOCK_KEY);        if (StringUtils.isEmpty(stockNum)) {log.warn(&quot; 订单创建失败，库存不足！&quot;);            return &quot; 订单创建失败，库存不足！&quot;;        }        int stock = Integer.parseInt(stockNum);        if (stock &lt;= 0) {log.warn(&quot; 订单创建失败，库存不足！&quot;);            // 注意，如果库存已经没有了，需要释放掉锁，不然会造成死锁            redisTemplate.delete(LOCK_KEY);            return &quot; 订单创建失败，库存不足！&quot;;        }        log.info(&quot; 扣减前库存数: {}&quot;, stock);        redisTemplate.opsForValue().set(ORDER_STOCK_KEY, String.valueOf(stock - 1));        log.info(&quot; 扣减后库存数: {}&quot;, redisTemplate.opsForValue().get(ORDER_STOCK_KEY));        // 注意，在处理完业务后，需要释放掉锁，不然会造成死锁        redisTemplate.delete(LOCK_KEY);        log.info(&quot; 结束创建订单...........&quot;);        return &quot; 当前库存数：&quot; + redisTemplate.opsForValue().get(ORDER_STOCK_KEY);    }}</code></pre><ul><li>启动 8080 端口应用</li></ul><pre><code class="yaml"># 端口server:  port: 8080</code></pre><ul><li>启动 8081 端口应用</li></ul><pre><code class="yaml"># 端口server:  port: 8081</code></pre><p><code>使用 Jmeter 模拟 5s 1000 并发，对创建订单接口进行访问</code></p><div aligh="center">    <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/Redis 分布式锁 /jmeter-1000c.png" srcset="/img/loading.gif" width="100%"></div><p><code>查看结果，所有请求都成功了。查看响应结发现没有重复扣减库存情况，说明 redis.setnx 可以保证分布式下的并发安全问题</code></p><ul><li>8080 节点日志</li></ul><pre><code class="java">2020-03-28 21:56:59.285  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 21:56:59.297  c.r.r.lock.controller.OrderController    : 扣减前库存数: 472020-03-28 21:56:59.311  c.r.r.lock.controller.OrderController    : 扣减后库存数: 462020-03-28 21:56:59.318  c.r.r.lock.controller.OrderController    : 结束创建订单...........2020-03-28 21:56:59.421  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 21:56:59.443  c.r.r.lock.controller.OrderController    : 扣减前库存数: 452020-03-28 21:56:59.500  c.r.r.lock.controller.OrderController    : 扣减后库存数: 442020-03-28 21:56:59.528  c.r.r.lock.controller.OrderController    : 结束创建订单.................2020-03-28 21:57:02.157  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 21:57:02.159  c.r.r.lock.controller.OrderController    : 扣减前库存数: 32020-03-28 21:57:02.166  c.r.r.lock.controller.OrderController    : 扣减后库存数: 22020-03-28 21:57:02.170  c.r.r.lock.controller.OrderController    : 结束创建订单...........2020-03-28 21:57:02.177  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 21:57:02.180  c.r.r.lock.controller.OrderController    : 扣减前库存数: 22020-03-28 21:57:02.186  c.r.r.lock.controller.OrderController    : 扣减后库存数: 12020-03-28 21:57:02.189  c.r.r.lock.controller.OrderController    : 结束创建订单...........2020-03-28 21:57:02.206  c.r.r.lock.controller.OrderController    : 开始创建订单...........2020-03-28 21:57:02.210  c.r.r.lock.controller.OrderController    : 订单创建失败，库存不足！</code></pre><ul><li>8081 节点日志</li></ul><pre><code class="java">2020-03-28 21:56:59.135 c.r.r.lock.controller.OrderController : 开始创建订单...........2020-03-28 21:56:59.148 c.r.r.lock.controller.OrderController : 扣减前库存数: 502020-03-28 21:56:59.156 c.r.r.lock.controller.OrderController : 扣减后库存数: 492020-03-28 21:56:59.162 c.r.r.lock.controller.OrderController : 结束创建订单...........2020-03-28 21:56:59.194 c.r.r.lock.controller.OrderController : 开始创建订单...........2020-03-28 21:56:59.217 c.r.r.lock.controller.OrderController : 扣减前库存数: 492020-03-28 21:56:59.236 c.r.r.lock.controller.OrderController : 扣减后库存数: 482020-03-28 21:56:59.528 c.r.r.lock.controller.OrderController : 结束创建订单.................2020-03-28 21:57:02.124 c.r.r.lock.controller.OrderController : 开始创建订单...........2020-03-28 21:57:02.131 c.r.r.lock.controller.OrderController : 扣减前库存数: 52020-03-28 21:57:02.138 c.r.r.lock.controller.OrderController : 扣减后库存数: 42020-03-28 21:57:02.141 c.r.r.lock.controller.OrderController : 结束创建订单...........2020-03-28 21:57:02.191 c.r.r.lock.controller.OrderController : 开始创建订单...........2020-03-28 21:57:02.196 c.r.r.lock.controller.OrderController : 扣减前库存数: 12020-03-28 21:57:02.201 c.r.r.lock.controller.OrderController : 扣减后库存数: 02020-03-28 21:57:02.204 c.r.r.lock.controller.OrderController : 结束创建订单...........2020-03-28 21:57:02.206 c.r.r.lock.controller.OrderController : 开始创建订单...........2020-03-28 21:57:02.210 c.r.r.lock.controller.OrderController : 订单创建失败，库存不足！</code></pre><h5 id="Redis-setnx- 多节点 -finally"><a href="#Redis-setnx- 多节点 -finally" class="headerlink" title="Redis.setnx 多节点 finally"></a>Redis.setnx 多节点 finally</h5><p><code>虽然以上代码已经可以保证分布式下的并发安全，但是代码还存在这问题。假设我们的程序在创建订单的过程中出现异常，那么上述代码就会因为没有及时删除锁，而造成死锁。那么解决方法也比较简单，我们在 finally 块中删除锁，就可以了</code></p><pre><code class="java">@Slf4j@RestController@RequestMapping(&quot;/orders&quot;)public class OrderController {    public static final String ORDER_STOCK_KEY = &quot;order:stock&quot;;    public static final String LOCK_KEY = &quot;lock:key&quot;;    public static final String LOCK_VALUE = &quot;lock:value&quot;;    @Autowired    private RedisTemplate&lt;String, String&gt; redisTemplate;    /**     * 创建订单     *     * @return     */    @GetMapping(&quot;/createOrder&quot;)    public String unsafeDeductOrder() {        // 这里使用 SpringBoot 提供的 setIfAbsent api 模拟 setnx 的效果        // 如果返回 true 表示获取锁成功，正常创建订单。否则失败，不做任何操作        Boolean flag = redisTemplate.opsForValue().setIfAbsent(LOCK_KEY, LOCK_VALUE);        if (!flag) {return &quot;&quot;;}        log.info(&quot; 开始创建订单...........&quot;);        try {String stockNum = redisTemplate.opsForValue().get(ORDER_STOCK_KEY);            if (StringUtils.isEmpty(stockNum)) {log.warn(&quot; 订单创建失败，库存不足！&quot;);                return &quot; 订单创建失败，库存不足！&quot;;            }            int stock = Integer.parseInt(stockNum);            if (stock &lt;= 0) {log.warn(&quot; 订单创建失败，库存不足！&quot;);                return &quot; 订单创建失败，库存不足！&quot;;            }            log.info(&quot; 扣减前库存数: {}&quot;, stock);            redisTemplate.opsForValue().set(ORDER_STOCK_KEY, String.valueOf(stock - 1));            log.info(&quot; 扣减后库存数: {}&quot;, redisTemplate.opsForValue().get(ORDER_STOCK_KEY));        } catch (Exception e) {// do something} finally {            // 注意，在处理完业务后，需要释放掉锁，不然会造成死锁            redisTemplate.delete(LOCK_KEY);        }        log.info(&quot; 结束创建订单...........&quot;);        return &quot; 当前库存数：&quot; + redisTemplate.opsForValue().get(ORDER_STOCK_KEY);    }}</code></pre><hr><h5 id="Redis-setnx- 多节点 -expire- 非原子"><a href="#Redis-setnx- 多节点 -expire- 非原子" class="headerlink" title="Redis.setnx 多节点 expire 非原子"></a>Redis.setnx 多节点 expire 非原子 </h5><p><code> 上述代码已经保证了如果业务代码出现了异常，一样可以正常释放锁，来避免发生死锁。但是并没有完，如果程序运行程中服务器宕机了，那么如上代码还是会因为没有删除锁，而造成程序的死锁。那么我们可以给 setnx 的 key 设置一个 expire 过期时间，这样如果程序在运行中服务宕机了锁也会在 expire 过期时间到达后，进行删除锁</code></p><pre><code class="java">@Slf4j@RestController@RequestMapping(&quot;/orders&quot;)public class OrderController {    public static final String ORDER_STOCK_KEY = &quot;order:stock&quot;;    public static final String LOCK_KEY = &quot;lock:key&quot;;    public static final String LOCK_VALUE = &quot;lock:value&quot;;    @Autowired    private RedisTemplate&lt;String, String&gt; redisTemplate;    /**     * 创建订单     *     * @return     */    @GetMapping(&quot;/createOrder&quot;)    public String unsafeDeductOrder() {        // 这里使用 SpringBoot 提供的 setIfAbsent api 模拟 setnx 的效果        // 如果返回 true 表示获取锁成功，正常创建订单。否则失败，不做任何操作        Boolean flag = redisTemplate.opsForValue().setIfAbsent(LOCK_KEY, LOCK_VALUE);        if (!flag) {return &quot;&quot;;}        // 这里设置 5s 过期，当服务器宕机时 5s 后 redis 会自动删除锁        redisTemplate.expire(LOCK_KEY, 5, TimeUnit.SECONDS);        log.info(&quot; 开始创建订单...........&quot;);        try {String stockNum = redisTemplate.opsForValue().get(ORDER_STOCK_KEY);            if (StringUtils.isEmpty(stockNum)) {log.warn(&quot; 订单创建失败，库存不足！&quot;);                return &quot; 订单创建失败，库存不足！&quot;;            }            int stock = Integer.parseInt(stockNum);            if (stock &lt;= 0) {log.warn(&quot; 订单创建失败，库存不足！&quot;);                return &quot; 订单创建失败，库存不足！&quot;;            }            log.info(&quot; 扣减前库存数: {}&quot;, stock);            redisTemplate.opsForValue().set(ORDER_STOCK_KEY, String.valueOf(stock - 1));            log.info(&quot; 扣减后库存数: {}&quot;, redisTemplate.opsForValue().get(ORDER_STOCK_KEY));        } catch (Exception e) {// do something} finally {            // 注意，在处理完业务后，需要释放掉锁，不然会造成死锁            redisTemplate.delete(LOCK_KEY);        }        log.info(&quot; 结束创建订单...........&quot;);        return &quot; 当前库存数：&quot; + redisTemplate.opsForValue().get(ORDER_STOCK_KEY);    }}</code></pre><hr><h5 id="Redis-setnx- 多节点 -expire- 原子操作"><a href="#Redis-setnx- 多节点 -expire- 原子操作" class="headerlink" title="Redis.setnx 多节点 expire 原子操作"></a>Redis.setnx 多节点 expire 原子操作 </h5><p><code> 上述代码已经保证了如果服务器宕机，一样可以正常释放锁，来避免发生死锁。但是并没有完，如果服务器在 setnx 和 expire 代码中间宕机了，那么如上代码还是会因为没有删除锁，而造成程序的死锁。那么我们可以使用 setnx(key, value, timeout, unit) api 来保证获取锁和过期设置的原子性，来解决上述问题</code></p><pre><code class="java">@Slf4j@RestController@RequestMapping(&quot;/orders&quot;)public class OrderController {    public static final String ORDER_STOCK_KEY = &quot;order:stock&quot;;    public static final String LOCK_KEY = &quot;lock:key&quot;;    public static final String LOCK_VALUE = &quot;lock:value&quot;;    @Autowired    private RedisTemplate&lt;String, String&gt; redisTemplate;    /**     * 创建订单     *     * @return     */    @GetMapping(&quot;/createOrder&quot;)    public String unsafeDeductOrder() {        // 这里使用 SpringBoot 提供的 setIfAbsent api 模拟 setnx 的效果        // 如果返回 true 表示获取锁成功，正常创建订单。否则失败，不做任何操作        // 这里设置 5s 过期，当服务器宕机时 5s 后 redis 会自动删除锁，保证获取锁和过期设置的原子性        Boolean flag = redisTemplate.opsForValue().setIfAbsent(LOCK_KEY, LOCK_VALUE, 5, TimeUnit.SECONDS);        if (!flag) {return &quot;&quot;;}        log.info(&quot; 开始创建订单...........&quot;);        try {String stockNum = redisTemplate.opsForValue().get(ORDER_STOCK_KEY);            if (StringUtils.isEmpty(stockNum)) {log.warn(&quot; 订单创建失败，库存不足！&quot;);                return &quot; 订单创建失败，库存不足！&quot;;            }            int stock = Integer.parseInt(stockNum);            if (stock &lt;= 0) {log.warn(&quot; 订单创建失败，库存不足！&quot;);                return &quot; 订单创建失败，库存不足！&quot;;            }            log.info(&quot; 扣减前库存数: {}&quot;, stock);            redisTemplate.opsForValue().set(ORDER_STOCK_KEY, String.valueOf(stock - 1));            log.info(&quot; 扣减后库存数: {}&quot;, redisTemplate.opsForValue().get(ORDER_STOCK_KEY));        } catch (Exception e) {// do something} finally {            // 注意，在处理完业务后，需要释放掉锁，不然会造成死锁            redisTemplate.delete(LOCK_KEY);        }        log.info(&quot; 结束创建订单...........&quot;);        return &quot; 当前库存数：&quot; + redisTemplate.opsForValue().get(ORDER_STOCK_KEY);    }}</code></pre><hr><h5 id="Redis-setnx- 多节点 -expire- 原子操作超时程序未执行完，添加 -clientId-uuid- 判断，避免释放其他线程锁"><a href="#Redis-setnx- 多节点 -expire- 原子操作超时程序未执行完，添加 -clientId-uuid- 判断，避免释放其他线程锁" class="headerlink" title="Redis.setnx 多节点 expire 原子操作超时程序未执行完，添加 clientId (uuid) 判断，避免释放其他线程锁"></a>Redis.setnx 多节点 expire 原子操作超时程序未执行完，添加 clientId (uuid) 判断，避免释放其他线程锁 </h5><p><code> 上述代码在一般的程序中使用基本上已经没有问题了。但是我们做设计，必须要将场景考虑全。上面我们设置了过期时间为 5s，但是在实际的业务中我们无法确定超时时间设置多少才是正确的。那么问题就来了，假如有 A、B、C 三个线程并发执行创建订单，我们设置了过期时间为 5s，A 线程首先获取到锁，但是程序执行需要 10s，那么 A 线程还没有执行完业务时，锁已经被释放，此时线程 B 获取到锁，B 线程执行业务代码过程中 A 线程业务执行完成，A 线程会释放锁，注意此时 A 线程释放的锁其实是 B 线程的锁，这种情况下如果有多个线程，那么将有大部分的线程释放的锁是不属于自己的，这样的程序是有问题的。如何解决这样的问题呢？我们可以将 lock_value 设置为每个线程独有一个值，在释放锁时判断 lock_value 是否为当前线程所有，如果是则释放锁，如果不是则跳过。这样就可以解决 C 释放 B 、 B 释放 A 锁的问题了</code></p><blockquote><p>流程图如下:</p><div aligh="center">   <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/Redis 分布式锁 /Redis-lock.png" srcset="/img/loading.gif" width="100%"></div></blockquote><pre><code class="java">@Slf4j@RestController@RequestMapping(&quot;/orders&quot;)public class OrderController {    public static final String ORDER_STOCK_KEY = &quot;order:stock&quot;;    public static final String LOCK_KEY = &quot;lock:key&quot;;    @Autowired    private RedisTemplate&lt;String, String&gt; redisTemplate;    /**     * 创建订单     *     * @return     */    @GetMapping(&quot;/createOrder&quot;)    public String unsafeDeductOrder() {        // 当前线程 lock_value        String lockValue = UUID.randomUUID().toString();        // 这里使用 SpringBoot 提供的 setIfAbsent api 模拟 setnx 的效果        // 如果返回 true 表示获取锁成功，正常创建订单。否则失败，不做任何操作        // 这里设置 5s 过期，当服务器宕机时 5s 后 redis 会自动删除锁，保证获取锁和过期设置的原子性        Boolean flag = redisTemplate.opsForValue().setIfAbsent(LOCK_KEY, lockValue, 5, TimeUnit.SECONDS);        if (!flag) {return &quot;&quot;;}        log.info(&quot; 开始创建订单...........&quot;);        try {String stockNum = redisTemplate.opsForValue().get(ORDER_STOCK_KEY);            if (StringUtils.isEmpty(stockNum)) {log.warn(&quot; 订单创建失败，库存不足！&quot;);                return &quot; 订单创建失败，库存不足！&quot;;            }            int stock = Integer.parseInt(stockNum);            if (stock &lt;= 0) {log.warn(&quot; 订单创建失败，库存不足！&quot;);                return &quot; 订单创建失败，库存不足！&quot;;            }            log.info(&quot; 扣减前库存数: {}&quot;, stock);            redisTemplate.opsForValue().set(ORDER_STOCK_KEY, String.valueOf(stock - 1));            log.info(&quot; 扣减后库存数: {}&quot;, redisTemplate.opsForValue().get(ORDER_STOCK_KEY));        } catch (Exception e) {// do something} finally {            // 注意，在处理完业务后，需要释放掉锁，不然会造成死锁            // 如果是当前线程的锁，才进行释放            String value = redisTemplate.opsForValue().get(LOCK_KEY);            if (lockValue.equals(value)) {redisTemplate.delete(LOCK_KEY);            }        }        log.info(&quot; 结束创建订单...........&quot;);        return &quot; 当前库存数：&quot; + redisTemplate.opsForValue().get(ORDER_STOCK_KEY);    }}</code></pre><hr><h5 id="Redisson-Java-Client- 解决续租问题"><a href="#Redisson-Java-Client- 解决续租问题" class="headerlink" title="Redisson Java Client 解决续租问题"></a>Redisson Java Client 解决续租问题 </h5><p><code> 上述代码解决掉了线程之间释放锁错误的问题，刚刚提到的无法确定锁过期时间的问题依然存在。对于这个问题的解决方案，目前用的比较多的是 &#39; 续期 &#39; 方式。简单来说就是，启动一个后台线程，定时检查业务代码执行状态，如果到达过期时间业务依然没有执行完，那么就进行 &#39; 续期 &#39; 操作，将过期时间延长，直至业务代码执行完成后，正常释放锁。&#39; 续期 &#39; 操作实现起来还是相对麻烦，而且需要考虑的场景较多，那么目前为止 Redis 增强框架 Redisson 提供了较为完整的续期功能，所以大多数企业都会使用该框架进行分布式锁的使用</code></p><blockquote><p>Redisson: Redisson 是一个 Redis Java 客户端，具有内存数据网格的特性。<br>它提供了更方便和最简单的方式与 Redis 的工作。<br>Redisson 对象提供了关注点分离，这允许您将重点放在数据建模和应用程序逻辑上。</p><div aligh="center">   <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/Redis 分布式锁 /redisson-logo.png" srcset="/img/loading.gif" width="100%"></div></blockquote><ul><li>添加依赖</li></ul><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.redisson&lt;/groupId&gt;    &lt;artifactId&gt;redisson-spring-boot-starter&lt;/artifactId&gt;    &lt;version&gt;3.11.0&lt;/version&gt;&lt;/dependency&gt;</code></pre><ul><li>添加配置类</li></ul><pre><code class="java">@Configurationpublic class RedissonConfig {@Value(&quot;${spring.redis.host}&quot;)    private String host;    @Value(&quot;${spring.redis.port}&quot;)    private Integer port;    @Value(&quot;${spring.redis.database}&quot;)    private Integer database;    @Value(&quot;${spring.redis.password}&quot;)    private String password;    @Bean(destroyMethod = &quot;shutdown&quot;)    public RedissonClient redissonClient() {        // 使用单机 Redis        Config config = new Config();        SingleServerConfig serverConfig = config.useSingleServer();        serverConfig.setAddress(String.format(&quot;redis://%s:%s&quot;, host, port));        serverConfig.setTimeout(5000);        serverConfig.setDatabase(database);        serverConfig.setPassword(StringUtils.isEmpty(password) ? null : password);        return Redisson.create(config);    }</code></pre><ul><li>使用</li></ul><pre><code class="java">@Slf4j@RestController@RequestMapping(&quot;/orders&quot;)public class OrderController {    public static final String ORDER_STOCK_KEY = &quot;order:stock&quot;;    public static final String LOCK_KEY = &quot;lock:key&quot;;    @Autowired    private RedisTemplate&lt;String, String&gt; redisTemplate;    @Autowired    private RedissonClient redissonClient;    /**     * 创建订单     *     * @return     */    @GetMapping(&quot;/createOrder&quot;)    public String unsafeDeductOrder() {        // 获取并开启锁        RLock lock = redissonClient.getLock(LOCK_KEY);        lock.lock();        log.info(&quot; 开始创建订单...........&quot;);        try {String stockNum = redisTemplate.opsForValue().get(ORDER_STOCK_KEY);            if (StringUtils.isEmpty(stockNum)) {log.warn(&quot; 订单创建失败，库存不足！&quot;);                return &quot; 订单创建失败，库存不足！&quot;;            }            int stock = Integer.parseInt(stockNum);            if (stock &lt;= 0) {log.warn(&quot; 订单创建失败，库存不足！&quot;);                return &quot; 订单创建失败，库存不足！&quot;;            }            log.info(&quot; 扣减前库存数: {}&quot;, stock);            redisTemplate.opsForValue().set(ORDER_STOCK_KEY, String.valueOf(stock - 1));            log.info(&quot; 扣减后库存数: {}&quot;, redisTemplate.opsForValue().get(ORDER_STOCK_KEY));        } catch (Exception e) {// do something} finally {            // 释放锁            lock.unlock();}        log.info(&quot; 结束创建订单...........&quot;);        return &quot; 当前库存数：&quot; + redisTemplate.opsForValue().get(ORDER_STOCK_KEY);    }}</code></pre><hr><h5 id="总结"><a href="# 总结" class="headerlink" title="总结"></a>总结 </h5><p> 以上就是我们在分布式环境下，使用锁的各种坑及解决方案。在我们日常工作中，已经有前辈封装了非常好的框架供我们解决各类问题，但在使用的同时，我们一定要知道为什么需要这类框架来解决这类问题，问题的本质是什么，这样才能做到触类旁通。</p>]]></content>
    
    
    <categories>
      
      <category>Redis</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>MySQL 表锁</title>
    <link href="/2020/03/21/MySQL-Lock/"/>
    <url>/2020/03/21/MySQL-Lock/</url>
    
    <content type="html"><![CDATA[<center> <font face="黑体" size="6">MySQL 表锁</font> </center><hr><a id="more"></a><h5 id="MySQL- 表锁"><a href="#MySQL- 表锁" class="headerlink" title="MySQL 表锁"></a>MySQL 表锁</h5><p>MySQL 中提供了锁定表 <code>lock tables</code> 和解锁表 <code>unlock tables</code> 的法语，用来对指定对表进行锁定和解锁限制。</p><hr><h5 id="涉及命令"><a href="# 涉及命令" class="headerlink" title="涉及命令"></a>涉及命令</h5><table><thead><tr><th>命令</th><th>含义</th><th>常用</th></tr></thead><tbody><tr><td>select connection_id()</td><td>显示会话 id</td><td>select connection_id() 显示当前会话 id</td></tr><tr><td>show open tables</td><td>显示所有表占用锁的信息（包含全部表）</td><td>show open tables 显示所有表占用锁的信息（包含全部表）</td></tr><tr><td>show open tables where in_user &gt;= 1</td><td>显示所有表占用锁的信息（只包含已加锁的表）</td><td>显示所有表占用锁的信息（只包含已加锁的表）</td></tr><tr><td>lock table tableName1, tableName2… read</td><td>对指定表添加读锁（共享锁）</td><td>lock table user read 对 user 表添加读锁</td></tr><tr><td></td><td></td><td>lock table user, score read 对 user 与 score 表添加读锁</td></tr><tr><td>lock table tableName1, tableName2</td><td>对指定表添加写锁</td><td>lock table user write 对 user 表添加写锁</td></tr><tr><td></td><td></td><td>lock table user, score write 对 user 与 score 表添加写锁</td></tr><tr><td>unlock tables</td><td>对指定表进行解锁</td><td>unlock tables user 释放 user 表的锁</td></tr></tbody></table><hr><h5 id="示例"><a href="# 示例" class="headerlink" title="示例"></a>示例</h5><ul><li><code>lock table read</code> 锁表会将当前会话指定表进行锁定。限制当前会话只能查询该表，如果查询其他表则报错。如果对该表进行写操作也会报错。</li></ul><pre><code class="mysql">-- 查看当前会话 idselect connection_id();+-----------------+| connection_id() |+-----------------+|              64 |+-----------------+-- 使用读锁锁定 student 表lock table student read;Query OK, 0 rows affected (0.00 sec)-- 查看被锁住对表信息，如下表示 student 表被一个会话锁定（in_use = 1）show open tables where in_use &gt;= 1;+----------+---------+--------+-------------+| Database | Table   | In_use | Name_locked |+----------+---------+--------+-------------+| backup   | student |      1 |           0 |+----------+---------+--------+-------------+-- 查询带锁对表没问题select * from student;+--------+----------+| std_id | std_name |+--------+----------+|   1001 | zhangsan ||   1002 | lisi     ||   1003 | wangwu   |+--------+----------+-- 查询未锁定对表则报错select * from teacher;ERROR 1100 (HY000): Table &#39;teacher&#39; was not locked with LOCK TABLES-- 对锁定的表进行插入操作insert into student (std_id, std_name) values (1004, &#39;liuliu&#39;);ERROR 1100 (HY000): Table &#39;studentstudent&#39; was not locked with LOCK TABLES-- 对未锁定对表进行插入操作insert into teacher (teacher_id, teacher_name) values (1004, &#39;liuliu&#39;);ERROR 1100 (HY000): Table &#39;teacher&#39; was not locked with LOCK TABLES-- 再次执行锁表，之前的锁表将自动解锁lock table teacher read;Query OK, 0 rows affected (0.00 sec)-- 查看被锁住对表信息，如下表示 student 表被一个会话锁定（in_use = 1）show open tables where in_use &gt;= 1;+----------+---------+--------+-------------+| Database | Table   | In_use | Name_locked |+----------+---------+--------+-------------+| backup   | teacher |      1 |           0 |+----------+---------+--------+-------------+-- 客户端断开链接后，所有表锁将自动解锁, 重新链接后不再持有锁exit -- 断开链接mysql -uroot -p -- 再次链接show open tables where in_use &gt;= 1;Empty set (0.00 sec)</code></pre><hr><h5 id="注意点"><a href="# 注意点" class="headerlink" title="注意点"></a>注意点 </h5><p> 锁表获取方式：</p><blockquote><p>LOCK TABLES acquires locks as follows:<br>Sort all tables to be locked in an internally defined order. From the user standpoint, this order is undefined.<br>If a table is to be locked with a read and a write lock, put the write lock request before the read lock request.<br>Lock one table at a time until the session gets all locks.<br>This policy ensures that table locking is deadlock free.<br>LOCK TABLES acquires locks as follows:<br>Sort all tables to be locked in an internally defined order. From the user standpoint, this order is undefined.<br>If a table is to be locked with a read and a write lock, put the write lock request before the read lock request.<br>Lock one table at a time until the session gets all locks.<br>This policy ensures that table locking is deadlock free.<br>锁表获取锁的方式如下:<br>按照内部定义的顺序对所有要锁定的表进行排序。<br>从用户的角度来看，这个顺序是未定义的。<br>如果要用读锁和写锁锁定表，请将写锁请求放在读锁请求之前。<br>一次锁定一个表，直到会话获得所有锁。<br>此策略确保表锁定没有死锁。</p></blockquote><p>释放锁对条件：</p><blockquote><ul><li>当会话持有的表锁被释放时，它们都同时被释放会话可以显式地释放锁，也可以在某些条件下隐式地释放锁</li><li>可以使用 unlock tables 命令显示对释放锁</li><li>如果一个会话在已经持有锁的情况下发出一个 LOCK TABLES 命令再次获取锁，那么在授予新锁之前，MySQL 会将已经存在的锁隐式地解除</li><li>如果一个会话开始了一个事务(例如：start transaction)，就会执行一个隐式的 UNLOCK TABLES，从而释放现有的锁。</li><li>如果客户端会话的连接终止，无论是否正常，服务器都会隐式释放会话持有的所有表锁 (事务性和非事务性)。<br> 如果客户端重新连接，锁将不再有效。</li><li></li></ul></blockquote><p>关联锁表：</p><blockquote><p>lock table 命令可能会锁定比我们指定表更多对表。这是因为，如果表中有 trigger，那么 MySQL 为了让功能正常运行，<br>那么会将 trigger 中涉及对表一同 lock</p></blockquote><p><strong>note:</strong> 以上测试都是基于 InnoDB 引擎</p>]]></content>
    
    
    <categories>
      
      <category>MySQL</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>MySQL- 优化</title>
    <link href="/2020/03/18/MySQL-%E4%BC%98%E5%8C%96/"/>
    <url>/2020/03/18/MySQL-%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<center> <font face="黑体" size="6">MySQL- 优化</font> </center><hr><a id="more"></a><h5 id="MySQL-Count- 优化"><a href="#MySQL-Count- 优化" class="headerlink" title="MySQL Count 优化"></a>MySQL Count 优化 </h5><p> 从 user 表中查询 id 大于 10 的所以用户。InnoDB 存储引擎会进行逐行扫描，如果表中数据较多则会有性能问题</p><pre><code class="mysql">select count(*) from user where id &gt; 10;+----------+| count(*) |+----------+| 6597266  |+----------+1 row in setTime: 1.292s</code></pre><p>如果现将所有行数 count 出来，再见去 id &lt;= 10 的记录，速度就会快一些</p><pre><code class="mysql">select (select count(*) - (select count(*) from user where id &lt;= 10) from user) as count;+---------+| count   |+---------+| 6597266 |+---------+</code></pre><h5 id="MySQL-Limit- 优化"><a href="#MySQL-Limit- 优化" class="headerlink" title="MySQL Limit 优化"></a>MySQL Limit 优化</h5><p>limit 常用来进行分页，但是在偏移量很大的时候则会有性能问题</p><p>如下偏移量 100w 时，会先扫描 100w 数据后，在返回后面的 10 条记录，查询数据的效率会有所影响</p><pre><code class="mysql">select * from user order by id limit 1000000, 10;+---------+--------------+---------+| id      | name         | score   |+---------+--------------+---------+| 1000001 | user-999998  | 999998  || 1000002 | user-999999  | 999999  || 1000003 | user-1000000 | 1000000 || 1000004 | user-1000001 | 1000001 || 1000005 | user-1000002 | 1000002 || 1000006 | user-1000003 | 1000003 || 1000007 | user-1000004 | 1000004 || 1000008 | user-1000005 | 1000005 || 1000009 | user-1000006 | 1000006 || 1000010 | user-1000007 | 1000007 |+---------+--------------+---------+10 rows in setTime: 0.207s</code></pre><p>那么如果我们的 id 是自增或递增的，那么我们可以保存上次的偏移量，利用 id 的索引优势跳过前 100w 数据的扫描</p><pre><code class="mysql">select * from user where id &gt; 1000000 order by id limit 10;+---------+--------------+---------+| id      | name         | score   |+---------+--------------+---------+| 1000001 | user-999998  | 999998  || 1000002 | user-999999  | 999999  || 1000003 | user-1000000 | 1000000 || 1000004 | user-1000001 | 1000001 || 1000005 | user-1000002 | 1000002 || 1000006 | user-1000003 | 1000003 || 1000007 | user-1000004 | 1000004 || 1000008 | user-1000005 | 1000005 || 1000009 | user-1000006 | 1000006 || 1000010 | user-1000007 | 1000007 |+---------+--------------+---------+10 rows in setTime: 0.014s</code></pre><h5 id="MySQL-Group-By- 优化"><a href="#MySQL-Group-By- 优化" class="headerlink" title="MySQL Group By 优化"></a>MySQL Group By 优化 </h5><p> 查询 user 表并使用 score 字段进行分组，默认 score 字段没有索引，通过执行计划显示查询语句使用了临时表和非主键字段排序，所以进行了全表扫描</p><pre><code class="mysql">explain select * from user group by score limit 500000, 10;+----+-------------+-------+------------+------+---------------+--------+---------+--------+---------+----------+---------------------------------+| id | select_type | table | partitions | type | possible_keys | key    | key_len | ref    | rows    | filtered | Extra                           |+----+-------------+-------+------------+------+---------------+--------+---------+--------+---------+----------+---------------------------------+| 1  | SIMPLE      | user  | &lt;null&gt;     | ALL  | &lt;null&gt;        | &lt;null&gt; | &lt;null&gt;  | &lt;null&gt; | 6591199 | 100.0    | Using temporary; Using filesort |+----+-------------+-------+------------+------+---------------+--------+---------+--------+---------+----------+---------------------------------+</code></pre><p>下面我们为 score 字段添加索引，我们可以看到仅仅扫描了 limit 锁需要的 5000010 条数据</p><pre><code class="mysql">alter table `user` add index idx_score (`score`);desc user;+-------+--------------+------+-----+---------+----------------+| Field | Type         | Null | Key | Default | Extra          |+-------+--------------+------+-----+---------+----------------+| id    | int(11)      | NO   | PRI | &lt;null&gt;  | auto_increment || name  | varchar(32)  | NO   |     | &lt;null&gt;  |                || score | varchar(255) | YES  | MUL | &lt;null&gt;  |                |+-------+--------------+------+-----+---------+----------------+explain select * from user group by score limit 500000, 10;+----+-------------+-------+------------+-------+---------------+-----------+---------+--------+---------+----------+--------+| id | select_type | table | partitions | type  | possible_keys | key       | key_len | ref    | rows    | filtered | Extra  |+----+-------------+-------+------------+-------+---------------+-----------+---------+--------+---------+----------+--------+| 1  | SIMPLE      | user  | &lt;null&gt;     | index | idx_score     | idx_score | 258     | &lt;null&gt; | 5000010 | 100.0    | &lt;null&gt; |+----+-------------+-------+------------+-------+---------------+-----------+---------+--------+---------+----------+--------+</code></pre><p>下面我们来使用覆盖索引，我们可以看到 extra 字段的只为 using index 代表我们使用到了覆盖索引。那么此时这条查询语句是不需要回表的，所以也会提升部分效率</p><pre><code class="mysql">explain select score from user group by score limit 5000000, 10;+----+-------------+-------+------------+-------+---------------+-----------+---------+--------+---------+----------+-------------+| id | select_type | table | partitions | type  | possible_keys | key       | key_len | ref    | rows    | filtered | Extra       |+----+-------------+-------+------------+-------+---------------+-----------+---------+--------+---------+----------+-------------+| 1  | SIMPLE      | user  | &lt;null&gt;     | index | idx_score     | idx_score | 258     | &lt;null&gt; | 5000010 | 100.0    | Using index |+----+-------------+-------+------------+-------+---------------+-----------+---------+--------+---------+----------+-------------+</code></pre><p>下面我们在使用主键 id 作为分组条件，查看执行计划后，我们看到使用了 PRIMARY 主键索引</p><pre><code class="mysql">explain select * from user group by id limit 5000000, 10;+----+-------------+-------+------------+-------+-------------------+---------+---------+--------+---------+----------+--------+| id | select_type | table | partitions | type  | possible_keys     | key     | key_len | ref    | rows    | filtered | Extra  |+----+-------------+-------+------------+-------+-------------------+---------+---------+--------+---------+----------+--------+| 1  | SIMPLE      | user  | &lt;null&gt;     | index | PRIMARY,idx_score | PRIMARY | 4       | &lt;null&gt; | 5000010 | 100.0    | &lt;null&gt; |+----+-------------+-------+------------+-------+-------------------+---------+---------+--------+---------+----------+--------+</code></pre><p>下面我们在使用主键 id 作为分组条件前提下，加上使用覆盖索引，查看执行计划后，我们看到 extra 字段值为 using index 代表覆盖索引，没有回表操作</p><pre><code class="mysql">explain select id from user group by id limit 5000000, 10;+----+-------------+-------+------------+-------+-------------------+---------+---------+--------+---------+----------+-------------+| id | select_type | table | partitions | type  | possible_keys     | key     | key_len | ref    | rows    | filtered | Extra       |+----+-------------+-------+------------+-------+-------------------+---------+---------+--------+---------+----------+-------------+| 1  | SIMPLE      | user  | &lt;null&gt;     | index | PRIMARY,idx_score | PRIMARY | 4       | &lt;null&gt; | 5085756 | 100.0    | Using index |+----+-------------+-------+------------+-------+-------------------+---------+---------+--------+---------+----------+-------------+</code></pre><p>最后来对比以上全部 Group By 语句的执行效率</p><pre><code class="bash"># 无索引mysql&gt; select * from user group by score limit 5000000, 10... 结果大于 1 分钟# score 字段索引mysql&gt; select * from user group by score limit 5000000, 10;+---------+--------------+---------+| id      | name         | score   |+---------+--------------+---------+| 5500002 | user-5499999 | 5499999 || 58      | user-55      | 55      || 553     | user-550     | 550     || 5503    | user-5500    | 5500    || 55003   | user-55000   | 55000   || 550003  | user-550000  | 550000  || 5500003 | user-5500000 | 5500000 || 5500004 | user-5500001 | 5500001 || 5500005 | user-5500002 | 5500002 || 5500006 | user-5500003 | 5500003 |+---------+--------------+---------+10 rows in setTime: 46.519s# score 字段索引并使用覆盖索引mysql&gt; select score from user group by score limit 5000000, 10;+---------+| score   |+---------+| 5499999 || 55      || 550     || 5500    || 55000   || 550000  || 5500000 || 5500001 || 5500002 || 5500003 |+---------+10 rows in setTime: 1.013s# 主键 id 分组mysql&gt; select * from user group by id limit 5000000, 10;+---------+--------------+---------+| id      | name         | score   |+---------+--------------+---------+| 5000001 | user-4999998 | 4999998 || 5000002 | user-4999999 | 4999999 || 5000003 | user-5000000 | 5000000 || 5000004 | user-5000001 | 5000001 || 5000005 | user-5000002 | 5000002 || 5000006 | user-5000003 | 5000003 || 5000007 | user-5000004 | 5000004 || 5000008 | user-5000005 | 5000005 || 5000009 | user-5000006 | 5000006 || 5000010 | user-5000007 | 5000007 |+---------+--------------+---------+10 rows in setTime: 1.238s# 主键 id 分组并使用覆盖索引mysql&gt; select id from user group by id limit 5000000, 10;+---------+| id      |+---------+| 5000001 || 5000002 || 5000003 || 5000004 || 5000005 || 5000006 || 5000007 || 5000008 || 5000009 || 5000010 |+---------+10 rows in setTime: 0.940s</code></pre><p><strong>note:</strong> 需要 sql_mode 去掉 ONLY_FULL_GROUP_BY</p><hr><p><strong>引用：</strong><br><a href="https://database.51cto.com/art/201910/604945.htm" target="_blank" rel="noopener">MySQL 性能优化之骨灰级高阶神器</a></p>]]></content>
    
    
    <categories>
      
      <category>MySQL</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>MySQL- 设计范式</title>
    <link href="/2020/03/18/MySQL-%E8%AE%BE%E8%AE%A1%E8%8C%83%E5%BC%8F/"/>
    <url>/2020/03/18/MySQL-%E8%AE%BE%E8%AE%A1%E8%8C%83%E5%BC%8F/</url>
    
    <content type="html"><![CDATA[<center> <font face="黑体" size="6">MySQL- 设计范式 </font> </center><hr><a id="more"></a><p><strong> 在使用 MySQL 数据库时，我们通常有一些基本的设计规范需要遵守，这样会让我们在实际使用 MySQL 数据库时，避免前人才过的各种坑 </strong></p><hr><h5 id="MySQL- 设计范式（一）：数据表中所有字段都是不可分割的原子值"><a href="#MySQL- 设计范式（一）：数据表中所有字段都是不可分割的原子值" class="headerlink" title="MySQL 设计范式（一）：数据表中所有字段都是不可分割的原子值"></a>MySQL 设计范式（一）：数据表中所有字段都是不可分割的原子值 </h5><pre><code class="bash"># 如下 address 字段实际可以分割为国家、省份、城市、地区等字段。同时第三条和第一条记录重复（不唯一），所以不符合第一范式mysql&gt; CREATE TABLE `sys_user`  (-&gt;   `id` int(0) NOT NULL AUTO_INCREMENT,    -&gt;   `name` varchar(32) NOT NULL,    -&gt;   `address` varchar(32) NOT NULL,    -&gt;   PRIMARY KEY (`id`)    -&gt; );mysql&gt; insert into sys_user (name, address) values (&#39;zhangsan&#39;, &#39; 中国四川省武侯区桂溪街道 xx 号 &#39;);mysql&gt; insert into sys_user (name, address) values (&#39;lisi&#39;, &#39; 中国四川省武侯区桂溪街道 xx 号 &#39;);mysql&gt; select * from sys_user;+----+----------+------------------------------+| id | name     | address                      |+----+----------+------------------------------+|  1 | zhangsan | 中国四川省武侯区桂溪街道 xx 号 ||  2 | lisi     | 中国四川省武侯区桂溪街道 xx 号 ||  2 | wangwu   | 中国四川省武侯区桂溪街道 xx 号 |+----+----------+------------------------------+# 如下表字段基本不可分割。同时每行数据都是唯一的（必须有主键），所以符合第一范式mysql&gt; CREATE TABLE `sys_user`  (-&gt;   `id` int(0) PRIMARY KEY AUTO_INCREMENT,    -&gt;   `name` varchar(32) NOT NULL,    -&gt;   `country` varchar(32) NOT NULL,    -&gt;   `privence` varchar(32) NOT NULL,    -&gt;   `city` varchar(32) NOT NULL,    -&gt;   `addr` varchar(32) NOT NULL,    -&gt;   PRIMARY KEY (`id`)    -&gt; );mysql&gt; insert into sys_user (name, country, privence, city, addr) values (&#39;zhangsan&#39;, &#39; 中国 &#39;, &#39; 四川 &#39;, &#39; 成都 &#39;, &#39; 武侯区桂溪街道 xx 号 &#39;);mysql&gt; insert into sys_user (name, country, privence, city, addr) values (&#39;lisi&#39;, &#39; 中国 &#39;, &#39; 四川 &#39;, &#39; 成都 &#39;, &#39; 武侯区桂溪街道 xx 号 &#39;);mysql&gt; select * from sys_user;+----+----------+---------+----------+------+---------------------+| id | name     | country | privence | city | addr                |+----+----------+---------+----------+------+---------------------+|  1 | zhangsan | 中国    | 四川     | 成都 | 武侯区桂溪街道 xx 号  ||  2 | lisi     | 中国    | 四川     | 成都 | 武侯区桂溪街道 xx 号  ||  3 | wangwu   | 中国    | 四川     | 成都 | 武侯区桂溪街道 xx 号  |+----+----------+---------+----------+------+---------------------+</code></pre><p><strong>note:</strong> 设计范式只是在大多时候奏效，实际还需要根据业务区划分，例如上面的表，如果没有需求按照 country、city、privence 等字段分别统计 <br>，则无需进行拆分。</p><hr><h5 id="MySQL- 设计范式（二）：建立在第一范式基础上。同时所以非主键字段必须完全依赖主键，不能产生部分依赖"><a href="#MySQL- 设计范式（二）：建立在第一范式基础上。同时所以非主键字段必须完全依赖主键，不能产生部分依赖" class="headerlink" title="MySQL 设计范式（二）：建立在第一范式基础上。同时所以非主键字段必须完全依赖主键，不能产生部分依赖"></a>MySQL 设计范式（二）：建立在第一范式基础上。同时所以非主键字段必须完全依赖主键，不能产生部分依赖 </h5><pre><code class="bash"># 如下表 std_name 只与 std_id 有关，teacher_name 只与 teacher_id 有关。出现除主键以外其他列，只依赖于主键的部分字段mysql&gt; CREATE TABLE `student`  (    -&gt;   `std_id` int,    -&gt;   `std_name` varchar(32),    -&gt;   `teacher_id` int,    -&gt;   `teacher_name` varchar(32),    -&gt;   PRIMARY KEY (`std_id`, `std_name`)    -&gt; );mysql&gt; insert into student (std_id, std_name, teacher_id, teacher_name) values (1001, &#39;zhangsan&#39;, 2001, &#39; 张老师 &#39;);mysql&gt; insert into student (std_id, std_name, teacher_id, teacher_name) values (1002, &#39;lisi&#39;, 2002, &#39; 李老师 &#39;);mysql&gt; insert into student (std_id, std_name, teacher_id, teacher_name) values (1003, &#39;wangwu&#39;, 2001, &#39; 张老师 &#39;);mysql&gt; select * from student;+--------+----------+------------+--------------+| std_id | std_name | teacher_id | teacher_name |+--------+----------+------------+--------------+|   1001 | zhangsan |       2001 | 张老师       ||   1002 | lisi     |       2002 | 李老师       ||   1003 | lisi     |       2001 | 张老师       |+--------+----------+------------+--------------+# 如下拆表后，满足第二范式mysql&gt; CREATE TABLE `student`  (    -&gt;   `std_id` int primary key,    -&gt;   `std_name` varchar(32)    -&gt; );msyql&gt; insert into student (std_id, std_name) values (1001, &#39;zhangsan&#39;);msyql&gt; insert into student (std_id, std_name) values (1002, &#39;lisi&#39;);msyql&gt; insert into student (std_id, std_name) values (1003, &#39;wangwu&#39;);mysql&gt; CREATE TABLE `teacher`  (    -&gt;   `teacher_id` int primary key,    -&gt;   `teacher_name` varchar(32)    -&gt; );mysql&gt; insert into teacher (teacher_id, teacher_name) values (2001, &#39; 张老师 &#39;);mysql&gt; insert into teacher (teacher_id, teacher_name) values (2002, &#39; 李老师 &#39;);mysql&gt; CREATE TABLE `student_teacher`  (    -&gt;   `id` int primary key,    -&gt;   `std_id` int,    -&gt;   `teacher_id` int    -&gt; );mysql&gt; insert into student_teacher (id, std_id, teacher_id) values (1, 1001, 2001);mysql&gt; insert into student_teacher (id, std_id, teacher_id) values (2, 1002, 2002);mysql&gt; insert into student_teacher (id, std_id, teacher_id) values (3, 1003, 2001);mysql&gt; select * from student;+--------+----------+| std_id | std_name |+--------+----------+|   1001 | zhangsan ||   1002 | lisi     ||   1003 | wangwu   |+--------+----------+mysql&gt; select * from teacher;+------------+--------------+| teacher_id | teacher_name |+------------+--------------+|       2001 | zhanglaoshi  ||       2002 | lilaoshi     |+------------+--------------+mysql&gt; select * from student_teacher;+----+--------+------------+| id | std_id | teacher_id |+----+--------+------------+|  1 |   1001 |       2001 ||  2 |   1002 |       2002 ||  3 |   1003 |       2001 |+----+--------+------------+</code></pre><h5 id="MySQL- 设计范式（三）：建立在第二范式基础上。同时非主键字段的其他列之间不能有传递以来关系"><a href="#MySQL- 设计范式（三）：建立在第二范式基础上。同时非主键字段的其他列之间不能有传递以来关系" class="headerlink" title="MySQL 设计范式（三）：建立在第二范式基础上。同时非主键字段的其他列之间不能有传递以来关系"></a>MySQL 设计范式（三）：建立在第二范式基础上。同时非主键字段的其他列之间不能有传递以来关系 </h5><pre><code class="bash"># 如下表 std_email 字段依赖于 id 字段外，还依赖 std_id 字段，产生了依赖传递关系，所以不符合第三范式mysql&gt; CREATE TABLE `student`  (    -&gt;   `std_id` int primary key,    -&gt;   `std_name` varchar(32)    -&gt; );mysql&gt; CREATE TABLE `student_teacher`  (    -&gt;   `id` int primary key,    -&gt;   `std_id` int,    -&gt;   `teacher_id` int,    -&gt;   `std_email` varchar(32)    -&gt; );# 应该将 std_email 字段加入 student 表，依赖于 std_id 字段即可mysql&gt; CREATE TABLE `student`  (    -&gt;   `std_id` int primary key,    -&gt;   `std_name` varchar(32),    -&gt;   `std_email` varchar(32)    -&gt; );mysql&gt; CREATE TABLE `student_teacher`  (    -&gt;   `id` int primary key,    -&gt;   `std_id` int,    -&gt;   `teacher_id` int    -&gt; );</code></pre><div aligh="center">    <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/MySQL- 设计范式 /mysql-standard-logo.jpeg" srcset="/img/loading.gif" width="100%"></div>]]></content>
    
    
    <categories>
      
      <category>MySQL</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>MySQL-Slow-Query</title>
    <link href="/2020/03/17/MySQL-Slow-Query/"/>
    <url>/2020/03/17/MySQL-Slow-Query/</url>
    
    <content type="html"><![CDATA[<center> <font face="黑体" size="6">MySQL-Slow-Query</font> </center><hr><a id="more"></a><p><strong>日常使用 MySQL 数据库时，经常会有一些 SQL 执行比较慢，这有可能是数据量到问题，也有可能是 SQL 本身写的有问题。那么如何让 MySQL 帮我们 </strong><br><strong> 记录这些比较慢到 SQL 语句，便于我们日后优化呢？我们可以使用 MySQL 为我们提供的慢日志功能来满足以上需求</strong></p><h5 id="查看慢日志信息"><a href="# 查看慢日志信息" class="headerlink" title="查看慢日志信息"></a>查看慢日志信息</h5><pre><code class="bash">mysql&gt; show variables like &#39;%slow_query_log%&#39;;+---------------------+--------------------------------------+| Variable_name       | Value                                |+---------------------+--------------------------------------+| slow_query_log      | OFF                                  || slow_query_log_file | /var/lib/mysql/e36ca99c5d19-slow.log |+---------------------+--------------------------------------+</code></pre><h5 id="如何开启慢日志"><a href="# 如何开启慢日志" class="headerlink" title="如何开启慢日志"></a>如何开启慢日志</h5><pre><code class="bash">mysql&gt; set global slow_query_log = 1;Query OK, 0 rows affected (0.05 sec)# 再次查看慢日志mysql&gt; show variables like &#39;%slow_query_log%&#39;;+---------------------+--------------------------------------+| Variable_name       | Value                                |+---------------------+--------------------------------------+| slow_query_log      | ON                                   || slow_query_log_file | /var/lib/mysql/e36ca99c5d19-slow.log |+---------------------+--------------------------------------+</code></pre><p><strong>note:</strong> <code>slow_query_log</code> 值为 <code>ON</code> 表示开启。为 <code>OFF</code> 表示禁用。</p><hr><h5 id="查看慢日志时间"><a href="# 查看慢日志时间" class="headerlink" title="查看慢日志时间"></a>查看慢日志时间</h5><pre><code class="bash">mysql&gt; show variables like &#39;%long_query_time%&#39;;+-----------------+-----------+| Variable_name   | Value     |+-----------------+-----------+| long_query_time | 10.000000 |+-----------------+-----------+</code></pre><h5 id="设置慢日志时间"><a href="# 设置慢日志时间" class="headerlink" title="设置慢日志时间"></a>设置慢日志时间</h5><pre><code class="bash">mysql&gt; set global long_query_time = 3;Query OK, 0 rows affected (0.00 sec)# 再次查看慢日志时间mysql&gt; show variables like &#39;%long_query_time%&#39;;+-----------------+-----------+| Variable_name   | Value     |+-----------------+-----------+| long_query_time | 10.000000 |+-----------------+-----------+</code></pre><p><strong>note:</strong> <code>long_query_time</code> 单位时间为秒，默认为 10 秒。当 SQL 执行时间超过 <code>long_query_time</code> 时，则将执行语句记录到慢日志中。</p><hr><h5 id="查看超过阈值到 -SQL- 数量"><a href="# 查看超过阈值到 -SQL- 数量" class="headerlink" title="查看超过阈值到 SQL 数量"></a>查看超过阈值到 SQL 数量</h5><pre><code class="bash">mysql&gt; show global status like &#39;%slow_queries%&#39;;+---------------+-------+| Variable_name | Value |+---------------+-------+| Slow_queries  | 0     |+---------------+-------+# 执行一条慢 SQLselect sleep(3), id from user limit 1;+----------+----+| sleep(3) | id |+----------+----+|        0 | 10 |+----------+----+1 row in set (3.00 sec)# 再次查看mysql&gt; show global status like &#39;%slow_queries%&#39;;+---------------+-------+| Variable_name | Value |+---------------+-------+| Slow_queries  | 1     |+---------------+-------+# 通过查看慢日志可以看到具体到 SQL$ cat e36ca99c5d19-slow.log  mysqld, Version: 5.7.29-log (MySQL Community Server (GPL)). started with:  Tcp port: 3306  Unix socket: /var/run/mysqld/mysqld.sock  Time                 Id Command    Argument  # Time: 2020-03-17T15:07:38.895767Z  # User@Host: root[root] @ localhost []  Id:    58  # Query_time: 24.006077  Lock_time: 0.000270 Rows_sent: 8  Rows_examined: 8  use backup;  SET timestamp=1584457658;  select sleep(3), id from user;</code></pre><p><strong>note:</strong> 通过慢日志我们就可以定期检查哪些 SQL 执行较慢，是否可以优化了。</p><div aligh="center">    <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/MySQL-Slow-Query/mysql-slow-query.jpeg" srcset="/img/loading.gif" width="100%"></div>]]></content>
    
    
    <categories>
      
      <category>MySQL</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>ZooKeeper 入门</title>
    <link href="/2020/03/17/ZooKeeper/"/>
    <url>/2020/03/17/ZooKeeper/</url>
    
    <content type="html"><![CDATA[<center> <font face="黑体" size="6">ZooKeeper 入门</font> </center><a id="more"></a><h5 id="介绍"><a href="# 介绍" class="headerlink" title="介绍"></a>介绍</h5><p>ZooKeeper 是一个高度可靠到分布式协调框架，用于维护配置信息、统一命名、分布式同步和提供组服务功能。</p><hr><h5 id="Zookeeper- 组成"><a href="#Zookeeper- 组成" class="headerlink" title="Zookeeper 组成"></a>Zookeeper 组成</h5><p>ZooKeeper 简单来讲由两部分组成：</p><ol><li><p>文件系统（节点 + 数据）</p><div aligh="center">    <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/ZooKeeper/zookeeper-node.png" srcset="/img/loading.gif" width="100%"></div></li><li><p>通知机制（Watcher）</p></li></ol><hr><h5 id="ZooKeeper- 节点类型"><a href="#ZooKeeper- 节点类型" class="headerlink" title="ZooKeeper 节点类型"></a>ZooKeeper 节点类型</h5><p><code>PERSISTENT</code> 持久化节点<br><code>PERSISTENT_SEQUENTIAL</code> 顺序持久化节点<br><code>EPHEMERAL</code> 临时节点<br><code>EPHEMERAL_SEQUENTIAL</code> 顺序临时节点</p><hr><h5 id="ZooKeeper- 常用命令"><a href="#ZooKeeper- 常用命令" class="headerlink" title="ZooKeeper 常用命令"></a>ZooKeeper 常用命令</h5><table><thead><tr><th>命令</th><th>含义</th><th>示例</th></tr></thead><tbody><tr><td>get /node</td><td>获取节点数据</td><td>get /namespace 获取 /namespace 节点数据</td></tr><tr><td>get /node/subNode</td><td>获取子节点数据</td><td>get /namespace/dev 获取 /namespace/dev 节点数据</td></tr><tr><td>create /node data</td><td>创建节点及数据</td><td>create /namespace raindrop 创建 /namespace 节点数据为 raindrop</td></tr><tr><td>create /node/subNode data</td><td>创建子节点及数据</td><td>create /namespace/dev dbHost 创建 /namespace/dev 节点数据为 dbHost</td></tr><tr><td>create -e /node data</td><td>创建临时节点及数据</td><td>create -e /lock uuid 创建临时节点 /lock 数据为 uuid</td></tr><tr><td>create -s /node data</td><td>创建顺序节点及数据</td><td>create -s /lock uuid 创建顺序节点 /lock 数据为 uuid 数据自动累加</td></tr><tr><td>set /node data</td><td>修改节点数据</td><td>set /namespace rain 修改 /namespace 节点数据为 rain</td></tr><tr><td>set /node/subNode data</td><td>修改子节点数据</td><td>set /namespace/dev dbName 修改 /namespace/dev 节点数据为 dbName</td></tr><tr><td>delete /node</td><td>删除节点</td><td>delete /namespace 删除 /namespace 节点，若存在子节点则不能删除</td></tr><tr><td>deleteall /node</td><td>删除节点，包含子节点</td><td>deleteall /namespace 删除 /namespace 节点及子节点数据</td></tr><tr><td>watcher</td><td>通知机制，一次性</td><td>stat /lock watch 订阅 /lock 节点 watch 时间，创建 /lock 节点时触发</td></tr><tr><td>stat</td><td>查看节点信息</td><td>stat /namespace 查看 /namespace 节点信息</td></tr></tbody></table><hr><h5 id="ZooKeeper- 命令示例"><a href="#ZooKeeper- 命令示例" class="headerlink" title="ZooKeeper 命令示例"></a>ZooKeeper 命令示例</h5><ul><li><code>create</code></li></ul><pre><code class="bash"># 创建跟节点[zk: localhost:2181(CONNECTED) 25] create /namespace environmentCreated /namespace# 创建子节点[zk: localhost:2181(CONNECTED) 26] create /namespace/dev-host 127.0.0.1Created /namespace/dev-host# 创建临时节点，客户端链接关闭后失效（会被删除）[zk: localhost:2181(CONNECTED) 27] create -e /tmp raindropCreated /tmp# 创建顺序节点，注意第二次创建时序列进行了自增[zk: localhost:2181(CONNECTED) 30] create -s /lock uuidCreated /lock0000000010[zk: localhost:2181(CONNECTED) 31] create -s /lock uuidCreated /lock0000000011</code></pre><ul><li><code>get</code></li></ul><pre><code class="bash"># 获取节点数据[zk: localhost:2181(CONNECTED) 32] get /namespaceenvironment[zk: localhost:2181(CONNECTED) 33] get /namespace/dev-host127.0.0.1[zk: localhost:2181(CONNECTED) 34] get /tmpraindrop# 获取不存在的节点或提示错误[zk: localhost:2181(CONNECTED) 41] get /tttorg.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /ttt</code></pre><ul><li><code>set</code></li></ul><pre><code class="bash"># 更新节点数据[zk: localhost:2181(CONNECTED) 36] set /namespace raindrop[zk: localhost:2181(CONNECTED) 37] set /namespace/dev-host 0.0.0.0[zk: localhost:2181(CONNECTED) 38] get /namespaceraindrop[zk: localhost:2181(CONNECTED) 39] get /namespace/dev-host0.0.0.0# 更新不存在节点会提示错误[zk: localhost:2181(CONNECTED) 40] set /ttt 111Node does not exist: /ttt</code></pre><ul><li><code>delete</code></li></ul><pre><code class="bash"># 删除节点后，查询已经不存在[zk: localhost:2181(CONNECTED) 42] delete /tmp[zk: localhost:2181(CONNECTED) 43] get /tmporg.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /tmp# 删除带有子节点的节点会提示错误[zk: localhost:2181(CONNECTED) 44] delete /namespaceNode not empty: /namespace</code></pre><ul><li><code>deleteall</code></li></ul><pre><code class="bash"># 删除节点，包含子节点，删除后查询已经不存在[zk: localhost:2181(CONNECTED) 45] deleteall /namespace[zk: localhost:2181(CONNECTED) 46] get /namespaceorg.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /namespace</code></pre><ul><li><code>watcher</code></li></ul><pre><code class="bash"># stat 订阅创建节点[zk: localhost:2181(CONNECTED) 50] stat -w /namespaceNode does not exist: /namespace[zk: localhost:2181(CONNECTED) 51] create /namespace raindropCreated /namespaceWATCHER::WatchedEvent state:SyncConnected type:NodeCreated path:/namespace# get 订阅节点数据改变[zk: localhost:2181(CONNECTED) 52] get -w /namespaceraindrop[zk: localhost:2181(CONNECTED) 53] set /namespace raindrop666WATCHER::WatchedEvent state:SyncConnected type:NodeDataChanged path:/namespace</code></pre><ul><li><code>stat</code></li></ul><pre><code class="bash"># 查看节点信息，包括版本、长度、子节点等信息[zk: localhost:2181(CONNECTED) 56] stat /namespacecZxid = 0x2actime = Sat Mar 21 00:10:31 CST 2020mZxid = 0x2bmtime = Sat Mar 21 00:10:50 CST 2020pZxid = 0x2acversion = 0dataVersion = 1aclVersion = 0ephemeralOwner = 0x0dataLength = 11numChildren = 0</code></pre><hr><h5 id="ZAB- 协议"><a href="#ZAB- 协议" class="headerlink" title="ZAB 协议"></a>ZAB 协议</h5><p><code>myid</code><br><code>zxid</code> 全局 顺序 唯一 事务 id</p><hr><h5 id="Leader- 选举"><a href="#Leader- 选举" class="headerlink" title="Leader 选举"></a>Leader 选举 </h5><p><code> 半数机制</code></p><p><code>myid</code></p><p><code>zxid</code></p><hr><h5 id="Zookeeper- 使用场景"><a href="#Zookeeper- 使用场景" class="headerlink" title="Zookeeper 使用场景"></a>Zookeeper 使用场景</h5>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Nginx-Mirror</title>
    <link href="/2020/03/16/Nginx-Mirror/"/>
    <url>/2020/03/16/Nginx-Mirror/</url>
    
    <content type="html"><![CDATA[<center> <font face="黑体" size="6">Nginx-Mirror</font> </center><hr><a id="more"></a><h5 id="需求"><a href="# 需求" class="headerlink" title="需求"></a>需求 </h5><p> 今日有一个新的业务需求需要上线，领导要求上线前要充分测试功能及并发能力，最好可以模拟线上的真是流量。<br>基于此，我找到了 Nginx 提供的 nginx_http_mirror_module 模块。</p><hr><h5 id="Nginx-http-mirror-module"><a href="#Nginx-http-mirror-module" class="headerlink" title="Nginx_http_mirror_module"></a>Nginx_http_mirror_module</h5><p><code>Nginx 1.13.4</code> 提供了 Mirror 模块，用于创建源站点的镜像站点，将源站点请求复制到 Mirror 站点来实现原始请求的镜像，Mirror<br>站点的响应将被忽略。</p><div aligh="center">    <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/Nginx-Mirror/nginx-mirror.png" srcset="/img/loading.gif" width="100%"></div><hr><h5 id="复制真实流量，不支持 -Post- 请求体复制"><a href="# 复制真实流量，不支持 -Post- 请求体复制" class="headerlink" title="复制真实流量，不支持 Post 请求体复制"></a>复制真实流量，不支持 Post 请求体复制 </h5><p> 如下配置将实现真实用户请求 80 端入正常访问现有生产 web1 端点，Nginx 同时将流量复制到 /mirror 路径的 web2 端点，不支持 Post 请求</p><pre><code class="bash"># 编辑 nginx.confserver {    listen 80;    server_name localhost;    # 流量复制    location / {        mirror /mirror; # 镜像站点路径        mirror_request_body off;        proxy_pass http://127.0.0.1:8080/web1;    }    location /mirror {if ($request_method != GET) {return 403;}        internal; # 内部访问        proxy_pass http://127.0.0.1:8080/web2;        proxy_pass_request_body off;        proxy_set_header Content-Length &quot;&quot;;        proxy_set_header X-Original-URI $request_uri;    }}</code></pre><hr><h5 id="复制真实流量，支持 -Post- 请求体复制"><a href="# 复制真实流量，支持 -Post- 请求体复制" class="headerlink" title="复制真实流量，支持 Post 请求体复制"></a>复制真实流量，支持 Post 请求体复制 </h5><p> 如下配置将实现真实用户请求 80 端入正常访问现有生产 web1 端点，Nginx 同时将流量复制到 /mirror 路径的 web2 端点</p><pre><code class="bash"># 编辑 nginx.confserver {    listen 80;    server_name localhost;    # 流量复制    location / {        mirror /mirror; # 镜像站点路径        mirror_request_body on; # 此参数为 on 时支持 post 复制，为 off 时不支持复制        proxy_pass http://127.0.0.1:8080/web1;    }    location /mirror {        internal; # 内部访问        proxy_pass http://127.0.0.1:8080/web2;        proxy_pass_request_body on; # 此参数配合 mirror_request_body 参数使用        proxy_set_header X-Original-URI $request_uri;    }}</code></pre><hr><h5 id="镜像站点流量翻倍"><a href="# 镜像站点流量翻倍" class="headerlink" title="镜像站点流量翻倍"></a>镜像站点流量翻倍 </h5><p> 如希望用双倍的流量压测镜像站点，只需要重复配置 mirror 路径即可完成</p><pre><code class="bash"># 编辑 nginx.confserver {    listen 80;    server_name localhost;    location / {        mirror /mirror; # 配置镜像站点        mirror /mirror; # 配置镜像站点        mirror_request_body on;        proxy_pass http://127.0.0.1:8080/web1;    }    location /mirror {        internal; # 内部访问        proxy_pass http://127.0.0.1:8080/web2;        proxy_pass_request_body on;        proxy_set_header X-Original-URI $request_uri;    }}</code></pre><hr><h5 id="镜像站点日志"><a href="# 镜像站点日志" class="headerlink" title="镜像站点日志"></a>镜像站点日志</h5><p>mirror 站点默认不支持写日志，所以需要配合 server 来达到写日志的目的</p><pre><code class="bash">server {    listen 80;    server_name localhost;    location / {        mirror /mirror;        mirror_request_body on;        proxy_pass http://127.0.0.1:8080/web1;    }    location /mirror {        internal; # 内部访问        proxy_pass http://127.0.0.1:8000$request_uri; # 转发到内部 server        proxy_pass_request_body on;        proxy_set_header X-Original-URI $request_uri;    }}server {    listen 8000;    server_name localhost;    location / {        # 在这里写日志        access_log /usr/local/Cellar/openresty/1.15.8.2/nginx/access.log main;        proxy_pass http://127.0.0.1:8080/web2;    }}</code></pre><hr><p><strong>note:</strong> mirror 支持到域为 http、server、location，可以在同一级别域中指定多个 mirror</p>]]></content>
    
    
    <categories>
      
      <category>Nginx</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Nginx Ftp</title>
    <link href="/2020/03/13/Nginx%20Ftp/"/>
    <url>/2020/03/13/Nginx%20Ftp/</url>
    
    <content type="html"><![CDATA[<center> <font face="黑体" size="6">Nginx Ftp 搭建 </font> </center><a id="more"></a><h3 id="Centos-Nginx-Vsftpd- 搭建文件服务器"><a href="#Centos-Nginx-Vsftpd- 搭建文件服务器" class="headerlink" title="Centos Nginx Vsftpd 搭建文件服务器"></a>Centos Nginx Vsftpd 搭建文件服务器 </h3><ul><li> 本篇文章记录一下在工作中，使用 Nginx Vsftpd 搭建文件服务器的过程，以及文件索引美化的内容。<br> 环境如下：<br>Centos 7.2<br>Nginx 1.14<br>Ngx-Fancyindex 0.4.3</li></ul><h3 id="Setp-1"><a href="#Setp-1" class="headerlink" title="Setp 1"></a>Setp 1</h3><ul><li><p> 首先我们先来安装 Vsftpd 服务.</p><pre><code class="bash"># 使用 yum 安装$ yum -y install vsftpd# 创建 ftp 用户及密码$ useradd ftpadmin$ passwd ftpadmin# 防火墙开启 21 端口（ftp 默认 21 端口）$ vim /etc/sysconfig/iptables  # 新增规则 如图一  -A INPUT -m state --state NEW -m tcp -p tcp --dport 21 -j ACCEPT# 重启防火墙$ service iptables restart# 修改 Selinux，允许 ftp 外网访问# 查看状态 如图二，其他红色标识的两个选项需要改为 on$ getsebool -a | grep ftp# 修改 ftp 选项为 on$ setsebool -P allow_ftpd_full_access on$ setsebool -P ftp_home_dir on# 关闭 ftp 匿名访问 如图三$ vim /etc/vsftpd/vsftpd.conf  # 原为 anonymous_enable=NO  anonymous_enable=YES# 修改 ftp 所属用户为上面创建的用户 如图四$ vim /etc/vsftpd/vsftpd.conf  chown_username=ftpadmin# 设置 ftp 开机启动$ chkconfig vsftpd on# 重启 ftp 服务$ service vsftpd restart</code></pre></li><li><p> 图一:<br><img src="http://qiniu.raindrop-wl.cn/ftb-iptables.png" srcset="/img/loading.gif" alt="ftp-iptables"></p></li><li><p> 图二:<br><img src="http://qiniu.raindrop-wl.cn/ftp-selinux.png" srcset="/img/loading.gif" alt="ftp-selinux"></p></li><li><p> 图三:<br><img src="http://qiniu.raindrop-wl.cn/fts-anonymous.png" srcset="/img/loading.gif" alt="ftp-anonymous"></p></li><li><p> 图四:<br><img src="http://qiniu.raindrop-wl.cn/ftp-chown.png" srcset="/img/loading.gif" alt="ftp-chown"></p></li></ul><h3 id="Setp-2"><a href="#Setp-2" class="headerlink" title="Setp 2"></a>Setp 2</h3><ul><li><p>Nginx 安装 </p><pre><code class="bash"># 安装 c 依赖$ yum -y install gcc gcc-c++ autoconf automake make pcre-devel openssl openssl-devel# 解压 Nginx 并编译安装$ tar -zxvf nginx-1.4.0.tar.gz &amp;&amp; cd nginx-1.4.0$ ./configure \    --prefix=/usr/local/nginx \    --pid-path=/var/run/nginx/nginx.pid \    --lock-path=/var/lock/nginx.lock \    --error-log-path=/var/log/nginx/error.log \    --http-log-path=/var/log/nginx/access.log \    --with-http_gzip_static_module \    --http-client-body-temp-path=/var/temp/nginx/client \    --http-proxy-temp-path=/var/temp/nginx/proxy \    --http-fastcgi-temp-path=/var/temp/nginx/fastcgi \    --http-uwsgi-temp-path=/var/temp/nginx/uwsgi \    --http-scgi-temp-path=/var/temp/nginx/scgi \    --add-module=ngx-fancyindex-0.4.3  # 该模块用来美化 ftp 目录，在 github 上下载到 nginx-1.4.0 目录下即可 https://github.com/aperezdc/ngx-fancyindex$ make &amp;&amp; make install# 配置 nginx，将目录地址指向 ftp 目录位置，我们的目录为： /home/ftpuser$ vim /usr/local/nginx/conf/nginx.conf  location / {root /home/ftpuser;}# 重新加载 nginx，访问 http://localhost/ 即可看见文件目录了$ ./nginx -s reload</code></pre></li></ul><h3 id="Setp-3"><a href="#Setp-3" class="headerlink" title="Setp 3"></a>Setp 3</h3><ul><li><p> 下面我们将 Nginx 页面进行美化一下（现在的样子实在是有点不过关）</p><pre><code class="bash"># 下载 Nginx-Fancyindex-Theme，目前有两种主题比较好，地址如下，我们选择第一种# https://github.com/Naereen/Nginx-Fancyindex-Theme# https://github.com/TheInsomniac/Nginx-Fancyindex-Theme# 进入 nginx web 目录，并克隆项目$ cd nginx &amp;&amp; git clone https://github.com/Naereen/Nginx-Fancyindex-Theme# 修改 nginx 配置文件，导入样式文件 如图一$ vi conf/nginx.conf  include /home/weblogic/software/nginx-1.14/Nginx-Fancyindex-Theme/fancyindex.conf;# note：需要注意的是，我们需要把 Nginx-Fancyindex-Theme 目录全部拷贝一份到 ftp 根目录下，不然会报 404，如图二$ cp -R Nginx-Fancyindex-Theme /home/ftpuser# 重新加载 nginx 即可$ ./nginx -s reload</code></pre></li><li><p> 图一:<br><img src="http://qiniu.raindrop-wl.cn/ftp-theme.png" srcset="/img/loading.gif" alt="ftp-theme"></p></li><li><p> 图二:<br><img src="http://qiniu.raindrop-wl.cn/ftp-theme-path.png" srcset="/img/loading.gif" alt="ftp-theme-path"></p></li></ul><h3 id="Setp-4"><a href="#Setp-4" class="headerlink" title="Setp 4"></a>Setp 4</h3><ul><li><p> 我们来检查一下最终的效果，访问 <a href="http://localhost/" target="_blank" rel="noopener">http://localhost/</a> ，我们看到的内容会如下图一下，美观、大方、简洁、漂亮！</p><p><img src="http://qiniu.raindrop-wl.cn/ftp-over1.png" srcset="/img/loading.gif" alt="ftp-ftp-over1"></p><p><img src="http://qiniu.raindrop-wl.cn/ftp-over2.png" srcset="/img/loading.gif" alt="ftp-ftp-over2"></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Nginx</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Mysql High Availability</title>
    <link href="/2020/03/13/Mysql%20High%20Availability/"/>
    <url>/2020/03/13/Mysql%20High%20Availability/</url>
    
    <content type="html"><![CDATA[<center> <font face="黑体" size="6">Mysql + Keepalived 主主热备，搭建高可用集群 </font> </center><a id="more"></a><h3 id="在 -Mysql- 集群部署方案中有很多种组合方式，如 - 主从复制、主主热备、一主多从、多主一从（多源复制）等 - 无论哪种部署方案，都是为了提高 -Mysql- 服务的性能或可用性为目的 - 那么最终使用哪种部署方案，还是要根据需求场景来 - 本次将记录一下，工作中遇到的“主主热备 - 高可用”搭建的方法"><a href="# 在 -Mysql- 集群部署方案中有很多种组合方式，如 - 主从复制、主主热备、一主多从、多主一从（多源复制）等 - 无论哪种部署方案，都是为了提高 -Mysql- 服务的性能或可用性为目的 - 那么最终使用哪种部署方案，还是要根据需求场景来 - 本次将记录一下，工作中遇到的“主主热备 - 高可用”搭建的方法" class="headerlink" title="在 Mysql 集群部署方案中有很多种组合方式，如: 主从复制、主主热备、一主多从、多主一从（多源复制）等. 无论哪种部署方案，都是为了提高 Mysql 服务的性能或可用性为目的. 那么最终使用哪种部署方案，还是要根据需求场景来. 本次将记录一下，工作中遇到的“主主热备 + 高可用”搭建的方法."></a> 在 Mysql 集群部署方案中有很多种组合方式，如: 主从复制、主主热备、一主多从、多主一从（多源复制）等. 无论哪种部署方案，都是为了提高 Mysql 服务的性能或可用性为目的. 那么最终使用哪种部署方案，还是要根据需求场景来. 本次将记录一下，工作中遇到的“主主热备 + 高可用”搭建的方法.</h3><p><strong> 环境如下 </strong>:</p><table><thead><tr><th align="center">Plugin</th><th align="center">Version</th></tr></thead><tbody><tr><td align="center">Centos</td><td align="center">7.2</td></tr><tr><td align="center">MySQL</td><td align="center">5.7</td></tr><tr><td align="center">Keepalived</td><td align="center">1.4.5</td></tr></tbody></table><p><strong> 服务器配置 </strong>:</p><table><thead><tr><th align="center">Server</th><th align="center">Software</th><th align="center">Configure</th></tr></thead><tbody><tr><td align="center">192.168.1.100</td><td align="center">Master1/Slave2/Keepalived-Master</td><td align="center">8 核 + 8g</td></tr><tr><td align="center">192.168.1.101</td><td align="center">Master2/Slave1/Keepalived-Backup</td><td align="center">8 核 + 8g</td></tr><tr><td align="center">192.168.1.110(vip)</td><td align="center">&amp;</td><td align="center">&amp;</td></tr></tbody></table><p><strong>MySQL 主从架构 </strong></p><ol><li><p> 主服务器上面的任何修改都会通过自己的 I/O tread(I/O 线程) 保存在二进制日志 Binary log 里面。</p></li><li><p> 从服务器上面也启动一个 I/O thread，通过配置好的用户名和密码, 连接到主服务器上面请求读取二进制日志，然后把读取到的二进制日志写到本地的一个 Realy log（中继日志）里面。</p></li><li><p> 从服务器上面同时开启一个 SQL thread 定时检查 Realy log(这个文件也是二进制的)，如果发现有更新立即把更新的内容在本机的数据库上面执行一遍。</p></li></ol><div aligh="center">    <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/MySQL- 故障恢复（一）/MySQL.png" srcset="/img/loading.gif" width="100%"></div><p><strong> 实施过程 </strong></p><ul><li><p>192.168.1.100 与 192.168.1.101 主主热备.</p></li><li><p> 使用 Keepalived 搭建虚拟 VIP192.168.1.110，实现对外暴露统一 ip.<br><img src="http://qiniu.raindrop-wl.cn/mysql-keepalived.png" srcset="/img/loading.gif" alt="Mysql-Keepalived"></p></li></ul><h3 id="我们首先来配置主主热备"><a href="# 我们首先来配置主主热备" class="headerlink" title="我们首先来配置主主热备"></a> 我们首先来配置主主热备 </h3><ul><li><p>Master1 192.168.1.100 配置 </p><pre><code class="bash"># 防火墙开发 3306 端口$ firewall-cmd --permanent --zone=public --add-port=3306/tcp$ firewall-cmd --reload#配置 root 用户远程访问权限，配置 mysql 数据同步授权$ ./mysql -uroot -pmysql&gt; grant all on *.* to &#39;root&#39;@&#39;192.168.1.%&#39; identified by &#39;123456&#39;;mysql&gt; flush privileges;mysql&gt; grant replication slave on *.* to &#39;slave&#39;@&#39;192.168.1.%&#39; identified by &#39;123456&#39;;mysql&gt; flush privileges;#配置 my.cnf 如下$ vim /etc/my.cnf  [mysqld]  user=mysql  server-id=1                                    #主从服务器 id，必须保证唯一，值越小优先级越高（master 值小）  port=3306  basedir=/usr/local/mysql  datadir=/usr/local/mysql/data  socket=/tmp/mysql.sock  character-set-server=utf8  auto_increment_offset=1                        #自增起始值 1，因为是 master1 所以为 1  auto_increment_increment=2                     #自增步骤 2，因为目前的是 2 台机器集群，所有步骤为 2  log-bin=mysql-bin                              #开启 binlog 二进制日志（存储的是写操作的 sql 执行日志）  binlog_format=ROW                              #binlog 同步模式  replicate-ignore-db = mysql                    #忽略不同步主从的数据库  replicate-ignore-db = information_schema       #忽略不同步主从的数据库  replicate-ignore-db = performance_schema       #忽略不同步主从的数据库  replicate-ignore-db = test                     #忽略不同步主从的数据库  lower_case_table_names=1                       #大小写敏感，默认为 0 可以不配置  [mysqld_safe]  log-error=/usr/local/mysql/mysqld.log  pid-file=/usr/local/mysql/mysqld.pid  [client]  default-character-set=utf8  socket=/tmp/mysql.sock  [mysql]  default-character-set=utf8  socket=/tmp/mysql.sock#重启 mysql$ system restart mysqld#查看 binlog 日志及 pos 位置$ ./mysql -uroot -pmysql&gt; show master status;+------------------|----------|--------------|--------------------------|-------------------+| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB         | Executed_Gtid_Set |+------------------|----------|--------------|--------------------------|-------------------+| mysql-bin.000001 |      120 |              | mysql,information_schema |                   |+------------------|----------|--------------|--------------------------|-------------------+</code></pre></li><li><p>Master2 192.168.1.101 配置 </p><pre><code class="bash"># 防火墙开发 3306 端口$ firewall-cmd --permanent --zone=public --add-port=3306/tcp$ firewall-cmd --reload#配置 mysql 数据同步授权，配置 root 用户远程访问权限$ ./mysql -uroot -pmysql&gt; grant all on *.* to &#39;root&#39;@&#39;192.168.1.%&#39; identified by &#39;123456&#39;;mysql&gt; flush privileges;mysql&gt; grant replication slave on *.* to &#39;slave&#39;@&#39;192.168.1.%&#39; identified by &#39;123456&#39;;mysql&gt; flush privileges;#配置 my.cnf 如下$ vim /etc/my.cnf  [mysqld]  user=mysql  server-id=2                                    #主从服务器 id，必须保证唯一，值越小优先级越高（master 值小）  port=3306  basedir=/usr/local/mysql  datadir=/usr/local/mysql/data  socket=/tmp/mysql.sock  character-set-server=utf8  auto_increment_offset=2                        #自增起始值 2，因为是 master2 所以为 2  auto_increment_increment=2                     #自增步骤 2，因为目前的是 2 台机器集群，所有步骤为 2  log-bin=mysql-bin                              #开启 binlog 二进制日志（存储的是写操作的 sql 执行日志）  binlog_format=ROW                              #binlog 同步模式  replicate-ignore-db = mysql                    #忽略不同步主从的数据库  replicate-ignore-db = information_schema       #忽略不同步主从的数据库  replicate-ignore-db = performance_schema       #忽略不同步主从的数据库  replicate-ignore-db = test                     #忽略不同步主从的数据库  lower_case_table_names=1                       #大小写敏感，默认为 0 可以不配置  [mysqld_safe]  log-error=/usr/local/mysql/mysqld.log  pid-file=/usr/local/mysql/mysqld.pid  [client]  default-character-set=utf8  socket=/tmp/mysql.sock  [mysql]  default-character-set=utf8  socket=/tmp/mysql.sock#重启 mysql$ system restart mysqld#查看 binlog 日志及 pos 位置$ ./mysql -uroot -pmysql&gt; show master status;+------------------|----------|--------------|--------------------------|-------------------+| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB         | Executed_Gtid_Set |+------------------|----------|--------------|--------------------------|-------------------+| mysql-bin.000001 |      120 |              | mysql,information_schema |                   |+------------------|----------|--------------|--------------------------|-------------------+</code></pre></li></ul><ul><li><p>Master1 做同步操作 </p><pre><code class="bash">$ ./mysql -uroot -pmysql&gt; stop slave;mysql&gt; change master to \        master_host=&#39;192.168.1.101&#39;,        master_port=3306,        master_user=&#39;slave&#39;,        master_password=&#39;123456&#39;,        master_log_file=&#39;mysql-bin.000001&#39;,        master_log_pos=120;mysql&gt; start slave;mysql&gt; show slave status \G;*************************** 1. row ***************************            Slave_IO_State: Waiting for master to send event              Master_Host: 192.168.1.101              Master_User: slave              Master_Port: 3306            Connect_Retry: 60          Master_Log_File: mysql-bin.000001      Read_Master_Log_Pos: 120            Relay_Log_File: mysql-relay-bin.000001            Relay_Log_Pos: 120    Relay_Master_Log_File: mysql-bin.000001          Slave_IO_Running: Yes        Slave_SQL_Running: Yes    .........................    Seconds_Behind_Master: 0    .........................# 如上，只要保证 Slave_IO_Running、Slave_SQL_Running 的值全部为 Yes 就标识 Master1 与 Master2 实现了主从，Master1 同步 Master2 的数据 </code></pre></li><li><p>Master2 做同步操作 </p><pre><code class="bash">$ ./mysql -uroot -pmysql&gt; stop slave;mysql&gt; change master to \        master_host=&#39;192.168.1.100&#39;,        master_port=3306,        master_user=&#39;slave&#39;,        master_password=&#39;123456&#39;,        master_log_file=&#39;mysql-bin.000001&#39;,        master_log_pos=120;mysql&gt; start slave;mysql&gt; show slave status \G;*************************** 1. row ***************************            Slave_IO_State: Waiting for master to send event              Master_Host: 192.168.1.100              Master_User: slave              Master_Port: 3306            Connect_Retry: 60          Master_Log_File: mysql-bin.000001      Read_Master_Log_Pos: 120            Relay_Log_File: mysql-relay-bin.000001            Relay_Log_Pos: 120    Relay_Master_Log_File: mysql-bin.000001          Slave_IO_Running: Yes        Slave_SQL_Running: Yes    .........................    Seconds_Behind_Master: 0    .........................# 如上，只要保证 Slave_IO_Running、Slave_SQL_Running 的值全部为 Yes 就标识 Master2 与 Master1 实现了主从，Master2 同步 Master1 的数据 </code></pre></li></ul><ul><li><p> 主主热备同步验证 </p><pre><code class="shell"># 在 Master1 中操作mysql&gt; create database my_local;mysql&gt; use my_local;mysql&gt; CREATE TABLE `book` (`id` int(11) NOT NULL AUTO_INCREMENT COMMENT &#39; 主键 &#39;,        `book_name` varchar(100) NOT NULL COMMENT &#39; 书名 &#39;,        `author` varchar(100) DEFAULT NULL COMMENT &#39; 作者 &#39;,        `price` varchar(100) DEFAULT NULL COMMENT &#39; 价格 &#39;,        `remark` varchar(100) DEFAULT NULL COMMENT &#39; 备注 &#39;,        PRIMARY KEY (`id`)      ) ENGINE=InnoDB DEFAULT CHARSET=utf8;mysql&gt; insert into book values(1, &quot;Java 深入浅出 &quot;, &quot;Mas&quot;, &quot;50.00&quot;, &quot;Java 入门不错的书！&quot;);mysql&gt; insert into book values(2, &quot;Python 深入浅出 &quot;, &quot;Mas&quot;, &quot;50.00&quot;, &quot;Python 入门不错的书！&quot;);mysql&gt; insert into book values(3, &quot;Golang 深入浅出 &quot;, &quot;Mas&quot;, &quot;50.00&quot;, &quot;Golang 入门不错的书！&quot;);# 在 Master1 中操作mysql&gt; select * from book;+----|-----------------|--------|-------|----------------------+| id | book_name       | author | price | remark               |+----|-----------------|--------|-------|----------------------+|  1 | Java 深入浅出     | Mas    | 50.00 | Java 入门不错的书！      ||  2 | Python 深入浅出   | Mas    | 50.00 | Python 入门不错的书！    ||  3 | Golang 深入浅出   | Mas    | 50.00 | Golang 入门不错的书！    |+----|-----------------|--------|-------|----------------------+# 在 Master2 中操作mysql&gt; use my_local;mysql&gt; select * from book;+----|-----------------|--------|-------|----------------------+| id | book_name       | author | price | remark               |+----|-----------------|--------|-------|----------------------+|  1 | Java 深入浅出     | Mas    | 50.00 | Java 入门不错的书！      ||  2 | Python 深入浅出   | Mas    | 50.00 | Python 入门不错的书！    ||  3 | Golang 深入浅出   | Mas    | 50.00 | Golang 入门不错的书！    |+----|-----------------|--------|-------|----------------------+mysql&gt; CREATE TABLE `user` (`id` int(11) NOT NULL AUTO_INCREMENT COMMENT &#39; 主键 &#39;,        `name` varchar(100) NOT NULL COMMENT &#39; 姓名 &#39;,        `email` varchar(100) DEFAULT NULL COMMENT &#39; 邮件 &#39;,        `phone` varchar(100) DEFAULT NULL COMMENT &#39; 手机号 &#39;,        `remark` varchar(100) DEFAULT NULL COMMENT &#39; 备注 &#39;,        PRIMARY KEY (`id`)      ) ENGINE=InnoDB DEFAULT CHARSET=utf8;mysql&gt; insert into user values(1, &quot;Wang Liang&quot;, &quot;727474430@qq.com&quot;, &quot;18888888888&quot;, &quot; 管理员 &quot;);mysql&gt; insert into user values(2, &quot;Wang Er&quot;, &quot;727474430@qq.com&quot;, &quot;18666666666&quot;, &quot; 普通用户 &quot;);mysql&gt; insert into user values(3, &quot;Wang San&quot;, &quot;727474430@qq.com&quot;, &quot;18555555555&quot;, &quot; 正常人 &quot;);# 在 Master2 中操作mysql&gt; select * from user;+----|------------|------------------|-------------|----------+| id | name       | email            | phone       | remark   |+----|------------|------------------|-------------|----------+|  1 | Wang Liang | 727474430@qq.com | 18888888888 | 管理员    ||  2 | Wang Er    | 727474430@qq.com | 18666666666 | 普通用户  ||  3 | Wang San   | 727474430@qq.com | 18555555555 | 正常人   |+----|------------|------------------|-------------|----------+# 在 Master1 中操作mysql&gt; use my_local;mysql&gt; select * from user;+----|------------|------------------|-------------|----------+| id | name       | email            | phone       | remark   |+----|------------|------------------|-------------|----------+|  1 | Wang Liang | 727474430@qq.com | 18888888888 | 管理员    ||  2 | Wang Er    | 727474430@qq.com | 18666666666 | 普通用户  ||  3 | Wang San   | 727474430@qq.com | 18555555555 | 正常人   |+----|------------|------------------|-------------|----------+# 至此 192.168.1.100 与 192.168.1.101 主主同步已经配置成功 </code></pre></li></ul><h3 id="接下来我们配置 -Keepalived-ip- 飘逸高可用"><a href="# 接下来我们配置 -Keepalived-ip- 飘逸高可用" class="headerlink" title="接下来我们配置 Keepalived ip 飘逸高可用"></a> 接下来我们配置 Keepalived ip 飘逸高可用 </h3><ul><li><p> 安装 Keepalived，在 192.168.1.100、192.168.1.101 做相同的操作 </p><pre><code class="bash"># 安装依赖$ yum install -y openssl-devel wget$ yum install -y libnfnetlink-devel$ yum -y install libssl-dev libnl libnl-devel# 下载 keepalived$ cd /usr/local/src$ wget http://www.keepalived.org/software/keepalived-1.3.5.tar.gz &amp;&amp; tar -zxvf keepalived-1.3.5.tar.gz$ cd keepalived-1.3.5 &amp;&amp; ./configure --prefix=/usr/local/keepalived$ make &amp;&amp; make install$ cp /usr/local/src/keeyalived-1.3.5/keepalived/etc/init.d/keepalived /etc/rc.d/init.d$ cp /usr/local/keepalived/etc/sysconfig/keepalived /etc/sysconfig/$ mkdir /etc/keepalived$ cp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived/$ cp /usr/local/keepalived/sbin/keepalived /usr/sbin/# 开机启动echo &quot;/etc/init.d/keepalived start&quot; &gt;&gt; /etc/rc.local</code></pre></li><li><p> 在 Master1 中操作 </p><pre><code class="bash"># 备份一下配置文件，如果配置错误可以还原$ cp /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak$ vim /etc/keepalived/keepalived.conf  global_defs {  notification_email {727474430@qq.com}  notification_email_from 727474430@qq.com  smtp_server 127.0.0.1  smtp_connect_timeout 30  router_id MASTER-HA  }  vrrp_script chk_mysql_port {     #检测 mysql 服务是否在运行。有很多方式，比如进程，用脚本检测等等      script &quot;/opt/chk_mysql.sh&quot;   #这里通过脚本监测      interval 2                   #脚本执行间隔，每 2s 检测一次      weight -5                    #脚本结果导致的优先级变更，检测失败（脚本返回非 0）则优先级 -5      fall 2                       #检测连续 2 次失败才算确定是真失败。会用 weight 减少优先级（1-255 之间）      rise 1                       #检测 1 次成功就算成功。但不修改优先级  }  vrrp_instance VI_1 {      state MASTER      interface eth0               #指定虚拟 ip 的网卡接口      mcast_src_ip 192.168.1.100      virtual_router_id 51         #路由器标识，MASTER 和 BACKUP 必须是一致的      priority 101                 #定义优先级，数字越大，优先级越高，在同一个 vrrp_instance 下，MASTER 的优先级必须大于 BACKUP 的优先级。这样 MASTER 故障恢复后，就可以将 VIP 资源再次抢回来      advert_int 1      authentication {          auth_type PASS          auth_pass 1111      }      virtual_ipaddress {192.168.1.110}      track_script {chk_mysql_port}    }# 编写 keepalived 检测脚本$ vim /opt/chk_mysql.sh  #!/bin/bash  counter=$(netstat -na|grep &quot;LISTEN&quot;|grep &quot;3306&quot;|wc -l)  if [&quot;${counter}&quot; -eq 0 ]; then      /etc/init.d/keepalived stop  fi# 授权$ chmod 755 /opt/chk_mysql.sh# 启动 keepalived$ /etc/init.d/keepalived start</code></pre></li><li><p> 在 Master2 中操作 </p><pre><code class="bash"># 备份一下配置文件，如果配置错误可以还原$ cp /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak$ vim /etc/keepalived/keepalived.conf  global_defs {  notification_email {727474430@qq.com}  notification_email_from 727474430@qq.com  smtp_server 127.0.0.1  smtp_connect_timeout 30  router_id MASTER-HA  }  vrrp_script chk_mysql_port {     #检测 mysql 服务是否在运行。有很多方式，比如进程，用脚本检测等等      script &quot;/opt/chk_mysql.sh&quot;   #这里通过脚本监测      interval 2                   #脚本执行间隔，每 2s 检测一次      weight -5                    #脚本结果导致的优先级变更，检测失败（脚本返回非 0）则优先级 -5      fall 2                       #检测连续 2 次失败才算确定是真失败。会用 weight 减少优先级（1-255 之间）      rise 1                       #检测 1 次成功就算成功。但不修改优先级  }  vrrp_instance VI_1 {      state MASTER      interface eth0               #指定虚拟 ip 的网卡接口      mcast_src_ip 192.168.1.101      virtual_router_id 51         #路由器标识，MASTER 和 BACKUP 必须是一致的      priority 101                 #定义优先级，数字越大，优先级越高，在同一个 vrrp_instance 下，MASTER 的优先级必须大于 BACKUP 的优先级。这样 MASTER 故障恢复后，就可以将 VIP 资源再次抢回来      advert_int 1      authentication {          auth_type PASS          auth_pass 1111      }      virtual_ipaddress {192.168.1.110}      track_script {chk_mysql_port}    }# 编写 keepalived 检测脚本$ vim /opt/chk_mysql.sh  #!/bin/bash  counter=$(netstat -na|grep &quot;LISTEN&quot;|grep &quot;3306&quot;|wc -l)  if [&quot;${counter}&quot; -eq 0 ]; then      /etc/init.d/keepalived stop  fi# 授权$ chmod 755 /opt/chk_mysql.sh# 启动 keepalived$ /etc/init.d/keepalived start</code></pre></li><li><p> 配置防火墙规则 </p><pre><code class="bash"># 在 Master1、Master2 中做相同操作$ vim /etc/sysconfig/iptables  # 加入如下三行配置  -A INPUT -s 182.148.15.0/24 -d 224.0.0.18 -j ACCEPT       #允许组播地址通信  -A INPUT -s 182.148.15.0/24 -p vrrp -j ACCEPT             #允许 VRRP（虚拟路由器冗余协）通信  -A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT    #开放 mysql 的 3306 端口# 重启防火墙$ /etc/init.d/iptables restart</code></pre></li></ul><h3 id="Mysql-Keepalived- 故障转义高可用测试"><a href="#Mysql-Keepalived- 故障转义高可用测试" class="headerlink" title="Mysql Keepalived 故障转义高可用测试"></a>Mysql Keepalived 故障转义高可用测试 </h3><ul><li><p> 使用客户端连接 keepalived 所创建的 vip，查看是否可以连接并看到对应的数据.</p><pre><code class="bash">$ mysql -h192.168.1.110 -uroot -p123456mysql&gt; use my_local;mysql&gt; select * from user;+----|------------|------------------|-------------|----------+| id | name       | email            | phone       | remark   |+----|------------|------------------|-------------|----------+|  1 | Wang Liang | 727474430@qq.com | 18888888888 | 管理员    ||  2 | Wang Er    | 727474430@qq.com | 18666666666 | 普通用户  ||  3 | Wang San   | 727474430@qq.com | 18555555555 | 正常人   |+----|------------|------------------|-------------|----------+</code></pre></li><li><p> 查看当前 vip 所在地址 </p><pre><code class="bash"># 因为默认 vip 是创建在 master1 上的，所以我们首先在 master1 上执行$ ip addr  eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000  link/ether 52:54:00:3c:25:42 brd ff:ff:ff:ff:ff:ff  inet 192.168.1.100/27 brd 182.148.15.255 scope global eth0  inet 192.168.1.110/32 scope global eth0                              // 这个 32 位子网掩码的 vip 地址表示该资源目前还在 master1 机器上  inet 192.168.1.100/27 brd 82.48.115.255 scope global secondary eth0:0  inet6 fe80::5054:ff:fe3c:2542/64 scope link  valid_lft forever preferred_lft forever# 停止 Master1 上的 mysql 服务，根据配置如果 mysql 服务停止了，keepalived 也随之停止，然后 vip 将会漂移到 Master2 上.$ /etc/init.d/mysql stop  eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000  link/ether 52:54:00:3c:25:42 brd ff:ff:ff:ff:ff:ff  inet 192.168.1.100/27 brd 182.148.15.255 scope global eth0  inet 192.168.1.100/27 brd 82.48.115.255 scope global secondary eth0:0  inet6 fe80::5054:ff:fe3c:2542/64 scope link  valid_lft forever preferred_lft forever# 如上，如果 32 位子网掩码的 vip 没有了，就证明只是 vip 在 Master1 上已经停止# 查看 Master1 的系统日志，可以看到 vip 资源切换的过程$ tail -f /var/log/message  Apr 15 17:17:43 localhost Keepalived_vrrp[23037]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:17:48 localhost Keepalived_vrrp[23037]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:17:48 localhost Keepalived_vrrp[23037]: VRRP_Instance(VI_1) Sending/queueing gratuitous ARPs on eth0 for 192.168.1.110  Apr 15 17:17:48 localhost Keepalived_vrrp[23037]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:17:48 localhost Keepalived_vrrp[23037]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:17:48 localhost Keepalived_vrrp[23037]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:17:48 localhost Keepalived_vrrp[23037]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:39 localhost Keepalived_healthcheckers[23036]: Stopped  Apr 15 17:30:39 localhost Keepalived_vrrp[23037]: VRRP_Instance(VI_1) sent 0 priority  Apr 15 17:30:39 localhost Keepalived_vrrp[23037]: VRRP_Instance(VI_1) removing protocol VIPs.# 此时切换到 Master2 上执行$ ip addr  eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000  link/ether 52:54:00:3c:25:42 brd ff:ff:ff:ff:ff:ff  inet 192.168.1.101/27 brd 182.148.15.255 scope global eth0  inet 192.168.1.110/32 scope global eth0                              // 这个 32 位子网掩码的 vip 地址表示该资源目前还在 master2 机器上  inet6 fe80::5054:ff:fe3c:2542/64 scope link  valid_lft forever preferred_lft forever# 查看 Master2 的系统日志，可以看到 vip 资源切换的过程$ tail -f /var/log/message  Apr 15 17:30:41 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:41 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:41 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:41 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: VRRP_Instance(VI_1) Sending/queueing gratuitous ARPs on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110# 再次启动 Master1 上的 mysql 服务、然后启动 keepalived 服务，我们可以看到 vip 此时漂移回 Master1 服务器上$ /etc/init.d/mysql start$ /etc/init.d/keepalived start$ ip addr  eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000  link/ether 52:54:00:3c:25:42 brd ff:ff:ff:ff:ff:ff  inet 192.168.1.100/27 brd 182.148.15.255 scope global eth0  inet 192.168.1.110/32 scope global eth0                              // 这个 32 位子网掩码的 vip 地址表示该资源目前还在 master1 机器上  inet 192.168.1.100/27 brd 82.48.115.255 scope global secondary eth0:0  inet6 fe80::5054:ff:fe3c:2542/64 scope link  valid_lft forever preferred_lft forever# 查看日志$ tail -f /var/log/message  Apr 15 17:30:41 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:41 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:41 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:41 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: VRRP_Instance(VI_1) Sending/queueing gratuitous ARPs on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110# 在查看 Master2 上，vip 已经不存在了，漂移回 Master1 上了$ ip addr  eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000  link/ether 52:54:00:3c:25:42 brd ff:ff:ff:ff:ff:ff  inet 192.168.1.101/27 brd 182.148.15.255 scope global eth0  inet 192.168.1.101/27 brd 82.48.115.255 scope global secondary eth0:0  inet6 fe80::5054:ff:fe3c:2542/64 scope link  valid_lft forever preferred_lft forever# 查看日志$ tail -f /var/log/message  Apr 15 17:30:41 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: VRRP_Instance(VI_1) Sending/queueing gratuitous ARPs on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:30:46 localhost Keepalived_vrrp[8731]: Sending gratuitous ARP on eth0 for 192.168.1.110  Apr 15 17:40:41 localhost Keepalived_vrrp[8731]: VRRP_Instance(VI_1) Received advert with higher priority 101, ours 99  Apr 15 17:40:41 localhost Keepalived_vrrp[8731]: VRRP_Instance(VI_1) Entering BACKUP STATE  Apr 15 17:40:41 localhost Keepalived_vrrp[8731]: VRRP_Instance(VI_1) removing protocol VIPs.# 同样如果停止 Master1 或 Master2 上的 Keepalived 服务，vip 同样也会漂移，再次启动 Keepalived 服务，vip 会再次漂移回来.</code></pre></li></ul><h5 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q &amp; A"></a>Q &amp; A</h5><ul><li><p> 单向同步:<br> 可以重新执行 change master 同步操作，只不过这样同步后，只能同步在此之后的数据，不能能同步之前丢失的数据.</p></li><li><p> 主从报错:</p><pre><code class="bash"># 通过命令查询错误信息，主要查看一下字段mysql&gt; show slave status \G;       Slave_IO_Running: Yes       Slave_SQL_Running: No       Last_Error: 1008       Last_Error: Error Message &#39;Can&#39;t drop database &#39;lcp&#39;; database doesn&#39;t exist&#39; on query. Default database: &#39;lcp&#39;. Query: &#39;drop database lcp&#39;# 通过以上信息看出来，是数据库不存在而导致的主从查询失败. 原因是在主库和从库同时做了相同的操作也导致的报错. 解决这个问题，我们需要先查看一下错误日志，然后定位到问题所在的位置，在然后找一下一共有多少条错误，最后将 binlog 指针下移错误次数位置即可解决.# 查看错误日志文件地址mysql&gt; show global variables like &#39;%log%&#39;;# 查看错误日志文$ cat error.log# 执行 binlog 指针下移 2 位mysql&gt; stop slave;mysql&gt; set global_sql_slave_skip_counter=2mysql&gt; start slave;# 再次查看主从状态mysql&gt; show slave status \G;       Slave_IO_Running: Yes       Slave_SQL_Running: Yes</code></pre></li></ul><h5 id="抢占模式"><a href="# 抢占模式" class="headerlink" title="抢占模式:"></a> 抢占模式:</h5><ul><li><p> 主服务正常工作时，虚拟 IP 会在主上，备不提供服务，当主服务优先级低于备的时候，备会自动抢占虚拟 IP，这时，主不提供服务，备提供服务。也就是说，工作在抢占模式下，不分主备，只管优先级.</p></li><li><p> 这种方式通过参数 nopreempt（一般设置在 advert_int 的那一行下面）来控制。不管 priority 优先级，只要 MASTER 机器发生故障，VIP 资源就会被切换到 BACKUP 上。并且当 MASTER 机器恢复后，也不会去将 VIP 资源抢占回来，直至 BACKUP 机器发生故障时，才能自动切换回来.</p></li><li><p>nopreempt 这个参数只能用于 state 为 backup 的情况，所以在配置的时候要把 master 和 backup 的 state 都设置成 backup，这样才会实现 keepalived 的非抢占模式！</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Mysql</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>MySQL-Command</title>
    <link href="/2020/03/13/MySQL-Command/"/>
    <url>/2020/03/13/MySQL-Command/</url>
    
    <content type="html"><![CDATA[<center> <font face="黑体" size="6">MySQL-Command</font> </center><hr><a id="more"></a><h5 id="Other-Related"><a href="#Other-Related" class="headerlink" title="Other Related"></a>Other Related</h5><table><thead><tr><th> 命令 </th><th> 含义 </th><th> 常用 </th></tr></thead><tbody><tr><td>show processlist</td><td> 查看当前链接此数据库的进程信息 </td><td>show processlist</td></tr><tr><td>show profile</td><td> 查询当前会话中最后一条语句执行的资源使用情况，如果显示空，表示未开始 profile，开启 profile set profling=1</td><td>profile</td></tr><tr><td>show profiles</td><td> 以列表形式展示服务器中最近执行的语句资源使用情况，显示记录数量由 profiling_history_size 控制，默认 15 条 </td><td>profiles</td></tr><tr><td>show profile cpu,swaps for query queryId</td><td> 查询指定 query 语句的指定资源使用情况（这里是 CPU、SWAPS）</td><td>show profile cpu,swaps for query 1</td></tr><tr><td>show variables like ‘%engine%’</td><td> 查看 MySQL 默认引擎 </td><td>show variables like ‘%engine%’</td></tr><tr><td>show variables like ‘%query_cache%’</td><td> 查看 是否开启查询缓存 <code>have_query_cache</code> 是否支持缓存 <code>query_cache_type</code> 是否开启缓存 </td><td>show variables like ‘%query_cache%’</td></tr><tr><td>show variables like ‘%buffer_pool%’</td><td> 查看页内存信息 </td><td>show variables like ‘%buffer_pool%’</td></tr></tbody></table><ul><li><code>show processlist</code></li></ul><pre><code class="mysql">show processlist;+------+------+-----------------+------+---------+------+----------+------------------+| Id   | User | Host            | db   | Command | Time | State    | Info             |+------+------+-----------------+------+---------+------+----------+------------------+| 1175 | root | localhost:49797 | test | Query   | 0    | starting | show processlist || 1182 | root | localhost:50587 | test | Query   | 0    | &lt;null&gt;   | CALL batchInsert || 1183 | root | localhost:50629 | test | Sleep   | 294  |          | &lt;null&gt;           |+------+------+-----------------+------+---------+------+----------+------------------+</code></pre><ul><li><code>show profile</code></li></ul><pre><code class="mysql">show profile;+----------------------+----------+| Status               | Duration |+----------------------+----------+| starting             | 0.000031 || checking permissions | 0.000003 || Opening tables       | 0.001230 || init                 | 0.000017 || System lock          | 0.000004 || optimizing           | 0.000003 || statistics           | 0.000008 || preparing            | 0.000014 || executing            | 0.000003 || Sending data         | 1.645334 || end                  | 0.000004 || query end            | 0.000009 || closing tables       | 0.000004 || freeing items        | 0.000032 || cleaning up          | 0.000028 |+----------------------+----------+# 通过 query_id 查询show profile cpu, swaps for query 1;+----------------+----------+----------+------------+-------+| Status         | Duration | CPU_user | CPU_system | Swaps |+----------------+----------+----------+------------+-------+| starting       | 0.000517 | 0.000227 | 0.000333   | 0     || query end      | 0.000003 | 0.000002 | 0.000002   | 0     || closing tables | 0.000002 | 0.000001 | 0.000000   | 0     || freeing items  | 0.000014 | 0.000003 | 0.000012   | 0     || cleaning up    | 0.000005 | 0.000004 | 0.000000   | 0     |+----------------+----------+----------+------------+-------+</code></pre><ul><li><code>show profiles</code></li></ul><pre><code class="mysql">show profiles;+----------+--------------+-----------------------------------+| Query_ID | Duration     | Query                             |+----------+--------------+-----------------------------------+| 1        |     0.000844 | show variables like &#39;profiling%&#39;  || 2        |     0.00387  | select * from score               || 3        |     1.646724 | select count(*) from user         |+----------+--------------+-----------------------------------+</code></pre><ul><li><code>show variables</code></li></ul><pre><code class="mysql">show variables like &#39;%engine%&#39;;+----------------------------------+--------+| Variable_name                    | Value  |+----------------------------------+--------+| default_storage_engine           | InnoDB || default_tmp_storage_engine       | InnoDB || disabled_storage_engines         |        || internal_tmp_disk_storage_engine | InnoDB |+----------------------------------+--------+show variables like &#39;%query_cache%&#39;;+------------------------------+---------+| Variable_name                | Value   |+------------------------------+---------+| have_query_cache             | YES     || query_cache_limit            | 1048576 || query_cache_min_res_unit     | 4096    || query_cache_size             | 1048576 || query_cache_type             | OFF     || query_cache_wlock_invalidate | OFF     |+------------------------------+---------+show variables like &#39;%buffer_pool%&#39;;+-------------------------------------+----------------+| Variable_name                       | Value          |+-------------------------------------+----------------+| innodb_buffer_pool_chunk_size       | 134217728      || innodb_buffer_pool_dump_at_shutdown | ON             || innodb_buffer_pool_dump_now         | OFF            || innodb_buffer_pool_dump_pct         | 25             || innodb_buffer_pool_filename         | ib_buffer_pool || innodb_buffer_pool_instances        | 1              || innodb_buffer_pool_load_abort       | OFF            || innodb_buffer_pool_load_at_startup  | ON             || innodb_buffer_pool_load_now         | OFF            || innodb_buffer_pool_size             | 134217728      |+-------------------------------------+----------------+</code></pre><hr><h5 id="Table-Related"><a href="#Table-Related" class="headerlink" title="Table Related"></a>Table Related</h5><table><thead><tr><th> 命令 </th><th> 含义 </th><th> 常用 </th></tr></thead><tbody><tr><td>describe <code>tableName</code> / desc <code>tableName</code></td><td> 查看表的详情信息 </td><td>describe user; / desc user;</td></tr><tr><td>show create table <code>tableName</code></td><td> 查看表的创建语句 </td><td>show create table user;</td></tr><tr><td>create table <code>tableName</code> (<code>column</code> type desc)</td><td> 创建表 </td><td>create table <code>user</code> (id int primary key)</td></tr><tr><td>drop table <code>tableName</code></td><td> 删除表 </td><td>drop table <code>user</code></td></tr></tbody></table><ul><li><code>describe table</code></li></ul><pre><code class="mysql">describe user;+-------+--------------+------+-----+---------+----------------+| Field | Type         | Null | Key | Default | Extra          |+-------+--------------+------+-----+---------+----------------+| id    | int(11)      | NO   | PRI | NULL    | auto_increment || name  | varchar(32)  | NO   |     | NULL    |                || age   | varchar(32)  | NO   |     | NULL    |                || city  | varchar(32)  | NO   |     | NULL    |                || tmp   | varchar(255) | YES  |     | NULL    |                |+-------+--------------+------+-----+---------+----------------+# desc 等价于 describedesc user;+-------+--------------+------+-----+---------+----------------+| Field | Type         | Null | Key | Default | Extra          |+-------+--------------+------+-----+---------+----------------+| id    | int(11)      | NO   | PRI | NULL    | auto_increment || name  | varchar(32)  | NO   |     | NULL    |                || age   | varchar(32)  | NO   |     | NULL    |                || city  | varchar(32)  | NO   |     | NULL    |                || tmp   | varchar(255) | YES  |     | NULL    |                |+-------+--------------+------+-----+---------+----------------+</code></pre><ul><li><code>show create table</code></li></ul><pre><code class="mysql">show create table user;+-------+------------------------------------------------------------+| Table | Create Table                                               |+-------+------------------------------------------------------------+| user  | CREATE TABLE `user` (                                      ||  `id` int(11) NOT NULL AUTO_INCREMENT,                             ||  `name` varchar(32) CHARACTER SET utf8 NOT NULL,                   ||  `age` varchar(32) CHARACTER SET utf8 NOT NULL,                    ||  `city` varchar(32) CHARACTER SET utf8 NOT NULL,                   ||  `tmp` varchar(255) DEFAULT NULL,                                  ||  PRIMARY KEY (`id`)                                                || ) ENGINE=InnoDB AUTO_INCREMENT=18 DEFAULT CHARSET=latin1           |+-------+------------------------------------------------------------+1 row in set (0.00 sec)</code></pre><ul><li><code>create table</code></li></ul><pre><code class="mysql">CREATE TABLE `user` (`id` int(11) NOT NULL AUTO_INCREMENT,  `name` varchar(32) CHARACTER SET utf8 NOT NULL,  `age` varchar(32) CHARACTER SET utf8 NOT NULL,  PRIMARY KEY (`id`));</code></pre><ul><li><code>drop table</code></li></ul><pre><code class="mysql">drop table user;Query OK, 0 rows affected (0.05 sec)select * from user;ERROR 1146 (42S02): Table &#39;backup.user&#39; doesn&#39;t exist</code></pre><hr><h5 id="Binlog-Related"><a href="#Binlog-Related" class="headerlink" title="Binlog Related"></a>Binlog Related</h5><table><thead><tr><th> 命令 </th><th> 含义 </th><th> 常用 </th></tr></thead><tbody><tr><td>show variables like</td><td> 查询变量相关配置信息 </td><td>show variables like ‘%log_bin%’</td></tr><tr><td>show binlog events in ‘binlogfile’\G;</td><td> 查询 binlog 文件格式化后内容 </td><td></td></tr><tr><td>mysqlbinlog -v binlogFile</td><td> 查询 binlog 文件内容 </td><td>mysqlbinlog -v mysql-bin.000001</td></tr></tbody></table><ul><li><code>show variable binlog</code></li></ul><pre><code class="mysql">show variables like &#39;%log_bin%&#39;;+---------------------------------+--------------------------------+| Variable_name                   | Value                          |+---------------------------------+--------------------------------+| log_bin                         | ON                             || log_bin_basename                | /var/lib/mysql/mysql-bin       || log_bin_index                   | /var/lib/mysql/mysql-bin.index || log_bin_trust_function_creators | OFF                            || log_bin_use_v1_row_events       | OFF                            || sql_log_bin                     | ON                             |+---------------------------------+--------------------------------+</code></pre><ul><li><code>show binlog events</code></li></ul><pre><code class="mysql"># 查看当前 binlog 文件show master status \G;*************************** 1. row ***************************             File: mysql-bin.000001         Position: 10178     Binlog_Do_DB: backup Binlog_Ignore_DB:Executed_Gtid_Set:# 查询 binlog 详情show binlog events in &#39;mysql-bin.000001&#39;\G;...*************************** 44. row ***************************   Log_name: mysql-bin.000001        Pos: 2848 Event_type: Table_map  Server_id: 1End_log_pos: 2906       Info: table_id: 143 (backup.user)*************************** 45. row ***************************   Log_name: mysql-bin.000001        Pos: 2906 Event_type: Write_rows  Server_id: 1End_log_pos: 2951       Info: table_id: 143 flags: STMT_END_F*************************** 46. row ***************************   Log_name: mysql-bin.000001        Pos: 2951 Event_type: Xid  Server_id: 1End_log_pos: 2982       Info: COMMIT /* xid=808 */*************************** 47. row ***************************   Log_name: mysql-bin.000001        Pos: 2982 Event_type: Anonymous_Gtid  Server_id: 1End_log_pos: 3047       Info: SET @@SESSION.GTID_NEXT= &#39;ANONYMOUS&#39;*************************** 48. row ***************************   Log_name: mysql-bin.000001        Pos: 3047 Event_type: Query  Server_id: 1End_log_pos: 3145       Info: drop database backup...</code></pre><ul><li><code>mysqlbinlog -v</code></li></ul><pre><code class="bash">...# at 2906#200313 14:03:59 server id 1  end_log_pos 2951 CRC32 0x17496f50         Write_rows: table id 143 flags: STMT_END_FBINLOG &#39;z5JrXhMBAAAAOgAAAFoLAAAAAI8AAAAAAAEABmJhY2t1cAAEdXNlcgAEAw8PDwZgAGAAYAAAj7jcTQ==z5JrXh4BAAAALQAAAIcLAAAAAI8AAAAAAAEAAgAE//ARAAAAAAI0MABQb0kX&#39;/*!*/;### INSERT INTO `backup`.`user`### SET###   @1=17###   @2=&#39;&#39;###   @3=&#39;40&#39;###   @4=&#39;&#39;# at 2951#200313 14:03:59 server id 1  end_log_pos 2982 CRC32 0x76e6e0db         Xid = 808COMMIT/*!*/;# at 2982#200313 14:04:38 server id 1  end_log_pos 3047 CRC32 0x00bc8281         Anonymous_GTID  last_committed=10       sequence_number=11      rbr_only=noSET @@SESSION.GTID_NEXT= &#39;ANONYMOUS&#39;/*!*/;# at 3047#200313 14:04:38 server id 1  end_log_pos 3145 CRC32 0xbc32a2d6         Query   thread_id=41    exec_time=0     error_code=0SET TIMESTAMP=1584108278/*!*/;SET @@session.pseudo_thread_id=41/*!*/;drop database backup/*!*/;# at 3145#200313 14:06:59 server id 1  end_log_pos 3192 CRC32 0x68a2c9ea         Rotate to mysql-bin.000002  pos: 4SET @@SESSION.GTID_NEXT= &#39;AUTOMATIC&#39; /* added by mysqlbinlog */ /*!*/;DELIMITER ;# End of log file/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/;...</code></pre><hr><h5 id="Index-Related"><a href="#Index-Related" class="headerlink" title="Index Related"></a>Index Related</h5><table><thead><tr><th> 命令 </th><th> 含义 </th><th> 常用 </th></tr></thead><tbody><tr><td>show index from tableName</td><td> 查看表的索引信息 </td><td>show index from user;</td></tr><tr><td>alter table <code>tableName</code> add primary key (<code>column</code>)</td><td> 添加主键索引 </td><td>alter table user add primary key (<code>id</code>);</td></tr><tr><td>alter table <code>tableName</code> add unique (<code>column</code>)</td><td> 添加唯一索引 </td><td>alter table user add unique (<code>name</code>);</td></tr><tr><td>alter table <code>tableName</code> add fulltext (<code>column</code>)</td><td> 添加全文索引 </td><td>alter table user add fulltext (<code>name</code>);</td></tr><tr><td>alter table <code>tableName</code> add index <code>indexName</code> (<code>column</code>)</td><td> 添加普通索引 </td><td>alter table user add index idx_name (<code>name</code>);</td></tr><tr><td>alter table <code>tableName</code> add index <code>indexName</code> (<code>column1</code>, <code>column2</code>, …)</td><td> 添加联合索引 </td><td>alter table user add index idx_name (<code>name</code>,<code>age</code>,<code>sex</code>);</td></tr><tr><td>alter table <code>tableName</code> add constraint FK_ID foreign key (<code>column</code>) references tableName (<code>column</code>)</td><td> 添加外建 </td><td>alter table user add constraint FK_SID foreign key (<code>sid</code>) references score (<code>id</code>);</td></tr><tr><td>alter table <code>tableName</code> drop primary key</td><td> 删除主键 </td><td>alter table user drop primary key;</td></tr><tr><td>alter table <code>tableName</code> drop index <code>indexName</code></td><td> 删除索引（包含唯一索引）</td><td>alter table user drop index <code>name</code>;</td></tr><tr><td>alter table <code>tableName</code> drop foreign key FK_ID</td><td> 删除外建 </td><td>alter table user drop foreign key FK_SID;</td></tr></tbody></table><ul><li><code>show index</code></li></ul><pre><code class="mysql">show index from student;+---------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+| Table   | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment |+---------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+| student |          0 | PRIMARY  |            1 | std_id      | A         |           2 |     NULL | NULL   |      | BTREE      |         |               |+---------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+</code></pre><ul><li><code>alter table add</code></li></ul><pre><code class="mysql">-- 添加主键索引，注意查看 Key 字段desc student;+----------+-------------+------+-----+---------+-------+| Field    | Type        | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+-------+| std_id   | int(11)     | NO   |     | NULL    |       || std_name | varchar(32) | YES  |     | NULL    |       |+----------+-------------+------+-----+---------+-------+alter table student add primary key (`std_id`);Query OK, 0 rows affected (0.11 sec)desc student;+----------+-------------+------+-----+---------+-------+| Field    | Type        | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+-------+| std_id   | int(11)     | NO   | PRI | NULL    |       || std_name | varchar(32) | YES  |     | NULL    |       |+----------+-------------+------+-----+---------+-------+-- 添加唯一索引，注意查看 Key 字段alter table student add unique (`std_name`);Query OK, 0 rows affected (0.05 sec)desc student;+----------+-------------+------+-----+---------+-------+| Field    | Type        | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+-------+| std_id   | int(11)     | NO   | PRI | NULL    |       || std_name | varchar(32) | YES  | UNI | NULL    |       |+----------+-------------+------+-----+---------+-------+-- 添加普通索引，注意查看 Key 字段alter table student add index idx_std_name (`std_name`);Query OK, 0 rows affected (0.04 sec)desc student;+----------+-------------+------+-----+---------+-------+| Field    | Type        | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+-------+| std_id   | int(11)     | NO   | PRI | NULL    |       || std_name | varchar(32) | YES  | MUL | NULL    |       |+----------+-------------+------+-----+---------+-------+-- 添加复合索引show index from student;+---------+------------+-------------+--------------+-------------+| Table   | Non_unique | Key_name    | Seq_in_index | Column_name |+---------+------------+-------------+--------------+-------------+| student |          0 | PRIMARY     |            1 | std_id      || student |          1 | idx_id_name |            1 | std_id      || student |          1 | idx_id_name |            2 | std_name    |+---------+------------+-------------+--------------+-------------+</code></pre><ul><li><code>alter table drop</code></li></ul><pre><code class="mysql">-- 删除主键索引，注意查看 Key 字段desc student;+----------+-------------+------+-----+---------+-------+| Field    | Type        | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+-------+| std_id   | int(11)     | NO   | PRI | NULL    |       || std_name | varchar(32) | YES  |     | NULL    |       |+----------+-------------+------+-----+---------+-------+alter table student drop primary key;Query OK, 3 rows affected (0.08 sec)desc student;+----------+-------------+------+-----+---------+-------+| Field    | Type        | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+-------+| std_id   | int(11)     | NO   | MUL | NULL    |       || std_name | varchar(32) | YES  |     | NULL    |       |+----------+-------------+------+-----+---------+-------+-- 删除索引（包含唯一索引），注意查看 Key 字段desc student;+----------+-------------+------+-----+---------+-------+| Field    | Type        | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+-------+| std_id   | int(11)     | NO   | PRI | NULL    |       || std_name | varchar(32) | YES  | MUL | NULL    |       |+----------+-------------+------+-----+---------+-------+alter table student drop index idx_stu_name;Query OK, 0 rows affected (0.03 sec)desc student;+----------+-------------+------+-----+---------+-------+| Field    | Type        | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+-------+| std_id   | int(11)     | NO   | PRI | NULL    |       || std_name | varchar(32) | YES  |     | NULL    |       |+----------+-------------+------+-----+---------+-------+</code></pre><hr><h5 id="Join-Search-Related"><a href="#Join-Search-Related" class="headerlink" title="Join Search Related"></a>Join Search Related</h5><table><thead><tr><th> 命令 </th><th> 含义 </th><th> 常用 </th></tr></thead><tbody><tr><td>join</td><td> 内链接（只查询两张表关联字段相等的记录）</td><td>select u.name, s.score from user u join score s on u.sid = s.id;</td></tr><tr><td>inner join</td><td> 内链接（只查询两张表关联字段相等的记录）</td><td>select u.name, s.score from user u inner join score s on u.sid = s.id;</td></tr><tr><td>left join</td><td> 左链接（以左表为主，两张表关联字段相等则显示右表数据，否则补 null）</td><td>select u.name, s.score from user u left join score s on u.sid = s.id;</td></tr><tr><td>left outer join</td><td> 左链接（以左表为主，两张表关联字段相等则显示右表数据，否则补 null）</td><td>select u.name, s.score from user u left outer join score s on u.sid = s.id;</td></tr><tr><td>right join</td><td> 右链接（以右表为主，两张表关联字段相等则显示左表数据，否则补 null）</td><td>select u.name, s.score from user u right join score s on u.sid = s.id;</td></tr><tr><td>right outer join</td><td> 右链接（以右表为主，两张表关联字段相等则显示左表数据，否则补 null）</td><td>select u.name, s.score from user u right outer join score s on u.sid = s.id;</td></tr><tr><td>full join</td><td> 全链接（将查询两张表的全部记录）</td><td>select u.name, s.score from user u full join score s on u.sid = s.id;</td></tr></tbody></table><ul><li> 准备数据 </li></ul><pre><code class="mysql">select * from user;+----+----------+| id | name     |+----+----------+| 1  | zhangsan || 2  | lisi     || 3  | wangwu   |+----+----------+select * from score;+----+-------+-----+| id | score | uid |+----+-------+-----+| 1  | 80    | 1   || 2  | 88    | 2   || 3  | 100   | 4   |+----+-------+-----+</code></pre><ul><li> 内链接 </li></ul><pre><code class="mysql">select u.name, s.score from `user` u join score s on u.id = s.uid;+----------+-------+| name     | score |+----------+-------+| zhangsan | 80    || lisi     | 88    |+----------+-------+select u.name, s.score from `user` u inner join score s on u.id = s.uid;+----------+-------+| name     | score |+----------+-------+| zhangsan | 80    || lisi     | 88    |+----------+-------+</code></pre><ul><li> 左链接 </li></ul><pre><code class="mysql">select u.name, s.score from`user`u left join score s on u.id = s.uid;+----------+--------+| name     | score  |+----------+--------+| zhangsan | 80     || lisi     | 88     || wangwu   | &lt;null&gt; |+----------+--------+select u.name, s.score from`user`u left outer join score s on u.id = s.uid;+----------+--------+| name     | score  |+----------+--------+| zhangsan | 80     || lisi     | 88     || wangwu   | &lt;null&gt; |+----------+--------+</code></pre><ul><li> 右链接 </li></ul><pre><code class="mysql">select u.name, s.score from `user` u right join score s on u.id = s.uid;+----------+-------+| name     | score |+----------+-------+| zhangsan | 80    || lisi     | 88    || &lt;null&gt;   | 100   |+----------+-------+select u.name, s.score from `user` u right outer join score s on u.id = s.uid;+----------+-------+| name     | score |+----------+-------+| zhangsan | 80    || lisi     | 88    || &lt;null&gt;   | 100   |+----------+-------+</code></pre><ul><li> 全链接 </li></ul><pre><code class="mysql">select u.name,s.score from `user` u left join score s on u.id = s.uid union select u.name, s.score from user u right join score s on u.id = s.uid;+----------+--------+| name     | score  |+----------+--------+| zhangsan | 80     || lisi     | 88     || wangwu   | &lt;null&gt; || &lt;null&gt;   | 100    |+----------+--------+</code></pre><p><strong>note</strong>: MySQL 不支持 full join 需要使用 union 方式代替 </p><hr><div aligh="center">    <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/MySQL- 故障恢复（一）/join-search.png" srcset="/img/loading.gif" width="100%"></div>]]></content>
    
    
    <categories>
      
      <category>MySQL</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>MySQL- 故障恢复（二）</title>
    <link href="/2020/03/11/MySQL-%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
    <url>/2020/03/11/MySQL-%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<center> <font face="黑体" size="6">MySQL 故障恢复方法（二）</font> </center><hr><a id="more"></a><h5 id="背景"><a href="# 背景" class="headerlink" title="背景"></a>背景</h5><ul><li>Master 192.168.0.1</li><li>Slave1 192.168.0.2</li><li>Slave2 192.168.0.3</li></ul><p>小明 11:00 接到告警通知，Master 节点出现异常，因为基于 MyCat 做了故障切换，目前服务应该可以正常 <br> 使用。因为此时 Slave1 节点可以负责读写工作。就在庆幸架构做的好时，接到用户反馈，线上服务已不可用<br>，排查后发现数据库被删。此时小明内心一万只草泥马飘过。</p><div aligh="center">    <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/MySQL- 故障恢复（一）/MySQL.png" srcset="/img/loading.gif" width="100%"></div><p><strong>note:</strong> 线上环境 MySQL 架构为一主两从，使用 MyCat 作为中间件配置读写分离。</p><hr><h5 id="解决方案"><a href="# 解决方案" class="headerlink" title="解决方案"></a>解决方案</h5><blockquote><p>因为此时是数据库被删，那么就不可以简单粗暴使用备份的方式解决了。我们需要使用 Binlog 日志到方式来 <br> 恢复数据。说干就干，步骤如下。</p></blockquote><ol><li><strong>停止 MyCat 防止数据写入</strong></li></ol><pre><code class="bash">$ mycat stop</code></pre><ol start="2"><li><strong>中断当前 Binlog</strong></li></ol><pre><code class="mysql">-- flush logs 命令会中断当前 binlog 文件写入，并新启一个 binlog 文件接收后续命令show master status \G;*************************** 1. row ***************************                     File: mysql-bin.000001                 Position: 439             Binlog_Do_DB: backup         Binlog_Ignore_DB:        Executed_Gtid_Set:flush logs;show master status \G;*************************** 1. row ***************************                     File: mysql-bin.000002                 Position: 154             Binlog_Do_DB: backup         Binlog_Ignore_DB:        Executed_Gtid_Set:</code></pre><ol start="3"><li><strong>查看备份文件 MASTER_LOG_POS 位置</strong></li></ol><pre><code class="bash"># 在备份 MySQL 时，一定要添加 `--master-data` 参数。$ more mysql-backup.sql...---- Position to start replication or point-in-time recovery from--CHANGE MASTER TO MASTER_LOG_FILE=&#39;mysql-bin.000001&#39;, MASTER_LOG_POS=1890;---- Table structure for table `user`--DROP TABLE IF EXISTS `user`;/*!40101 SET @saved_cs_client     = @@character_set_client */;/*!40101 SET character_set_client = utf8 */;CREATE TABLE `user` (`id` int(11) NOT NULL AUTO_INCREMENT,  `name` varchar(32) CHARACTER SET utf8 NOT NULL,  `age` varchar(32) CHARACTER SET utf8 NOT NULL,  `city` varchar(32) CHARACTER SET utf8 NOT NULL,  PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=14 DEFAULT CHARSET=latin1;/*!40101 SET character_set_client = @saved_cs_client */;...</code></pre><ol start="4"><li><strong>查看 Binlog 日志</strong></li></ol><pre><code class="mysql">-- 查看 binlog 信息show variables like &#39;%log_bin%&#39;;+---------------------------------+--------------------------------+| Variable_name                   | Value                          |+---------------------------------+--------------------------------+| log_bin                         | ON                             || log_bin_basename                | /var/lib/mysql/mysql-bin       || log_bin_index                   | /var/lib/mysql/mysql-bin.index || log_bin_trust_function_creators | OFF                            || log_bin_use_v1_row_events       | OFF                            || sql_log_bin                     | ON                             |+---------------------------------+--------------------------------+# 第一种方式，使用 show binlog 命令show binlog events in &#39;mysql-bin.000001&#39;\G;# 这里我们看到 drop databases backup 语句在 position 3047 开始位置...*************************** 44. row ***************************   Log_name: mysql-bin.000001        Pos: 2848 Event_type: Table_map  Server_id: 1End_log_pos: 2906       Info: table_id: 143 (backup.user)*************************** 45. row ***************************   Log_name: mysql-bin.000001        Pos: 2906 Event_type: Write_rows  Server_id: 1End_log_pos: 2951       Info: table_id: 143 flags: STMT_END_F*************************** 46. row ***************************   Log_name: mysql-bin.000001        Pos: 2951 Event_type: Xid  Server_id: 1End_log_pos: 2982       Info: COMMIT /* xid=808 */*************************** 47. row ***************************   Log_name: mysql-bin.000001        Pos: 2982 Event_type: Anonymous_Gtid  Server_id: 1End_log_pos: 3047       Info: SET @@SESSION.GTID_NEXT= &#39;ANONYMOUS&#39;*************************** 48. row ***************************   Log_name: mysql-bin.000001        Pos: 3047 Event_type: Query  Server_id: 1End_log_pos: 3145       Info: drop database backup...</code></pre><pre><code class="bash"># 第二种方式，查看 binlog 二进制文件。$ mysqlbinlog -v mysql-bin.000001# 主要查看 drop database backup 语句在 position 3047 开始...# at 2906#200313 14:03:59 server id 1  end_log_pos 2951 CRC32 0x17496f50         Write_rows: table id 143 flags: STMT_END_FBINLOG &#39;z5JrXhMBAAAAOgAAAFoLAAAAAI8AAAAAAAEABmJhY2t1cAAEdXNlcgAEAw8PDwZgAGAAYAAAj7jcTQ==z5JrXh4BAAAALQAAAIcLAAAAAI8AAAAAAAEAAgAE//ARAAAAAAI0MABQb0kX&#39;/*!*/;### INSERT INTO `backup`.`user`### SET###   @1=17###   @2=&#39;&#39;###   @3=&#39;40&#39;###   @4=&#39;&#39;# at 2951#200313 14:03:59 server id 1  end_log_pos 2982 CRC32 0x76e6e0db         Xid = 808COMMIT/*!*/;# at 2982#200313 14:04:38 server id 1  end_log_pos 3047 CRC32 0x00bc8281         Anonymous_GTID  last_committed=10       sequence_number=11      rbr_only=noSET @@SESSION.GTID_NEXT= &#39;ANONYMOUS&#39;/*!*/;# at 3047#200313 14:04:38 server id 1  end_log_pos 3145 CRC32 0xbc32a2d6         Query   thread_id=41    exec_time=0     error_code=0SET TIMESTAMP=1584108278/*!*/;SET @@session.pseudo_thread_id=41/*!*/;drop database backup/*!*/;# at 3145#200313 14:06:59 server id 1  end_log_pos 3192 CRC32 0x68a2c9ea         Rotate to mysql-bin.000002  pos: 4SET @@SESSION.GTID_NEXT= &#39;AUTOMATIC&#39; /* added by mysqlbinlog */ /*!*/;DELIMITER ;# End of log file/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/;...</code></pre><ol start="5"><li><p><strong>查找删除语句所在 position</strong></p><p><code>show binlog events in &#39;mysql-bin.000001&#39;\G;</code></p><div aligh="center">    <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/MySQL- 故障恢复（一）/pos1.png" srcset="/img/loading.gif" width="100%"></div><p><code>mysqlbinlog -v mysql-bin.000001</code></p> <div aligh="center">     <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/MySQL- 故障恢复（一）/pos1.png" srcset="/img/loading.gif" width="100%" "> </div></li><li><p><strong>创建数据库</strong></p></li></ol><pre><code class="mysql">-- Mastercreate database backup;show databases;+--------------------+| Database           |+--------------------+| information_schema || backup             || mysql              || performance_schema || sys                |+--------------------+-- Slave1、Slave2show databases;+--------------------+| Database           |+--------------------+| information_schema || backup             || mysql              || performance_schema || sys                |+--------------------+</code></pre><ol start="7"><li><strong>使用备份文件恢复数据</strong></li></ol><pre><code class="bash"># 指定数据库恢复，因为备份文件中可能有多个数据库$ mysql -uroot -p backup &lt; backup.sql</code></pre><pre><code class="mysql">-- 查看已恢复数据 Mastershow tables;+------------------+| Tables_in_backup |+------------------+| user             |+------------------+select * from user;+----+------+-----+------+| id | name | age | city |+----+------+-----+------+| 10 | 小黑 | 18  | N 市  || 11 | 小白 | 20  | N 市  || 12 | 小红 | 12  | X 市  || 13 | 小蓝 | 18  | X 市  |+----+------+-----+------+-- 查看已恢复数据 Slave1、Slave2show tables;+------------------+| Tables_in_backup |+------------------+| user             |+------------------+select * from user;+----+------+-----+------+| id | name | age | city |+----+------+-----+------+| 10 | 小黑 | 18  | N 市  || 11 | 小白 | 20  | N 市  || 12 | 小红 | 12  | X 市  || 13 | 小蓝 | 18  | X 市  |+----+------+-----+------+</code></pre><ol start="8"><li><strong>按照 Binlog 恢复到 position 之前位置</strong></li></ol><pre><code class="bash"># 首先我们需要记住备份文件中 MASTER_LOG_POS 位置 1890# 其次我们需要记住 binlog 日志中 drop 语句之前的 pos 位置 3047# 执行 mysqlbinlog 命令恢复数据，-d 指定数据库 --start-position 为备份文件中的pos 位置， --end-position 为 drop 语句前的 pos 位置。如果为报错则为执行成功$ mysqlbinlog -d backup --start-position 1890 --stop-position 3047 mysql-bin.000001 | mysql -uroot -p</code></pre><ol start="9"><li><strong>查询恢复数据</strong></li></ol><pre><code class="mysql">-- Masterselect * from user;+----+------+-----+------+| id | name | age | city |+----+------+-----+------+| 10 | 小黑 | 18  | N 市  || 11 | 小白 | 20  | N 市  || 12 | 小红 | 12  | X 市  || 13 | 小蓝 | 18  | X 市  || 14 | 小紫 | 13  | X 市  || 15 | 小粉 | 14  | z 市  || 16 | 小黄 | 22  | z 市  || 17 | 小绿 | 33  | z 市  |+----+------+-----+------+-- Slave1、Slave2select * from user;+----+------+-----+------+| id | name | age | city |+----+------+-----+------+| 10 | 小黑 | 18  | N 市  || 11 | 小白 | 20  | N 市  || 12 | 小红 | 12  | X 市  || 13 | 小蓝 | 18  | X 市  || 14 | 小紫 | 13  | X 市  || 15 | 小粉 | 14  | z 市  || 16 | 小黄 | 22  | z 市  || 17 | 小绿 | 33  | z 市  |+----+------+-----+------+</code></pre><ol start="10"><li><strong>开启 MyCat</strong></li></ol><pre><code class="bash">$ mycat start</code></pre><hr><h5 id="总结"><a href="# 总结" class="headerlink" title="总结"></a>总结</h5><ul><li>经过上面一系列到操作，最终恢复了数据和主从架构。这次我们使用了基于 binlog 二进制日志恢复数据的方法。这种方法操作上虽然会有复杂性，但是恢复数据的能力要比之前的暴力方式强得多。</li><li>当然，我们在日常数据库管理中，还是要按职能分配权限。不要以公司规模小、业务量不大、数据不多为接口给自己带来不必要的麻烦！</li></ul><div aligh="center">    <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/MySQL- 故障恢复（一）/over.png" srcset="/img/loading.gif" width="100%"></div>]]></content>
    
    
    <categories>
      
      <category>MySQL</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>MySQL- 故障恢复（一）</title>
    <link href="/2020/03/11/MySQL-%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <url>/2020/03/11/MySQL-%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<center> <font face="黑体" size="6">MySQL 故障恢复方法（一）</font> </center><hr><a id="more"></a><h5 id="背景"><a href="# 背景" class="headerlink" title="背景"></a>背景</h5><ul><li>Master 192.168.0.1</li><li>Slave1 192.168.0.2</li><li>Slave2 192.168.0.3</li></ul><p>小明 11:00 接到告警通知，Master 节点出现异常，因为基于 MyCat 做了故障切换，目前服务应该可以正常 <br> 使用。因为此时 Slave1 节点可以负责读写工作。半分钟后 Master 节点重启成功，MySQL 自动启动后，线上 <br> 服务开始报错，排查日志后发现，此时主从数据库数据已不同步，导致报错。</p><div aligh="center">    <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/MySQL- 故障恢复（一）/MySQL.png" srcset="/img/loading.gif" width="100%"></div><p><strong>note:</strong> 线上环境 MySQL 架构为一主两从，使用 MyCat 作为中间件配置读写分离。</p><hr><h5 id="解决方案"><a href="# 解决方案" class="headerlink" title="解决方案"></a>解决方案</h5><blockquote><p>因为此时只是数据不同步，那么可以确定的是，Slave1 节点的数据是最全的，那么简单粗暴使用备份的方式 <br> 恢复数据。说干就干，步骤如下。</p></blockquote><ol><li><strong>停止 MyCat 防止数据写入</strong></li></ol><pre><code class="bash">$ sh mycat stop</code></pre><ol start="2"><li><strong>停止主从复制</strong></li></ol><pre><code class="bash"># Slave1、Slave2mysql&gt; stop slave;mysql&gt; show slave status \G;*************************** 1. row ***************************               Slave_IO_State:                  Master_Host: 192.168.0.2                  Master_User: slave                  Master_Port: 3306                Connect_Retry: 60              Master_Log_File: mysql-bin.000002          Read_Master_Log_Pos: 2705               Relay_Log_File: 2af2354ad45b-relay-bin.000006                Relay_Log_Pos: 320        Relay_Master_Log_File: mysql-bin.000002             Slave_IO_Running: No            Slave_SQL_Running: No              Replicate_Do_DB: backup*************************** 1. row ***************************               Slave_IO_State:                  Master_Host: 192.168.0.3                  Master_User: slave                  Master_Port: 3306                Connect_Retry: 60              Master_Log_File: mysql-bin.000002          Read_Master_Log_Pos: 2705               Relay_Log_File: 2af2354ad45b-relay-bin.000006                Relay_Log_Pos: 320        Relay_Master_Log_File: mysql-bin.000002             Slave_IO_Running: No            Slave_SQL_Running: No              Replicate_Do_DB: backup</code></pre><ol start="3"><li><strong>重置主从关系</strong></li></ol><pre><code class="bash"># Mastermysql&gt; resrt master;mysql&gt; show master status \G;*************************** 1. row ***************************                         File: mysql-bin.000001                     Position: 154                 Binlog_Do_DB: backup             Binlog_Ignore_DB:            Executed_Gtid_Set:# Slave1、Slave2mysql&gt; reset slave;mysql&gt; show slave status \G;*************************** 1. row ***************************               Slave_IO_State:                  Master_Host: 192.168.0.2                  Master_User: slave                  Master_Port: 3306                Connect_Retry: 60              Master_Log_File:          Read_Master_Log_Pos: 4               Relay_Log_File: 2af2354ad45b-relay-bin.000001                Relay_Log_Pos: 4        Relay_Master_Log_File:             Slave_IO_Running: No            Slave_SQL_Running: No              Replicate_Do_DB: backup*************************** 1. row ***************************               Slave_IO_State:                  Master_Host: 192.168.0.3                  Master_User: slave                  Master_Port: 3306                Connect_Retry: 60              Master_Log_File:          Read_Master_Log_Pos: 4               Relay_Log_File: 2af2354ad45b-relay-bin.000001                Relay_Log_Pos: 4        Relay_Master_Log_File:             Slave_IO_Running: No            Slave_SQL_Running: No              Replicate_Do_DB: backup</code></pre><ol start="4"><li><strong>导出 Slave1 数据</strong></li></ol><pre><code class="bash"># 导出 backup 库$ mysqldump -uroot -p backup &gt; backup.sql# 拷贝到 Master 服务器$ scp backup.sql root@192.168.0.1:/mysql</code></pre><ol start="5"><li><strong>导入 Master 库</strong></li></ol><pre><code class="bash"># 删除数据库mysql&gt; drop database backup;# 创建数据库mysql&gt; create database backup;# 导入数据$ mysql -uroot -p backup &lt; backup.sql</code></pre><ol start="6"><li><strong>重新配置主从关系</strong></li></ol><pre><code class="bash"># Slave1、Slave2mysql&gt; change master to       master_host=&#39;192.168.0.1&#39;,       master_port=3306,       master_user=&#39;slave&#39;,       master_password=&#39;slave123&#39;,       master_log_file=&#39;mysql-bin.000001&#39;       master_log_pos=154;</code></pre><ol start="7"><li><strong>开启主从</strong></li></ol><pre><code class="bash"># Salve1、Slave2mysql&gt; start slave;mysql&gt; show slave status \G;*************************** 1. row ***************************               Slave_IO_State: Waiting for master to send event                  Master_Host: 192.168.0.2                  Master_User: slave                  Master_Port: 3306                Connect_Retry: 60              Master_Log_File: mysql-bin.000001          Read_Master_Log_Pos: 154               Relay_Log_File: 2af2354ad45b-relay-bin.000003                Relay_Log_Pos: 367        Relay_Master_Log_File: mysql-bin.000001             Slave_IO_Running: Yes            Slave_SQL_Running: Yes              Replicate_Do_DB: backup*************************** 1. row ***************************               Slave_IO_State: Waiting for master to send event                  Master_Host: 192.168.0.3                  Master_User: slave                  Master_Port: 3306                Connect_Retry: 60              Master_Log_File: mysql-bin.000001          Read_Master_Log_Pos: 154               Relay_Log_File: 2af2354ad45b-relay-bin.000003                Relay_Log_Pos: 367        Relay_Master_Log_File: mysql-bin.000001             Slave_IO_Running: Yes            Slave_SQL_Running: Yes              Replicate_Do_DB: backup</code></pre><ol start="8"><li><strong>开启 MyCat</strong></li></ol><pre><code class="bash">$ mycat start</code></pre><hr><h5 id="总结"><a href="# 总结" class="headerlink" title="总结"></a>总结 </h5><p> 经过上面一系列到操作，最终恢复了数据和主从架构。虽然此方法可以恢复数据，但是前提是至少有一台 MySQL 节 <br> 点数据是未丢失到，只有满足这个前提，才能使用这种简单粗暴到方法。</p><div aligh="center">    <img src="/.com//wangliang/Documents/ 王亮 /blog/source/_posts/MySQL- 故障恢复（一）/over.png" srcset="/img/loading.gif" width="100%"></div>]]></content>
    
    
    <categories>
      
      <category>MySQL</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>CAS</title>
    <link href="/2020/03/10/CAS/"/>
    <url>/2020/03/10/CAS/</url>
    
    <content type="html"><![CDATA[<p><strong>Compare And Swap</strong></p><a id="more"></a><h5 id="背景"><a href="# 背景" class="headerlink" title="背景"></a>背景</h5><p>Java 在 1.4 版本后，提供了 JUC 下面的很多并发工具类，我们常使用的如下：</p><ol><li>AtomicInteger</li><li>AtomicLong</li><li>AtmoicReference</li></ol><p>那么在使用这些原子工具类来确保并发安全的背后，究竟是什么操作，代替了原有的 Sync 重量锁操作呢？<strong>CAS Java Util Current</strong> 背后的男人。</p><h5 id="CAS- 概念"><a href="#CAS- 概念" class="headerlink" title="CAS 概念"></a>CAS 概念</h5><blockquote><p>Cas 是 Compare And Swap 的简称，他的出现主要是解决了并发操作时，使用 Sync 锁而产生的效率问题，同时他的实现也是乐观锁的一种方式。</p></blockquote><h5 id="L1- 缓存概念"><a href="#L1- 缓存概念" class="headerlink" title="L1 缓存概念"></a>L1 缓存概念</h5><blockquote><p>L1 缓存是为了提高线程每次直接从主内存读写变量的速度而开发的逻辑缓存单元，各线程 L1 中的数据是独享的。有些处理器还提供了 L2 工作缓存</p></blockquote><h5 id="并发问题"><a href="# 并发问题" class="headerlink" title="并发问题"></a>并发问题 </h5><p> 在没有 CAS 出现之前，我们在并发操作一个共享变量的时候，步骤如下：</p><blockquote><p>假设目前有两个线程（T1、T2），同时对内存中的共享变量 x 其值为 0 变量做 +1 操作</p></blockquote><ol><li>线程 T1 从主内存读取变量 x 值，同时将 x 加入到 L1 缓存</li><li>线程 T2 从主内存读取变量 x 值，同时将 x 加入到 L1 缓存</li><li>线程 T1 对 x 做 +1 操作，此时 x 值为 1，并将其写入到 L1 缓存中</li><li>线程 T2 对 x 做 +1 操作，此时 x 值为 1，并将其写入到 L1 缓存中</li><li>线程 T1 将 L1 缓存中的 x 写入到主内存（此时主内存的 x 值为 1）</li><li>线程 T2 将 L1 缓存中的 x 写入到主内存（此时主内存的 x 值为 1）</li></ol><blockquote><p>经过如上步骤我们发现，最终主内存中的 x 并不符合我们预期对值 2，而这就是并发安全问题。<br>解决上述问题，以往我们会对操作 x 的方法添加 Sync 关键字，使该方法加锁来解决此类问题。<br>但是锁的消耗是巨大的，为了这么小的一个改变，而对方法加锁，是不值得的。为此 CAS 诞生。</p></blockquote><h5 id="CAS- 解决方式"><a href="#CAS- 解决方式" class="headerlink" title="CAS 解决方式"></a>CAS 解决方式 </h5><p> 我们来看一下 CAS 如何解决上述问题:</p><blockquote><p>假设目前有两个线程（T1、T2），同时对内存中的共享变量 x 其值为 0 变量做 +1 操作</p></blockquote><ol><li>线程 T1 从主内存读取变量 x 值，同时将 x 加入到 L1 缓存</li><li>线程 T2 从主内存读取变量 x 值，同时将 x 加入到 L1 缓存</li><li>线程 T1 对 x 做 +1 操作，此时 x 值为 1，并将其写入到 L1 缓存中</li><li>线程 T2 对 x 做 +1 操作，此时 x 值为 1，并将其写入到 L1 缓存中</li><li>线程 T1 将 L1 缓存中的 x 写入到主内存，在写入之前会再次从主内存中拿到 x 的值，并与开始获取到的 x 值做对比，<br>发现相等，然后写入 x 值到主内存（此时主内存的 x 值为 1）</li><li>线程 T2 将 L1 缓存中的 x 写入到主内存，在写入之前会再次从主内存中拿到 x 的值，并与开始获取到的 x 值做对比,<br>发现不等，此时 T2 线程不会将 x 值写入到主内存，而是返回到第一步操作，读取主内存中 x 的值，并对其做 +1 操作，<br>然后再次判断主内存中当前 x 与开始获取到的 x 做对比（此时 x 为 1），直到相等后，然后写入 x 值到主内存（此时主内存的 x 值为 2）</li></ol><blockquote><p>以上便是 CAS 操作到步骤，在与之前线程直接将 x 值协会主内存中不同，CAS 此时会做一个对比，将开始获取到到 x 与当前 <br> 主内存的 x 做对比，如果一致则写入主内存，如果不一致则回到获取 x 值的步骤重新执行，直至 x 对比一致后写入主内存</p></blockquote><h5 id="CAS- 流程图如下"><a href="#CAS- 流程图如下" class="headerlink" title="CAS 流程图如下"></a>CAS 流程图如下 </h5><h5 id="ABA- 问题（对象引用）"><a href="#ABA- 问题（对象引用）" class="headerlink" title="ABA 问题（对象引用）"></a>ABA 问题（对象引用）</h5><h5 id="乐观锁"><a href="# 乐观锁" class="headerlink" title="乐观锁"></a> 乐观锁</h5>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Dockerfile 使用</title>
    <link href="/2020/03/03/Dockerfile/"/>
    <url>/2020/03/03/Dockerfile/</url>
    
    <content type="html"><![CDATA[<p><strong>Dockerfile</strong> 使用 </p><a id="more"></a><h5 id="Dockerfile- 常用命令"><a href="#Dockerfile- 常用命令" class="headerlink" title="Dockerfile 常用命令"></a>Dockerfile 常用命令 </h5><table><thead><tr><th align="center"> 命令 </th><th align="center"> 备注 </th><th align="center"> 是否必填 </th></tr></thead><tbody><tr><td align="center">FROM</td><td align="center"> 基础镜像 </td><td align="center"> 必填 </td></tr><tr><td align="center">ADD</td><td align="center"> 拷贝文件到容器中（文件可以为 URL 链接）</td><td align="center"> 不必填 </td></tr><tr><td align="center">COPY</td><td align="center"> 拷贝文件到容器中（文件只能是本地文件）</td><td align="center"> 不必填 </td></tr><tr><td align="center">WORKDIR</td><td align="center"> 切换工作目录到指定目录 </td><td align="center"> 不必填 </td></tr><tr><td align="center">RUN</td><td align="center"> 镜像构建时运行脚本命令 </td><td align="center"> 不必填 </td></tr><tr><td align="center">CMD</td><td align="center"> 镜像构建后，启动容器时运行脚本命令 </td><td align="center"> 不必填 </td></tr><tr><td align="center">ENTRYPOINT</td><td align="center"> 镜像构建后，启动容器时运行脚本命令 </td><td align="center"> 不必填 </td></tr><tr><td align="center">ONBUILE</td><td align="center"> 在当前 Dockerfile 中不执行，在子镜像中会的 FROM 命令后执行 </td><td align="center"> 不必填 </td></tr><tr><td align="center">ENV</td><td align="center"> 设置环境变量，容器启动后依然存在 </td><td align="center"> 不必填 </td></tr><tr><td align="center">ARG</td><td align="center"> 设置变量参数，只在容器构建时存在 </td><td align="center"> 不必填 </td></tr><tr><td align="center">SHELL</td><td align="center"> 执行 SHELL 脚本 </td><td align="center"> 不必填 </td></tr><tr><td align="center">MAINTAINER</td><td align="center"> 维护人信息 </td><td align="center"> 不必填 </td></tr><tr><td align="center">LABEL</td><td align="center">key-value 形式标签，没有实质作用 </td><td align="center"> 不必填 </td></tr><tr><td align="center">EXPOSE</td><td align="center"> 暴露容器内端口 </td><td align="center"> 不必填 </td></tr><tr><td align="center">USER</td><td align="center">RUN、CMD、ENTRYPOINT 执行 Shell 命令时指定用户，默认 root</td><td align="center"> 不必填 </td></tr><tr><td align="center">VOLUME</td><td align="center"> 挂在主机目录到容器 </td><td align="center"> 不必填 </td></tr><tr><td align="center">HEALTHCHECK</td><td align="center"> 告诉 Docker 如何测试容器以检查它是否仍在工作，健康检查 </td><td align="center"> 不必填 </td></tr></tbody></table><h5 id="命令示例"><a href="# 命令示例" class="headerlink" title="命令示例"></a> 命令示例 </h5><ul><li><p><strong>FROM</strong></p><pre><code class="dockerfile"># Dockerfile 基于 centos 为基础镜像构建FROM centos</code></pre></li></ul><ul><li><p><strong>MAINTAINER</strong></p><pre><code class="dockerfile"># 维护者信息MAINTAINER Raindrop &lt;727474430@qq.com&gt;</code></pre></li></ul><ul><li><p><strong>LABEL</strong></p><pre><code class="dockerfile"># 标签，一般可用来替代 MAINTAINERLABEL maintainer=Raindrop email=727474430@qq.com</code></pre></li></ul><ul><li><p><strong>ARG</strong></p><pre><code class="dockerfile"># 环境变量，构建镜像时有效ARG SERVICE_NAME TomcatRUN echo $SERVICE_NAME# 可在构建时传入变量docker build -t --build-arg SERVICE_NAME=Weblogic .</code></pre></li></ul><ul><li><p><strong>ENV</strong></p><pre><code class="dockerfile"># 环境变量，容器启动后依然有效ENV JAVA_HOME /usr/local/jdk1.8RUN echo $JAVA_HOME</code></pre></li></ul><ul><li><p><strong>ADD</strong></p><pre><code class="dockerfile"># 拷贝文件到容器中，可拷贝网络资源ADD index.html /var/www/htmlADD https://www.baidu.com/index.html /var/www/html</code></pre></li></ul><ul><li><p><strong>COPY</strong></p><pre><code class="dockerfile"># 拷贝文件到容器中，只能拷贝本地资源，不拷贝网络资源时，建议使用COPY index.html /var/www/htmlCOPY app.jar /app</code></pre></li></ul><ul><li><p><strong>WORKDIR</strong></p><pre><code class="dockerfile"># 切入工作目录，类似 cdWORKDIR /appWORKDIR /tomcat</code></pre></li></ul><ul><li><p><strong>RUN</strong></p><pre><code class="dockerfile"># 构建镜像时执行的 shellRUN [&quot;yum&quot;, &quot;install&quot;, &quot;httpd&quot;]RUN yum install httpd</code></pre></li></ul><ul><li><p><strong>CMD</strong></p><pre><code class="dockerfile"># 启动容器时执行的 shellCMD [&quot;-C&quot;, &quot;/run.sh&quot;]CMD [&quot;/usr/sbin/sshd&quot;, &quot;-D&quot;]CMD /usr/sbin/sshd -D</code></pre></li></ul><ul><li><p><strong>ENTRYPOINT</strong></p><pre><code class="dockerfile"># 启动容器时执行的 shell，同 CMD 类似，只是由 ENTRYPOINT 启动的程序不会被 docker run 命令行指定的参数所覆盖，而且，这些命令行参数会被当作参数传递给 ENTRYPOINT 指定指定的程序ENTRYPOINT [&quot;/bin/bash&quot;, &quot;-C&quot;, &quot;/start.sh&quot;]ENTRYPOINT /bin/bash -C &#39;/start.sh&#39;</code></pre></li></ul><ul><li><p><strong>EXPOSE</strong></p><pre><code class="dockerfile"># 暴露端口EXPOSE 80 443</code></pre></li></ul><ul><li><p><strong>USER</strong></p><pre><code class="dockerfile"># RUN、CMD、ENTRYPOINT 执行 shell 命令指定用户，默认 rootUSER &lt;user&gt;[:&lt;usergroup&gt;]USER &lt;UID&gt;[:&lt;UID&gt;]USER weblogic:weblogic</code></pre></li></ul><ul><li><p><strong>VOLUME</strong></p><pre><code class="dockerfile"># 挂载容器目录之本地VOLUME [&quot;/var/lib/mysql&quot;]VOLUME /usr/lib/mysql /var/lib/mysql</code></pre></li></ul><ul><li><p><strong>ONBUILE</strong></p><pre><code class="dockerfile"># 子容器 FROM 后执行，通常用于构建基础镜像时预先添加内容，在子镜像中依赖，以减轻镜像容量FROM alpineONBUILD ENV APP_NAME=TomcatCMD echo $APP_NAMEdocker build -t test .---# 若不指定 CMD 和 ENTRYPOINT 默认执行父镜像指令，若父镜像也没有 CMD 和 ENTRYPOINT 则报错FROM test</code></pre></li></ul><ul><li><p><strong>HEALTHCHECK</strong></p><pre><code class="dockerfile"># 健康检查HEALTHCHECK --interval=5m --timeout=3s --retries=3 \    CMD curl -f http:/localhost/ || exit 1# 含义-- interval=DURATION (default: 30s)：每隔多长时间探测一次，默认 30 秒-- timeout= DURATION (default: 30s)：服务响应超时时长，默认 30 秒-- start-period= DURATION (default: 0s)：服务启动多久后开始探测，默认 0 秒-- retries=N (default: 3)：认为检测失败几次为宕机，默认 3 次# 一些返回值的说明：0：容器成功是健康的，随时可以使用1：不健康的容器无法正常工作2：保留不使用此退出代码 </code></pre></li></ul><h5 id="Dockerfile 示例"><a href="#Dockerfile 示例" class="headerlink" title="Dockerfile 示例"></a>Dockerfile 示例 </h5><ul><li><p> 构建 centos 镜像 </p><pre><code class="dockerfile"># 基础镜像FROM centos# 维护人信息MAINTAINER Raindrop &lt;727474430@qq.com&gt;# 构建时运行命令RUN yum -y update &amp;&amp; yum -y install httpd# 暴露 80 端口EXPOSE 80# 复制 index.html 到指定地址COPY index.html /var/www/html/index.html# 切换工作目录WORKDIR /var/www/html/index.html# 设置环境变量ENV SHELL_NAME=&quot;run.sh&quot;# 复制该脚本至镜像中，并修改其权限ADD $SHELL_NAME /run.shRUN chmod 775 /run.sh# 容器启动时执行脚本文件CMD [&quot;/run.sh&quot;]</code></pre></li></ul><p><img src="/.com//Dockerfile.png" srcset="/img/loading.gif" alt="img"></p>]]></content>
    
    
    <categories>
      
      <category>docker</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Curl 常用命令</title>
    <link href="/2020/02/16/Curl/"/>
    <url>/2020/02/16/Curl/</url>
    
    <content type="html"><![CDATA[<p><strong>Curl</strong> 日常命令 </p><a id="more"></a><h5 id="参数列表"><a href="# 参数列表" class="headerlink" title="参数列表"></a> 参数列表 </h5><table><thead><tr><th> 参数 </th><th> 含义 </th><th> 用法 </th></tr></thead><tbody><tr><td>-s</td><td> 去掉进度条 </td><td>curl 127.0.0.1:80 -s</td></tr><tr><td>-o</td><td> 指定结果写入文件 </td><td>curl 127.0.0.1:80 -o curl.txt</td></tr><tr><td>-d</td><td> 指定参数 body</td><td>curl 127.0.0.1:80 -d ‘foo=bar’</td></tr><tr><td>-H</td><td> 指定请求头 </td><td>curl 127.0.0.1:80 -H ‘Content-Type:application/json’</td></tr><tr><td>-X</td><td> 指定请求方法 </td><td>curl 127.0.0.1:80 -X POST -H -H ‘Content-Type:application/json’ -d ‘{“foo”:”bar”}’</td></tr><tr><td></td><td></td><td></td></tr></tbody></table><h5 id="s"><a href="#s" class="headerlink" title="-s"></a>-s</h5><pre><code class="bash">$ curl https://www.baidu.com -o baidu.txt$ curl https://www.baidu.com -o baidu.txt -s</code></pre><p><img src="/.com//curl-s.png" srcset="/img/loading.gif" alt="curl-s"></p><h5 id="o"><a href="#o" class="headerlink" title="-o"></a>-o</h5><pre><code class="bash">$ curl https://www.baidu.com -o baidu.txt$ ll baidu.txt$ cat baidu.txt</code></pre><p><img src="/.com//curl-o(1).png" srcset="/img/loading.gif" alt="curl-o"></p><p><img src="/.com//curl-o(2).png" srcset="/img/loading.gif" alt="curl-o"></p><h5 id="d"><a href="#d" class="headerlink" title="-d"></a>-d</h5><pre><code class="bash">$ curl http://localhost:8888 -d &quot;age=18&quot;</code></pre><p><img src="/.com//curl-d.png" srcset="/img/loading.gif" alt="curl-d"></p><h5 id="H"><a href="#H" class="headerlink" title="-H"></a>-H</h5><pre><code class="bash">$ curl http://localhost:8888 -H &quot;Content-Type:application/json&quot;$ curl http://localhost:8888 -H &quot;foo:bar&quot;</code></pre><p><img src="/.com//curl-h(1).png" srcset="/img/loading.gif" alt="curl-h(1)"></p><p><img src="/.com//curl-h(2).png" srcset="/img/loading.gif" alt="curl-h(2)"></p><h5 id="X"><a href="#X" class="headerlink" title="-X"></a>-X</h5><pre><code class="bash">curl http://localhost:8888\?name\=wl -H &quot;Content-Type:application/json&quot; -X POST  -d &quot;{\&quot;age\&quot;:24}&quot;</code></pre><p><img src="/.com//curl-x.png" srcset="/img/loading.gif" alt="curl-x"></p>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Docker Jenkins Develop Springboot</title>
    <link href="/2019/12/25/Docker%20Jenkins%20Develop%20Springboot/"/>
    <url>/2019/12/25/Docker%20Jenkins%20Develop%20Springboot/</url>
    
    <content type="html"><![CDATA[<p><strong>Jenkins Deployment Nginx And SpringBoot Instance</strong></p><a id="more"></a><p><strong>需求:</strong><br>  由于公司项目的不断增加，新需求不断的增加，导致每部署一次项目都是一次折磨（项目打包、jar 包上传、启动、监控日志…）。所以决定通过以 Jenkins 持续集成的方式，部署公司项目（Nginx 前端、Tomcat 后端）。</p><p><strong>方案</strong><br>  在本次搭建中我们将基于 Centos7.2 + Docker 来实现需求。主要是在 Docker 中部署 Jenkins，挂在宿主机 Jdk、Maven、Nginx、Jenkins_home，在容器中进行 Jenkins 相关配置管理。</p><p><strong>实现</strong>  </p><ul><li><p>Setp 1: Jdk1.8</p><pre><code class="bash"># 下载并安装 jdk1.8$ mkdir /usr/local/jdk1.8$ wget http://download.oracle.com/otn-pub/java/jdk/8u161-b12/2f38c3b165be4555a1fa6e98c45e0808/jdk-8u161-linux-x64.tar.gz &amp;&amp; tar -zxvf jdk-8u161-linux-x64.tar.gz /usr/local/jdk1.8# 配置环境变量$ vim /etc/profileexport JAVA_HOME=/usr/local/jdk1.8export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.java:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport PATH=$PATH:$JAVA_HOME/bin$ source /etc/profile# 运行 java -version 验证安装是否成功$ java -version</code></pre></li><li><p>Setp 2: Maven3.5</p><pre><code class="bash"># 下载并安装 maven3.5$ mkdir /usr/local/maven3.5$ wget http://mirrors.tuna.tsinghua.edu.cn/apache/maven/maven-3/3.6.0/binaries/apache-maven-3.6.0-bin.tar.gz &amp;&amp; tar -zxvf apache-maven-3.6.0-bin.tar.gz /usr/local/maven3.5# 配置环境变量$ vim /etc/profileexport M2_HOME=/usr/local/maven3.5export PATH=$PATH:$M2_HOME/bin# 运行 mvn -v 验证是否安装成功$ mvn -v</code></pre></li><li><p>Setp 3: Nginx1.14</p><pre><code class="bash"># 下载并安装 nginx$ wget -c https://nginx.org/download/nginx-1.14.0.tar.gz &amp;&amp; tar -zxvf nginx-1.14.0.tar.gz# 编译安装$ cd nginx-1.14.0 &amp;&amp; ./configure$ make &amp;&amp; make install# 查看安装路径$ whereis nginx# 启动 nginx、停止、退出、重启$ cd /usr/local/nginx/sbin$ ./nginx $ ./nginx -s stop$ ./nginx -s quit$ ./nginx -s reload# 配置开机启动$ vi /etc/rc.loca# 在最后一行添加$ /usr/local/nginx/sbin/nginx# 配置权限$ chmod 755 rc.local</code></pre></li><li><p>Setp 4: DockerCe</p><pre><code class="bash"># 安装依赖$ sudo yum install -y yum-utils \ device-mapper-persistent-data \ lvm2# 添加 repo 源$ sudo yum-config-manager \ --add-repo https://download.docker.com/linux/centos/docker-ce.repo# 安装 dockerce$ sudo yum-config-manager --enable docker-ce-edge$ sudo yum-config-manager --enable docker-ce-test$ sudo yum install docker-ce# 启动 docker、启动容器$ sudo systemctl start docker$ sudo docker run hello-world</code></pre></li><li><p>Setp 5: Docker 镜像拉取并启动容器</p><pre><code class="bash"># 拉取镜像$ docker pull jenkins/jenkins:lts# 启动容器同时挂载所需文件$ docker run -d \ --name my_jenkins \ -v /usr/local/jdk1.8:/usr/local/jdk1.8 \ -v /usr/local/maven3.5:/usr/local/maven3.5 \ -v /home/jenkins_home:/var/jenkins_home \ -p 8080 \ jenkins/jenkins:lts# 查看容器启动日志，获取 jenkins 初始密码$ docker logs -f containerId</code></pre><p><img src="http://qiniu.raindrop-wl.cn/jenkins_init_pass.jpg" srcset="/img/loading.gif" alt="jenkins_init_pass"></p></li><li><p>Setp 6: Jenkins 配置 <br> 登录 Jenkins，访问宿主机 8080 端口，第一次登录需要初始密码，就是我们上一步获取的密码。<br><img src="http://qiniu.raindrop-wl.cn/jenkins_login.jpg" srcset="/img/loading.gif" alt="jenkins_login"></p><p>选择安装推荐的插件即可<br><img src="http://qiniu.raindrop-wl.cn/jenkins_init_plugin.jpg" srcset="/img/loading.gif" alt="jenkins_init_plugin"></p><p>安装好插件以后，我们可以配置一个用户作为以后登录 Jenkins 的用户，这里就不做过多介绍了。</p></li><li><p>Setp 7: Jenkins 环境、任务配置 <br> 安装所需插件，Maven Integration Plugin、Nodejs、Publish Over SSH、Subversion、Ding<br><img src="http://qiniu.raindrop-wl.cn/jenkins_plugin_maven.png" srcset="/img/loading.gif" alt="jenkins_plugin_maven"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_plugin_nodejs.png" srcset="/img/loading.gif" alt="jenkins_plugin_nodejs"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_plugin_ssh.png" srcset="/img/loading.gif" alt="jenkins_plugin_ssh"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_plugin_svn.png" srcset="/img/loading.gif" alt="jenkins_plugin_svn"></p><p>服务器配置 Publish over ssh<br><img src="http://qiniu.raindrop-wl.cn/jenkins_config.png" srcset="/img/loading.gif" alt="jenkins_config"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_ssh_01.png" srcset="/img/loading.gif" alt="jenkins_ssh_01"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_ssh_02.png" srcset="/img/loading.gif" alt="jenkins_ssh_02"></p><p>配置 jdk、maven、nodejs，按照以下步骤来操作.<br><img src="http://qiniu.raindrop-wl.cn/jenkins_sys_config.png" srcset="/img/loading.gif" alt="jenkins_sys_config"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_sys_jdk.png" srcset="/img/loading.gif" alt="jenkins_sys_jdk"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_sys_maven.png" srcset="/img/loading.gif" alt="jenkins_sys_maven"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_sys_nodejs.png" srcset="/img/loading.gif" alt="jenkins_sys_nodejs"></p></li><li><p>Setp 8: 基础环境配置好了，下面我们开始正式配置前端任务，后端任务<br><img src="http://qiniu.raindrop-wl.cn/jenkins_project_web_01.png" srcset="/img/loading.gif" alt="jenkins_project_web_01"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_project_web_02.png" srcset="/img/loading.gif" alt="jenkins_project_web_02"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_project_web_03.png" srcset="/img/loading.gif" alt="jenkins_project_web_03"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_project_web_04.png" srcset="/img/loading.gif" alt="jenkins_project_web_04"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_project_web_05.png" srcset="/img/loading.gif" alt="jenkins_project_web_05"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_project_web_06.png" srcset="/img/loading.gif" alt="jenkins_project_web_06"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_project_web_07.png" srcset="/img/loading.gif" alt="jenkins_project_web_07"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_project_web_08.png" srcset="/img/loading.gif" alt="jenkins_project_web_08"></p><pre><code class="bash">#!/bin/bash -lDATE=$(date +%Y%m%d)TARFILE=tb-cams-web.tar.gzWORKSPACE=/home/webapps/tb-camsDISTFILE=$WORKSPACE/distBACKUP=$WORKSPACE/backupTMP=$WORKSPACE/tmpcd $WORKSPACEif [! -d $BACKUP];thenecho &quot;backup directory does not exists, new backup directory&quot;mkdir $BACKUPfiif [! -d $DISTFILE];thenecho &quot;dist directory does not exists, new dist directory&quot;mkdir $DISTFILEfimv $DISTFILE/$TARFILE $BACKUP/$TARFILE.$DATEmv $TMP/$TARFILE $DISTFILE/cd $DISTFILE &amp;&amp; tar -zxvf $TARFILEecho &quot;Cams web deploy success&quot;</code></pre></li><li><p>后端<br><img src="http://qiniu.raindrop-wl.cn/jenkins_project_admin_01.png" srcset="/img/loading.gif" alt="jenkins_project_admin_01"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_project_admin_02.png" srcset="/img/loading.gif" alt="jenkins_project_admin_02"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_project_admin_03.png" srcset="/img/loading.gif" alt="jenkins_project_admin_03"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_project_admin_04.png" srcset="/img/loading.gif" alt="jenkins_project_admin_04"><br><img src="http://qiniu.raindrop-wl.cn/jenkins_project_admin_05.png" srcset="/img/loading.gif" alt="jenkins_project_admin_05"></p><pre><code class="bash">#!/bin/bash -lDATE=$(date +%Y%m%d)WARFILE=tb-cams.warWORKSPACE=/home/webapps/tb-camsLOGFILE=$WORKSPACE/logsBACKUP=$WORKSPACE/backupcd $WORKSPACEif [! -d $BACKUP];thenecho &quot;backup directory does not exists, new backup directory&quot;mkdir $BACKUPfiif [! -d $LOGFILE];thenecho &quot;logs directory does not exists, new logs directory&quot;mkdir $LOGFILEfiPID=$(ps -ef | grep $WARFILE | grep -v grep | awk &#39;{print $2}&#39;)if [-z &quot;$PID&quot;];thenecho &quot;$WARFILE is not started&quot;elseecho &quot;$WARFILE is a startup task, kill process $PID&quot;kill -9 $PIDfimv $WARFILE $BACKUP/$WARFILE.$DATEmv $WORKSPACE/tmp/$WARFILE .rm -rf $WORKSPACE/tmp/$WARFILEjava -jar $WARFILE --spring.profiles.active=stg &gt; logs/cams.log &amp;</code></pre></li></ul>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
      <category>Docker</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Spring Boot Kotlin Jwt Token</title>
    <link href="/2019/04/06/SpringBood-Kotlin-Token/"/>
    <url>/2019/04/06/SpringBood-Kotlin-Token/</url>
    
    <content type="html"><![CDATA[<p><strong>Spring Boot Kotlin Jwt Token</strong></p><a id="more"></a><h3 id="本篇记录了，基于 Spring-Boot、Kotlin、Jwt 的 Token 接口认证功能的项目内容"><a href="# 本篇记录了，基于 Spring-Boot、Kotlin、Jwt 的 Token 接口认证功能的项目内容" class="headerlink" title="本篇记录了，基于 Spring Boot、Kotlin、Jwt 的 Token 接口认证功能的项目内容"></a>本篇记录了，基于 Spring Boot、Kotlin、Jwt 的 Token 接口认证功能的项目内容 </h3><p>  <strong> 环境如下</strong></p><table><thead><tr><th align="center">Plugin</th><th align="center">Version</th></tr></thead><tbody><tr><td align="center">SpringBoot</td><td align="center">2.0.8.RELEASE</td></tr><tr><td align="center">Kotlin</td><td align="center">1.2.71</td></tr><tr><td align="center">Java-Jwt</td><td align="center">3.3</td></tr></tbody></table><h3 id="时序图"><a href="# 时序图" class="headerlink" title="时序图"></a>时序图</h3><p>  <img src="http://qiniu.raindrop-wl.cn/kotlin-jwt.png" srcset="/img/loading.gif" alt="kotlin-jwt"></p><h3 id="项目配置"><a href="# 项目配置" class="headerlink" title="项目配置"></a>项目配置</h3><ul><li><p>Maven 依赖如下:</p><pre><code class="xml">&lt;!-- Spring Boot --&gt;&lt;parent&gt;&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&lt;version&gt;2.0.8.RELEASE&lt;/version&gt;&lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt;&lt;properties&gt;    &lt;java.version&gt;1.8&lt;/java.version&gt;    &lt;kotlin.version&gt;1.2.71&lt;/kotlin.version&gt;&lt;/properties&gt;&lt;dependencies&gt;    &lt;!-- Web --&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;!-- Jwt --&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.auth0&lt;/groupId&gt;        &lt;artifactId&gt;java-jwt&lt;/artifactId&gt;        &lt;version&gt;3.3.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;!-- FastJson --&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.alibaba&lt;/groupId&gt;        &lt;artifactId&gt;fastjson&lt;/artifactId&gt;        &lt;version&gt;1.2.49&lt;/version&gt;    &lt;/dependency&gt;    &lt;!-- Kotlin --&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.fasterxml.jackson.module&lt;/groupId&gt;        &lt;artifactId&gt;jackson-module-kotlin&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.jetbrains.kotlin&lt;/groupId&gt;        &lt;artifactId&gt;kotlin-reflect&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.jetbrains.kotlin&lt;/groupId&gt;        &lt;artifactId&gt;kotlin-stdlib-jdk8&lt;/artifactId&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt;    &lt;sourceDirectory&gt;${project.basedir}/src/main/kotlin&lt;/sourceDirectory&gt;    &lt;testSourceDirectory&gt;${project.basedir}/src/test/kotlin&lt;/testSourceDirectory&gt;    &lt;plugins&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;        &lt;/plugin&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.jetbrains.kotlin&lt;/groupId&gt;            &lt;artifactId&gt;kotlin-maven-plugin&lt;/artifactId&gt;            &lt;configuration&gt;                &lt;args&gt;                    &lt;arg&gt;-Xjsr305=strict&lt;/arg&gt;                &lt;/args&gt;                &lt;compilerPlugins&gt;                    &lt;plugin&gt;spring&lt;/plugin&gt;                &lt;/compilerPlugins&gt;            &lt;/configuration&gt;            &lt;dependencies&gt;                &lt;dependency&gt;                    &lt;groupId&gt;org.jetbrains.kotlin&lt;/groupId&gt;                    &lt;artifactId&gt;kotlin-maven-allopen&lt;/artifactId&gt;                    &lt;version&gt;${kotlin.version}&lt;/version&gt;                &lt;/dependency&gt;            &lt;/dependencies&gt;        &lt;/plugin&gt;    &lt;/plugins&gt;&lt;/build&gt;</code></pre></li><li><p>JwtUtil.kt 工具类，实现了签名、解析、校验、获取用户名的相关方法.</p><pre><code class="kotlin">package com.raindrop.auth.utilsimport com.auth0.jwt.JWTimport com.auth0.jwt.algorithms.Algorithmimport com.auth0.jwt.interfaces.Claimimport java.util.*/*** Jwt 工具类** @author Raindrop*/open class JwtUtil {    companion object {        /* 秘钥 */        private val secret = &quot;raindrop-666&quot;        /* 过期时间 15 分钟 */        private val expireTime = 15 * 60 * 1000        /**        * 生成 Token        *        * @param username 用户名        * @return token 令牌        */        fun sign(username: String): String {var createDate = Date()            var expireDate = Date(System.currentTimeMillis() + expireTime)            var claims = mapOf(&quot;username&quot; to username)            return JWT.create()                    .withHeader(claims)                    .withSubject(username)                    .withIssuedAt(createDate)                    .withExpiresAt(expireDate)                    .sign(Algorithm.HMAC512(secret))        }        /**        * 解析 Token        *        * @param token 令牌        * @return claim        */        fun parse(token: String): MutableMap&lt;String, Claim&gt;? {return JWT.decode(token).claims        }        /**        * 检验 Token        *        * @param token 令牌        * @return 有效 true 无效 false        */        fun verifyToken(token: String): Boolean {            return try {JWT.require(Algorithm.HMAC512(secret)).build().verify(token)                true            } catch (e: Exception) {false}        }        /**        * 获取用户名        *        * @param token 令牌        * @return 用户名        */        fun getUserName(token: String) = JWT.decode(token).getClaim(&quot;username&quot;).asString()        /**        * 刷新 token        *        * @param token 原 token        * @return 新 token        */        fun refresh(token: String): String {var createDate = Date()            var expireDate = Date(System.currentTimeMillis() + expireTime)            var username = parse(token)!![&quot;sub&quot;]!!.asString()            var header = mapOf(&quot;username&quot; to username)            return JWT.create()                    .withHeader(header)                    .withSubject(username)                    .withIssuedAt(createDate)                    .withExpiresAt(expireDate)                    .sign(Algorithm.HMAC512(secret))        }    }}</code></pre></li><li><p>AuthInterceptor.kt 拦截器，请求前进行拦截. 如果请求方法为 OPTIONS，则放过不进行拦截，关于 OPTIONS 请求方法，主要是在发送 PUT、DELETE 或 Content-Type application/json 请求前进行 <strong> 预检 </strong>，浏览器会先询问服务器，当前请求域名是否在服务器允许的范围内，如果允许则浏览器会发出正式的 XMLHttpRequest 请求，否则会报错. 此拦截器对<strong> 登录 </strong> 接口不进行拦截.</p><pre><code class="kotlin">package com.raindrop.auth.interceptorsimport com.alibaba.fastjson.JSONimport com.raindrop.auth.model.ResultEntityimport com.raindrop.auth.model.buildResultEntityimport com.raindrop.auth.utils.JwtUtilimport org.slf4j.LoggerFactoryimport org.springframework.stereotype.Componentimport org.springframework.web.servlet.HandlerInterceptorimport javax.servlet.http.HttpServletRequestimport javax.servlet.http.HttpServletResponse@Componentclass AuthInterceptor : HandlerInterceptor {private val logger = LoggerFactory.getLogger(this.javaClass)    private val options = &quot;OPTIONS&quot;    override fun preHandle(request: HttpServletRequest, response: HttpServletResponse, handler: Any): Boolean {if (request.method == options) return true        var authorization = request.getHeader(&quot;Authorization&quot;)        if (authorization != null) {var token = authorization.substring(7)            if (JwtUtil.verifyToken(token)) {logger.info(&quot;Auth Success Token Effective...&quot;)                return true            }        }        logger.info(&quot;Auth Fail Token Invalid...&quot;)        response.writer.write(JSON.toJSONString(buildUnauthorizedResultEntity()))        return false    }    fun buildUnauthorizedResultEntity(): ResultEntity {        return buildResultEntity {            code = 403            message = &quot;Auth Fail&quot;        }    }}</code></pre></li><li><p>AuthConfig.kt 拦截器配置，此处将 <strong> 登录 </strong> 接口过滤，不进行拦截，其他全部接口，全部需要携带 token 并认证通过后，方可访问.</p><pre><code class="kotlin">package com.raindrop.auth.configimport com.raindrop.auth.interceptors.AuthInterceptorimport org.springframework.context.annotation.Configurationimport org.springframework.web.servlet.config.annotation.InterceptorRegistryimport org.springframework.web.servlet.config.annotation.WebMvcConfigurer@Configurationclass AuthConfig : WebMvcConfigurer {    /**      * 添加拦截器      */    override fun addInterceptors(registry: InterceptorRegistry) {var excludePath = listOf(&quot;/auth/login&quot;, &quot;/auth/guest&quot;, &quot;/auth/refresh&quot;)        registry.addInterceptor(AuthInterceptor()).excludePathPatterns(excludePath)    }}</code></pre></li><li><p>ResultEntity.kt 通用返回实体，此处使用了 kotlin 高级语法，从而可以使用 dsl 方式构建通用返回实体.</p><pre><code class="kotlin">package com.raindrop.auth.modelimport java.io.Serializabledata class ResultEntity(        var code: Int = 200,        var message: String = &quot;success&quot;,        var data: Any = &quot;&quot;) : Serializablefun buildResultEntity(builder: ResultEntity.() -&gt; Unit) = ResultEntity().apply(builder)</code></pre></li><li><p>User.kt 用户实体.</p><pre><code class="kotlin">package com.raindrop.auth.modelclass User(        var username: String,        var password: String,        var nickName: String)</code></pre></li><li><p>IUserService.kt 用户服务接口.</p><pre><code class="kotlin">package com.raindrop.auth.serviceinterface IUserService {    /**      * 登录      *      * @param username 用户名      * @param password 用户密码      * @return      */    fun login(username: String, password: String): Boolean}</code></pre></li><li><p>UserServiceImpl.kt 用户服务实现.</p><pre><code class="kotlin">package com.raindrop.auth.service.implimport com.raindrop.auth.service.IUserServiceimport org.springframework.stereotype.Service@Serviceclass UserServiceImpl : IUserService {    /**    * 登录    *    * @param username 用户名    * @param password 用户密码    * @return    */    override fun login(username: String, password: String): Boolean = true}</code></pre></li><li><p>AuthController.kt 业务 Controller，/login 接口不进行拦截，账号密码正确后，返回 token. /users 接口需要拦截，需认证通过后携带正确的 token 后，方可访问.</p><pre><code class="kotlin">package com.raindrop.auth.webimport com.raindrop.auth.model.ResultEntityimport com.raindrop.auth.model.Userimport com.raindrop.auth.model.buildResultEntityimport com.raindrop.auth.service.IUserServiceimport com.raindrop.auth.utils.JwtUtilimport org.slf4j.LoggerFactoryimport org.springframework.beans.factory.annotation.Autowiredimport org.springframework.web.bind.annotation.GetMappingimport org.springframework.web.bind.annotation.PostMappingimport org.springframework.web.bind.annotation.RequestMappingimport org.springframework.web.bind.annotation.RestController@RestController@RequestMapping(&quot;/auth&quot;)class AuthController {private val logger = LoggerFactory.getLogger(this.javaClass)    @Autowired    lateinit var userService: IUserService    /**    * 登录    *    * @param username 用户名    * @param password 用户密码    * @return    */    @PostMapping(&quot;/login&quot;)    fun login(username: String, password: String): ResultEntity {if (username == null) {logger.warn(&quot;Login Fail, UserName Is Null&quot;)            throw IllegalArgumentException(&quot; 登录失败，用户不存在 &quot;)        }        if (password == null) {logger.warn(&quot;Login Fail, Password Is Null&quot;)            throw IllegalArgumentException(&quot; 登录失败，账号或密码错误 &quot;)        }        if (userService.login(username, password)) {var token = JwtUtil.sign(username)            return buildResultEntity {data = token}        }        return buildResultEntity {            code = 400            message = &quot; 登录失败 &quot;        }    }    /**    * 获取用户列表    *    * @return    */    @GetMapping(&quot;/users&quot;)    fun getUserList(): ResultEntity {        var users = listOf(User(&quot;wl&quot;, &quot;wl&quot;, &quot;wl&quot;),                User(&quot;lv&quot;, &quot;lv&quot;, &quot;lv&quot;),                User(&quot;ee&quot;, &quot;ee&quot;, &quot;ee&quot;)        )        return buildResultEntity {data = users}    }</code></pre></li></ul><pre><code>    @PostMapping(&quot;/refresh&quot;)    fun refreshToken(token: String): String = if (JwtUtil.verifyToken(token)) JwtUtil.refresh(token) else &quot;Token Invalid&quot;    @GetMapping(&quot;/guest&quot;)    fun getGuestMessage(): ResultEntity {        return buildResultEntity {data = &quot;Hello Guest, You are handsome!&quot;}    }}```</code></pre><ul><li><p>AuthTokenApplication.kt 启动类.</p><pre><code class="kotlin">package com.raindrop.authimport org.springframework.boot.autoconfigure.SpringBootApplicationimport org.springframework.boot.runApplication@SpringBootApplicationclass AuthTokenApplicationfun main(args: Array&lt;String&gt;) {runApplication&lt;AuthTokenApplication&gt;(*args)}</code></pre></li></ul><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><ul><li><p>无登录时访问 GET <a href="http://localhost:8888/auth/guest" target="_blank" rel="noopener">http://localhost:8888/auth/guest</a> ， 可以访问，因为该接口并未被过滤器拦截.<br><img src="http://qiniu.raindrop-wl.cn/jwt-users-login.png" srcset="/img/loading.gif" alt="jwt-guest"></p></li><li><p>无登录时访问 GET <a href="http://localhost:8888/auth/users" target="_blank" rel="noopener">http://localhost:8888/auth/users</a> ， 此时无意外提醒未授权，因为此接口被过滤器拦截.<br><img src="http://qiniu.raindrop-wl.cn/jwt-users-unlogin.png" srcset="/img/loading.gif" alt="jwt-users-unlogin"></p></li><li><p>访问登录接口 POST <a href="http://localhost:8888/auth/login" target="_blank" rel="noopener">http://localhost:8888/auth/login</a> ， 认证成功，并返回 token.<br><img src="http://qiniu.raindrop-wl.cn/jwt-login.png" srcset="/img/loading.gif" alt="jwt-login"></p></li><li><p>此时再次访问 GET <a href="http://localhost:8888/auth/users" target="_blank" rel="noopener">http://localhost:8888/auth/users</a> ， 可以正确获取结果.<br><img src="http://qiniu.raindrop-wl.cn/jwt-users-login.png" srcset="/img/loading.gif" alt="jwt-users-login"></p></li><li><p>token 过期，刷新 token 访问 POST <a href="http://localhost:8888/auth/refresh" target="_blank" rel="noopener">http://localhost:8888/auth/refresh</a> ， 认证原 token 成功后，返回新 token.<br><img src="http://qiniu.raindrop-wl.cn/jwt-refresh-token.png" srcset="/img/loading.gif" alt="jwt-refresh"></p><p>Source: <a href="https://github.com/727474430/Kotlin-Jwt-Token" target="_blank" rel="noopener">Link</a></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Java Atomic</title>
    <link href="/2019/04/06/Java%20Atomic/"/>
    <url>/2019/04/06/Java%20Atomic/</url>
    
    <content type="html"><![CDATA[<p><strong>Java 中”i++”是线程安全得吗? 一次面试题引发的学习 </strong></p><a id="more"></a><h3 id="什么是原子操作？"><a href="# 什么是原子操作？" class="headerlink" title="什么是原子操作？"></a> 什么是原子操作？</h3><ul><li><p> 所谓原子操作, 可以简单理解为一次不可分割的操作, 同时可以保证线程安全. 例如:</p><pre><code class="java">  int i = 1;</code></pre></li><li><p> 如上代码表示原子操作, 即一次性赋值, 没有多余的中间操作.</p></li></ul><h3 id="那么 i- 是否是原子操作呢"><a href="# 那么 i- 是否是原子操作呢" class="headerlink" title="那么 i++ 是否是原子操作呢?"></a> 那么 i++ 是否是原子操作呢?</h3><ul><li><p> 同样的方式来分析 i++ 操作. 可以分为三步:</p><ol><li> 获取上一次 i 值.</li><li> 将 i 的值 +1.</li><li> 赋值给 i.</li></ol></li><li><p> 由上可见 i++ 并非不可分割操作, 所以 i++ 并不是原子操作, 即 i++ 并非线程安全.</p></li></ul><h3 id="那么在 java 中如何保证自增操作的线程安全呢"><a href="# 那么在 java 中如何保证自增操作的线程安全呢" class="headerlink" title="那么在 java 中如何保证自增操作的线程安全呢?"></a> 那么在 java 中如何保证自增操作的线程安全呢?</h3><ul><li><p> 方法有 3 种:</p><ol><li> 利用同步–Synchronized.</li><li> 利用 Java 提供给我们的 AtomicInteger、AtomicLong…</li><li> 利用 Lock.</li></ol></li><li><p> 我们来看几种不同的方式获得的结果.</p><pre><code class="java">  public class IncrementTest {      public static int count = 0;      public static Counter counter = new Counter();      public static AtomicInteger atomicInteger = new AtomicInteger(0);      public volatile static int countVolatile = 0;      public static Lock lock = new ReentrantLock();      public static int countLock = 0;      public static void main(String[] args) {for (int i = 0; i &lt; 10; i++) {new Thread(() -&gt; {for (int j = 0; j &lt; 1000; j++) {                          count++;                          counter.increment();                          atomicInteger.getAndIncrement();                          countVolatile++;                          lockIncrement();}              }).start();}          try {Thread.sleep(3000);          } catch (InterruptedException e) {e.printStackTrace();          }          System.out.println(&quot;static int -&gt; &quot; + count);          System.out.println(&quot;counter -&gt; &quot; + counter.getValue());          System.out.println(&quot;atomicInteger -&gt; &quot; + atomicInteger.get());          System.out.println(&quot;volatile int -&gt; &quot; + countVolatile);          System.out.println(&quot;count lock -&gt; &quot; + countLock);      }      public static void lockIncrement() {lock.lock();          countLock++;          lock.unlock();}  }  class Counter {      private int value;      public synchronized int getValue() {return value;}      public synchronized int increment() {return ++value;}      public synchronized int decrement() {return --value;}  }</code></pre></li><li><p> 上述代码我们定义了四个类型的变量:</p><ol><li> 静态 int.</li><li>AtomicInteger Java 提供原子操作.</li><li>Counter 同步方式.</li><li>volatile 可见性关键字 (这里不对该关键字做讨论).</li></ol></li><li><p> 我们来看一下运行结果:</p><p><img src="http://qiniu.raindrop-wl.cn/increment.png" srcset="/img/loading.gif" alt="increment"></p></li><li><p> 可见,Java 中可以保证自增为线程安全的方法是 Atomic 以及 Synchronized.</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Mac Alfred Workflows</title>
    <link href="/2019/04/06/My%20Mac%20Alfred%20Workflows/"/>
    <url>/2019/04/06/My%20Mac%20Alfred%20Workflows/</url>
    
    <content type="html"><![CDATA[<p><strong>This blog records myself using alfred wordflows</strong></p><a id="more"></a><h3 id="Following-Plugin-In-No-Particular-Order"><a href="#Following-Plugin-In-No-Particular-Order" class="headerlink" title="Following Plugin In No Particular Order"></a>Following Plugin In No Particular Order</h3><table><thead><tr><th align="center">Name</th><th align="center">Function</th><th align="center">Shortcut</th></tr></thead><tbody><tr><td align="center">CodeVar</td><td align="center">define variable</td><td align="center"><code>xt</code>     name(chinese)</td></tr><tr><td align="center">CodeVar</td><td align="center">define variable</td><td align="center"><code>dt</code>     name(chinese)</td></tr><tr><td align="center">DS_Store</td><td align="center">delete macos generating .ds_store file</td><td align="center"><code>dsc</code>    current folder</td></tr><tr><td align="center">encode-decode</td><td align="center">command encoding</td><td align="center"><code>encode</code> string</td></tr><tr><td align="center">encode-decode</td><td align="center">command encoding</td><td align="center"><code>decode</code> string</td></tr><tr><td align="center">github_search</td><td align="center">fast search github repository info</td><td align="center"><code>github</code> repo name</td></tr><tr><td align="center">Hash</td><td align="center">hash encoding(md5 sha1 sha512…)</td><td align="center"><code>hash</code>   string</td></tr><tr><td align="center">Kill Process</td><td align="center">kill target process</td><td align="center"><code>kill</code>   target process</td></tr><tr><td align="center">kuaidichaxun</td><td align="center">fast query kuaidi</td><td align="center"><code>kd</code>     order number</td></tr><tr><td align="center">StackOverflow</td><td align="center">fast query StackOverflow in problem</td><td align="center"><code>.so</code>    problem</td></tr><tr><td align="center">V2EX</td><td align="center">fast query v2ex in info</td><td align="center"><code>v2ex</code>   info</td></tr><tr><td align="center">YouDao</td><td align="center">youdao translate</td><td align="center"><code>yd</code>     info</td></tr><tr><td align="center">QR code</td><td align="center">fast generator QR code</td><td align="center"><code>qr</code>     info</td></tr></tbody></table><h3 id="Using-Example-Image-Style"><a href="#Using-Example-Image-Style" class="headerlink" title="Using Example Image Style"></a>Using Example Image Style</h3><ul><li><p>CodeVar<br><img src="http://qiniu.raindrop-wl.cn/xt.png" srcset="/img/loading.gif" alt="img"></p></li><li><p>DS<sub>Store</sub><br><img src="http://qiniu.raindrop-wl.cn/dsc.png" srcset="/img/loading.gif" alt="img"></p></li><li><p>encode-decode<br><img src="http://qiniu.raindrop-wl.cn/encode.png" srcset="/img/loading.gif" alt="img"><br><img src="http://qiniu.raindrop-wl.cn/decode.png" srcset="/img/loading.gif" alt="img"></p></li><li><p>github<sub>search</sub><br><img src="http://qiniu.raindrop-wl.cn/github.png" srcset="/img/loading.gif" alt="img"></p></li><li><p>Hash<br><img src="http://qiniu.raindrop-wl.cn/hash.png" srcset="/img/loading.gif" alt="img"></p></li><li><p>Kill Process<br>![img](<a href="http://qiniu.raindrop-wl.cn/kill" target="_blank" rel="noopener">http://qiniu.raindrop-wl.cn/kill</a> process.png)</p></li><li><p>Kd<br><img src="http://qiniu.raindrop-wl.cn/kd.png" srcset="/img/loading.gif" alt="img"></p></li><li><p>StackOverFlow<br><img src="http://qiniu.raindrop-wl.cn/stackoverflow.png" srcset="/img/loading.gif" alt="img"></p></li><li><p>V2EX<br><img src="http://qiniu.raindrop-wl.cn/v2ex.png" srcset="/img/loading.gif" alt="img"></p></li><li><p>YouDao<br><img src="http://qiniu.raindrop-wl.cn/yd.png" srcset="/img/loading.gif" alt="img"></p></li><li><p>QR Code<br><img src="http://qiniu.raindrop-wl.cn/qr.png" srcset="/img/loading.gif" alt="img"></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Maven Project</title>
    <link href="/2019/01/05/Maven%20Project/"/>
    <url>/2019/01/05/Maven%20Project/</url>
    
    <content type="html"><![CDATA[<p><strong>Maven</strong> 主要用于项目构建、依赖管理、项目信息管理</p><a id="more"></a><h1 id="Maven 作用"><a href="#Maven 作用" class="headerlink" title="Maven 作用?"></a>Maven 作用?</h1><h3 id="自动下载依赖"><a href="# 自动下载依赖" class="headerlink" title="自动下载依赖"></a>自动下载依赖</h3><ul><li><p>当我们在 pom.xml 配置文件做了相应的配置之后,maven 会自动从远程仓库下载对应 jar 包</p></li><li><p>同时每个 jar 包内部也配有 pom.xml, 其中包含了该 jar 包所需要的其他依赖,maven 也可以同时帮助我们自动下载. 帮助我们开发人员省去了寻找 jar 包所花费的不必要时间.</p></li></ul><h3 id="热部署、热编译"><a href="# 热部署、热编译" class="headerlink" title="热部署、热编译"></a>热部署、热编译</h3><ul><li>当 Web 项目运行时, 我们对源代码进行修改后, 需要重启服务器或重新部署代码, 就可以自动被服务器所加载.</li></ul><h3 id="打包"><a href="# 打包" class="headerlink" title="打包"></a>打包</h3><ul><li>使用 Maven 可以直接打包 war 或 jar 项目.</li></ul><h1 id="Maven 项目结构"><a href="#Maven 项目结构" class="headerlink" title="Maven 项目结构"></a>Maven 项目结构</h1><table><thead><tr><th align="center">Path</th><th align="center">Meaning</th></tr></thead><tbody><tr><td align="center">src/main/java</td><td align="center">存放项目. java 文件</td></tr><tr><td align="center">src/main/resource</td><td align="center">存放项目资源文件</td></tr><tr><td align="center">src/test/java</td><td align="center">存放项目测试类. java 文件</td></tr><tr><td align="center">src/test/resource</td><td align="center">存放项目测试相关资源文件</td></tr><tr><td align="center">target</td><td align="center">项目输出目录</td></tr><tr><td align="center">pom.xml</td><td align="center">Maven 核心配置文件</td></tr></tbody></table><h1 id="Maven 使用"><a href="#Maven 使用" class="headerlink" title="Maven 使用"></a>Maven 使用 </h1><h3 id="从官网下载后进行解压 - 然后配置到环境变量即可通过命令行使用"><a href="# 从官网下载后进行解压 - 然后配置到环境变量即可通过命令行使用" class="headerlink" title="从官网下载后进行解压, 然后配置到环境变量即可通过命令行使用."></a> 从官网下载后进行解压, 然后配置到环境变量即可通过命令行使用.</h3><ul><li>mvn -v 查看版本号(测试环境变量是否配置成功).</li></ul><h3 id="命令行方式创建 Maven 项目"><a href="# 命令行方式创建 Maven 项目" class="headerlink" title="命令行方式创建 Maven 项目"></a>命令行方式创建 Maven 项目</h3><ul><li>mvn archetype:generate -DgroupId=com.raindrop -DartifactId=MavenTest -DarchetypeArtifactId=maven-archetype-quicktart -DinteractiveMode=false</li></ul><h1 id="Maven 常用命令"><a href="#Maven 常用命令" class="headerlink" title="Maven 常用命令"></a>Maven 常用命令</h1><table><thead><tr><th align="center">Command</th><th align="center">Meaning</th></tr></thead><tbody><tr><td align="center">mvn -v</td><td align="center">查看版本号</td></tr><tr><td align="center">mvn compile</td><td align="center">编译源代码</td></tr><tr><td align="center">mvn package</td><td align="center">根据项目生成 jar</td></tr><tr><td align="center">mvn deploy</td><td align="center">发布项目</td></tr><tr><td align="center">mvn test-compile</td><td align="center">编译测试源代码</td></tr><tr><td align="center">mvn test</td><td align="center">运行程序中单元测试</td></tr><tr><td align="center">mvn site</td><td align="center">生成项目相关信息网站</td></tr><tr><td align="center">mvn clean</td><td align="center">清除项目中已经生成的内容</td></tr><tr><td align="center">mvn install</td><td align="center">在本地 Repository 中安装 jar</td></tr><tr><td align="center">mvn eclipse:eclipse</td><td align="center">生成 Eclipse 项目相关文件</td></tr><tr><td align="center">mvn tomcat:run</td><td align="center">启动 tomcat 服务</td></tr><tr><td align="center">mvn spring-boot:run</td><td align="center">启动 Spring Boot 服务</td></tr><tr><td align="center">mvn clean package -DskipTests</td><td align="center">清除并重新打包, 跳过 test 包</td></tr><tr><td align="center">mvn eclipse:clean</td><td align="center">清除 Project 编译内容</td></tr><tr><td align="center">mvn clean package</td><td align="center">清除并重新打包</td></tr></tbody></table><h1 id="Maven 配置 jar 包"><a href="#Maven 配置 jar 包" class="headerlink" title="Maven 配置 jar 包"></a>Maven 配置 jar 包</h1><ul><li><p>Maven Repository Location:</p><pre><code class="xml">&lt;https://mvnrepository.com/&gt;&lt;dependency&gt;  &lt;groupId&gt;org.json&lt;/groupId&gt;  &lt;artifactId&gt;json&lt;/artifactId&gt;  &lt;version&gt;20160212&lt;/version&gt;&lt;/dependency&gt;</code></pre></li></ul>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Git Command(2)</title>
    <link href="/2019/01/05/Git%20Command(2)/"/>
    <url>/2019/01/05/Git%20Command(2)/</url>
    
    <content type="html"><![CDATA[<p><strong>Git brach command</strong></p><a id="more"></a><h3 id="如何创建一个分支"><a href="# 如何创建一个分支" class="headerlink" title="如何创建一个分支"></a> 如何创建一个分支 </h3><ul><li><p> 第一种方式：</p><pre><code class="bash"># 创建分支$ git branch &#39;branch-name&#39;# 切换分支$ git checkout &#39;branch-name&#39;</code></pre></li><li><p> 第二种方式 (I prefer to), 这种方式在创建分支后即切换到分支:</p><pre><code class="bash">$ git checkout -b &#39;branch-name&#39;</code></pre></li></ul><h3 id="学会了创建分支 - 接下来我们学习删除分支"><a href="# 学会了创建分支 - 接下来我们学习删除分支" class="headerlink" title="学会了创建分支, 接下来我们学习删除分支"></a> 学会了创建分支, 接下来我们学习删除分支 </h3><ul><li> 以下命令即可简单删除指定分支:<pre><code class="bash">$ git branch -d &#39;branch-name&#39;</code></pre></li></ul><h3 id="接下来我们学习如何合并分支"><a href="# 接下来我们学习如何合并分支" class="headerlink" title="接下来我们学习如何合并分支"></a> 接下来我们学习如何合并分支 </h3><ul><li><p> 首先来看默认 fast-forward 方式:</p><pre><code class="bash"># 这种方式执行后会提示我们使用点上 ff 方式合并, 默认情况下执行结果如下$ git merge &#39;branch-name&#39;</code></pre></li><li><p> 接下来我们看一下除了 ff 方式合并, 正常开时遇到的合并方式 </p><pre><code class="bash"># 首先创建分支 \`dev\`, 完成之后修改 README.org 文件并提交$ git checkout -b dev$ vim README.org$ git commit -am &quot;dev commit content&quot;# 然后切换到 master 分支, 修改 README.org 文件并提交$ git checkout master$ vim README.org$ git commit -am &quot;master commit content&quot;# 最后合并分支查看提示$ git merge dev</code></pre></li><li><p> 此时 git 提示我们 Readme 文件产生冲突, 请解决冲突后在进行合并. 然后我们打开 README.org 文件看到如下内容:<br> 该文件目前以 ===== 分割, HEAD -&gt; 表示当前分支提交到内容, dev -&gt; 表示另一个分支提交到内容. 此时我们需要将冲突解决后, 在进行合并集合完成目的.</p></li><li><p> 如上图所示，解决为该内容后就可以进行合并啦！</p><pre><code class="bash">$ git merge dev</code></pre></li></ul><h3 id="查看分支情况"><a href="# 查看分支情况" class="headerlink" title="查看分支情况"></a> 查看分支情况 </h3><ul><li> 通过带参数的 git log 进行查看, 如下图 <pre><code class="bash">$ git log --graph --pretty=oneline --abbrev-commit</code></pre></li></ul><h3 id="合并分支（普通合并）"><a href="# 合并分支（普通合并）" class="headerlink" title="合并分支（普通合并）"></a> 合并分支（普通合并）</h3><ul><li>git default useing fast-forward mode merge. we can pass prohibit(禁止) ff. use ordinary(普通) merge. ordinary merge will generate a new commit obejct.<pre><code class="bash">$ git merge --no-ff -m &quot;merge with no-ff&quot; dev</code></pre></li></ul><h3 id="分支管理策略"><a href="# 分支管理策略" class="headerlink" title="分支管理策略"></a> 分支管理策略 </h3><ul><li><p> 一般来说工作中使用 3 个分支进行开发就足够了.<br>master 主分支用来发布 <br>dev    日常开发使用分支 <br>bug    修改 bug 时使用分支 </p></li><li><p>master 分支应该是非常稳定的, 也就是仅仅用来进行新版本发布, 一般不再上面做开发,dev 分支应该是平常用了进行新功能开发的分支,dev 分支是不稳定的. 当我们新功能开发完成并测试通过后, 即可将 dev 合并到 master 中进行发布. 而 bug 分支我们只用来解决日常 bug, 解决后合并到 dev 分支即可.</p></li></ul><h3 id="Git-Branch-Relevent-Common-Command"><a href="#Git-Branch-Relevent-Common-Command" class="headerlink" title="Git Branch Relevent Common Command"></a>Git Branch Relevent Common Command</h3><table><thead><tr><th align="center">Command</th><th align="center">Meaning</th></tr></thead><tbody><tr><td align="center">git branch -v</td><td align="center"> 查看每一个分支最后一次提交 </td></tr><tr><td align="center">git branch -a</td><td align="center"> 查看本地和远程分支情况 </td></tr><tr><td align="center">git branch -merged</td><td align="center"> 查看已经与当前分支合并过的分支 </td></tr><tr><td align="center">git branch -no-merge</td><td align="center"> 查看已经与当前分支未合并的分支 </td></tr><tr><td align="center">git branch -r</td><td align="center"> 查看远程分支情况 </td></tr><tr><td align="center">git branch dev</td><td align="center"> 创建分支 dev</td></tr><tr><td align="center">git checkout dev</td><td align="center"> 切换到分支 dev</td></tr><tr><td align="center">git checkout -b dev</td><td align="center"> 创建同时切换到 dev 分支 </td></tr><tr><td align="center">git merge dev</td><td align="center"> 合并 dev 分支 </td></tr><tr><td align="center">git branch -d dev</td><td align="center"> 删除 dev 分支 </td></tr><tr><td align="center">git merge -no -ff -m”message”</td><td align="center"> 合并分支并禁用 fast-forward</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>Git</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Git Command(1)</title>
    <link href="/2019/01/05/Git%20Command(1)/"/>
    <url>/2019/01/05/Git%20Command(1)/</url>
    
    <content type="html"><![CDATA[<p><strong>Git rollback command</strong></p><a id="more"></a><h3 id="Revoke-Operation"><a href="#Revoke-Operation" class="headerlink" title="Revoke Operation"></a>Revoke Operation</h3><ul><li><p>Basic command</p><pre><code class="bash">$ git checkout -- [file]</code></pre></li><li><p>When file just in work area conduct modify, Not yet(还没有) commit to temporary(暂存) storage.<br>You can use this command, To achieve effect(来达到效果)</p><pre><code class="bash">$ git reset HEAD</code></pre></li><li><p>If you in work area conduct the modify, And commit to temporary. `git checkout &#x2013; [file]` command<br>it’s invalid(就无效了).<br>This time should use `git reset HEAD` command to achieve effect.</p><pre><code class="bash">$ git checkout HEAD [file]</code></pre></li><li><p>This command just will two on the top combine(组合起来), Direct use HEAD cover(覆盖) temporary and<br>word area.</p></li></ul><hr><h3 id="Rollback-Version"><a href="#Rollback-Version" class="headerlink" title="Rollback Version"></a>Rollback Version</h3><ul><li><p>Basic command</p><pre><code class="bash">$ git reset --hard HEAD~n</code></pre></li><li><p>In git `HEAD` express current version. This command just rollback to `~` after appoint version.</p><pre><code class="bash">$ git reset --hard commit_id</code></pre></li><li><p>This command just rollback to `commit<sub>id</sub>` version.<br>In git see commit<sub>id</sub> the method: git reflog command.</p></li></ul><hr><h3 id="Delete-Summary"><a href="#Delete-Summary" class="headerlink" title="Delete Summary"></a>Delete Summary</h3><ul><li><p>Basic command</p><pre><code class="bash">$ git rm</code></pre></li><li><p>This command will delete word area and temporary in content.</p></li><li><p>If delete file after, Want to get back(想要找回) just got us(刚刚被我们) delete the file.Use `git checkout HEAD [file]` command to achieve effect. Permise is(前提是) not commit.</p></li><li><p>If delete file after and commit, Then you need use `git reset &#x2013;hard HEAD~1` rollback<br>to one on top version, Can achieve effect(可以达到效果).</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Git</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Java Excel Opreator</title>
    <link href="/2019/01/05/Java%20Excel%20Operator/"/>
    <url>/2019/01/05/Java%20Excel%20Operator/</url>
    
    <content type="html"><![CDATA[<p><strong>记录一次 Apache POI 学习</strong></p><a id="more"></a><h3 id="POI- 介绍"><a href="#POI- 介绍" class="headerlink" title="POI 介绍"></a>POI 介绍</h3><ul><li><p>通过 Java 程序操作 Office 相关组件(本次需求是对 Excel 提出).</p></li><li><p>底层基于 XML, 提供海量数据 (500W) 操作, 支持 xls/xlsx 格式.</p></li></ul><h3 id="使用 - 模拟用户列表导入与导出 Excel"><a href="# 使用 - 模拟用户列表导入与导出 Excel" class="headerlink" title="使用: 模拟用户列表导入与导出 Excel."></a>使用: 模拟用户列表导入与导出 Excel.</h3><ul><li><p>封装一下工具类:</p><pre><code class="java">/*** 指定数据导出到 Excel** @param data* @param out*/public static void exportExcel(List&lt;User&gt; data, OutputStream out) {   HSSFWorkbook workbook = null;   try {       // 创建工作博       workbook = new HSSFWorkbook();       // 合并单元格       CellRangeAddress cellRangeAddress = new CellRangeAddress(0, 0, 0, 4);       // 创建头标题样式       HSSFCellStyle headStyle = createCellStyle(workbook, (short) 16);       // 创建列标题样式       HSSFCellStyle colStyle = createCellStyle(workbook, (short) 13);       // sheet       HSSFSheet sheet = workbook.createSheet(&quot; 用户名单 &quot;);       // 添加合并单元格对象       sheet.addMergedRegion(cellRangeAddress);       // 默认列宽度       sheet.setDefaultColumnWidth(25);       // 创建行       HSSFRow row = sheet.createRow(0);       // 创建单元格       HSSFCell cell = row.createCell(0);       // 加载单元格样式       cell.setCellStyle(headStyle);       cell.setCellValue(&quot; 用户列表 &quot;);       // 创建列标题       HSSFRow titleRow = sheet.createRow(1);       String[] titles = {&quot; 用户名 &quot;, &quot; 年龄 &quot;, &quot; 性别 &quot;, &quot; 邮箱 &quot;, &quot; 手机 &quot;};       // 添加每列标题及样式       for (int i = 0; i &lt; titles.length; i++) {HSSFCell newCell = titleRow.createCell(i);           newCell.setCellStyle(colStyle);           newCell.setCellValue(titles[i]);       }       // 创建单元格 写入数据       if (data != null) {for (int i = 0; i &lt; data.size(); i++) {User user = data.get(i);               // 写入每行数据(前两行已经被占用)               HSSFRow newRow = sheet.createRow(i + 2);               // 姓名               HSSFCell c1 = newRow.createCell(0);               c1.setCellValue(user.getName());               // 年龄               HSSFCell c2 = newRow.createCell(1);               c2.setCellValue(user.getAge());               // 性别               HSSFCell c3 = newRow.createCell(2);               c3.setCellValue(user.getSex() == 1 ? &quot; 男 &quot; : &quot; 女 &quot;);               // 邮箱               HSSFCell c4 = newRow.createCell(3);               c4.setCellValue(user.getEmail());               // 手机               HSSFCell c5 = newRow.createCell(4);               c5.setCellValue(user.getPhone());           }       }       // 写入到文件       workbook.write(out);   } catch (Exception e) {e.printStackTrace();   } finally {       // 关闭       try {workbook.close();       } catch (IOException e) {e.printStackTrace();       }   }}/*** 单元格样式配置** @param workbook* @param fontSize* @return*/private static HSSFCellStyle createCellStyle(HSSFWorkbook workbook, short fontSize) {HSSFCellStyle style = workbook.createCellStyle();   // 水平居中   style.setAlignment(HorizontalAlignment.CENTER);   // 垂直居中   style.setVerticalAlignment(VerticalAlignment.CENTER);   // 字体   HSSFFont font = workbook.createFont();   font.setBold(true);   font.setFontHeightInPoints(fontSize);   // 加载字体   style.setFont(font);   return style;}/*** Excel 文件导入** @param file* @return*/public static List&lt;User&gt; importExcel(File file) {   FileInputStream inputStream = null;   List&lt;User&gt; list = null;   HSSFWorkbook workbook = null;   try {list = new ArrayList&lt;&gt;();       inputStream = new FileInputStream(file);       // 读取文件       workbook = new HSSFWorkbook(inputStream);       // 读取 sheet       HSSFSheet sheet = workbook.getSheetAt(0);       // 读取行(行数大于 2)       if (sheet.getPhysicalNumberOfRows() &gt; 2) {           User user = null;           // 跳过前两行           for (int i = 2; i &lt; sheet.getPhysicalNumberOfRows(); i++) {               // 单元格               Row row0 = sheet.getRow(i);               user = new User();               // 封装数据               Cell cell0 = row0.getCell(0);               user.setName(cell0.getStringCellValue());               Cell cell1 = row0.getCell(1);               user.setAge(cell1.getStringCellValue());               Cell cell2 = row0.getCell(2);               user.setSex(cell2.getStringCellValue().equals(&quot; 男 &quot;) ? 1 : 0);               Cell cell3 = row0.getCell(3);               user.setEmail(cell3.getStringCellValue());               Cell cell4 = row0.getCell(4);               user.setPhone(cell4.getStringCellValue());               list.add(user);           }       }       workbook.close();} catch (Exception e) {e.printStackTrace();   } finally {       try {inputStream.close();       } catch (IOException e) {e.printStackTrace();       }   }   return list;}</code></pre><ul><li>工具类已经写好了, 下面我们来看一下 Controller 层代码.</li></ul><pre><code class="java">/*** Export Excel Api** @param request* @param response* @return*/@PostMapping(&quot;/v1/export&quot;)public String exportExcel(HttpServletRequest request, HttpServletResponse response) {   ServletOutputStream out = null;   try {List&lt;User&gt; list = (List&lt;User&gt;) request.getSession().getAttribute(&quot;users&quot;);       if (list != null) {response.setContentType(&quot;application/vnd.ms-excel;charset=gb2312&quot;);           response.setHeader(&quot;Content-Disposition&quot;, &quot;attachment;filename = &quot; + new String(&quot; 用户列表.xls&quot;.getBytes(), &quot;ISO-8859-1&quot;));           out = response.getOutputStream();           ExportExcelUtil.exportExcel(list, out);       }   } catch (Exception e) {e.printStackTrace();   }   return null;}/*** Import Excel Api** @param request* @param response* @param file* @return*/@PostMapping(&quot;/v1/import&quot;)public String importExcel(HttpServletRequest request, HttpServletResponse response, MultipartFile file) {if (file != null &amp;&amp; !file.isEmpty()) {String filePath = request.getSession().getServletContext().getRealPath(&quot;/&quot;) + file.getOriginalFilename();       try {file.transferTo(new File(filePath));       } catch (IOException e) {e.printStackTrace();       }   }   return &quot;redirect:/users/v1/upload&quot;;}/*** Find Specify File And Import** @param request* @param response* @return*/@RequestMapping(&quot;/v1/upload&quot;)public String fileUpload(HttpServletRequest request, HttpServletResponse response) {String filePath = request.getSession().getServletContext().getRealPath(&quot;/&quot;);   File uploadDest = new File(filePath);   String[] fileNames = uploadDest.list();   for (int i = 0; i &lt; fileNames.length; i++) {       // 打印出文件名       System.out.println(fileNames[i]);       List&lt;User&gt; list = ExportExcelUtil.importExcel(new File(filePath + fileNames[i]));       List&lt;User&gt; old = (List&lt;User&gt;) request.getSession().getAttribute(&quot;users&quot;);       old.addAll(list);   }   return &quot;user&quot;;}</code></pre><p>Source: <a href="https://github.com/727474430/Apache-POI" target="_blank" rel="noopener">link</a></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
